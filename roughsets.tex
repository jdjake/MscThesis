%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Avoiding Rough Sets}
\label{ch:RoughSets}

A major question in modern geometric measure theory is whether sets with sufficiently large Hausdorff dimension necessarily contain copies of certain patterns. For example, Theorem 6.8 of \cite{Matilla} shows that each set $X \subset \RR^d$ with Hausdorff dimension exceeding one must contain three colinear points. On the other hand, the main result of \cite{Maga} constructs a set $X \subset \RR^2$ with full Hausdorff dimension such that no four points in $X$ form the vertices of a parallelogram. At the time of this writing, many fundamental questions about the relation between the geometric patterns of a set and it's fractional dimension remain open. The threshold dimension above which patterns are guaranteed can vary for different patterns, or not even exist at all. In this paper, we provide lower bounds for the threshold by solving the pattern avoidance problem; constructing sets with large dimension avoiding patterns.

One natural way to approach the pattern avoidance problem is to find general methods for constructing pattern avoiding sets by exploiting a particular geometric feature of the pattern. In \cite{Mathe}, M\'{a}th\'{e} shows that, given a pattern specified by a countable union of rational coefficient bounded degree polynomials $f_1, f_2, \dots$ in $nd$ variables, one can construct a set $X \subset \RR^d$ such that for every collection of distinct points $x_1, \dots, x_n$, and each index $k$, $f_k(x_1, \dots, x_n) \neq 0$. In \cite{MalabikaRob}, Fraser and the second author consider a related problem where the polynomials $f_k$ are replaced with full rank $C^1$ functions.

% DISCUSS: SAY "WE SAY THIS AVOIDS THIS PATTERN IF..."

In this paper, we also find general methods for constructing pattern avoid sets. But rather than avoiding the zeroes of a function, we fix $Z \subset \RR^{dn}$, and construct sets $X$ such that for any distinct $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$. We then say $X$ avoids the pattern specified by $Z$. For instance, if $Z = \{ (x_1,x_2,x_3) \in (\RR^d)^3 : (x_1,x_2,x_3)\ \text{are colinear} \}$, then $X \subset \RR^d$ avoids the pattern specified by $Z$ precisely when $X$ does not contain three colinear points. Our problem generalizes the problem statements considered in \cite{Mathe} and \cite{MalabikaRob} if we set $Z = \bigcup_{k = 1}^\infty f_k^{-1}(0)$. From this perspective, M\'{a}th\'{e} constructs sets avoiding a set $Z$ formed from a countable union of algebraic varieties, while Fraser and the second author construct sets avoiding a set $Z$ formed from the countable union of $C^1$ manifolds.

The advantage of the formulation of pattern avoidance we consider is that it is now natural to consider `rough' sets $Z \subset \RR^{dn}$ which are not naturally specified as the zero set of a function. In particular, in this paper we consider $Z$ formed from the countable union of sets, each with lower Minkowski dimension bounded above by some $\alpha$. In contrast with previous work, no further assumptions are made on $Z$. The dimension of the avoiding set $X$ we will eventually construct depends only on the codimension $nd - \alpha$ of the set $Z$, and the number of variables $n$.

\begin{theorem}\label{mainTheorem}
	Let $Z \subset \RR^{nd}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$, with $d \leq \alpha < dn$. Then there exists a set $X \subset [0,1)^d$ with Hausdorff dimension at least $(nd - \alpha)/(n-1)$ such that whenever $x_1, \dots, x_n \in X$ are distinct, then $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

\begin{remark}
	When $\alpha < d$, the pattern avoidance problem is trivial, since $X = [0,1)^d - \pi(Z)$ is full dimensional and solves the pattern avoidance problem, where $\pi(x_1, \dots, x_n) = x_1$ is a projection map from $\RR^{dn}$ to $\RR^d$. The case $\alpha = dn$ is trivial as well, since we can set $X = \emptyset$.

	%And given only a lower Minkowski dimension bound on the sets which form $Z$, we cannot do any better than a zero dimensional set since it is possible for $Z$ to be $\RR^{dn}$, in which case solutions to the pattern avoidance problem can consist of at most $n-1$ points.
\end{remark}

% DISCUSS: Without mentioning why this result can only be developed because our method can be applied to very rough sets, the application doesn't seem exciting at all.

When $Z$ is a countable union of smooth manifolds, Theorem \ref{mainTheorem} generalizes Theorem 1.1 and 1.2 from \cite{MalabikaRob}. Section \ref{futureWorkSection} is devoted to a comparison of our methods with \cite{MalabikaRob}, as well as other general pattern avoidance methods. But our result is more interesting when it can be applied to truly `rough' sets. One surprising application to our method is obtained by considering a `rough' set $Y$ in addition to a set $Z$, and finding a set $X \subset Y$ of large dimension avoiding $Z$. Previous methods in the literature fundamentally exploit the ability to select points on the entirety of Euclidean space, and so it remains unlikely that we can obtain any result of this form using their methods, unless $Y$ is suitably flat, i.e. a smooth surface. To contrast this, our result even applies for certain sets $Y$ which are of Cantor type. We discuss applications of our result in Section 5.

Theorem \ref{mainTheorem} is proved using a Cantor-type construction, a common theme in the surrounding literature, described explicitly in Section \ref{discretizationsection}. For a sequence of decreasing lengths $\{ l_n \}$ with $l_n \to 0$, the construction specifies a selection mechanism for a nested family of sets $X_n \to X$, with $X_n$ a union of sidelength $l_n$ cubes and avoiding $Z$ at scales close to $l_n$. Our {\it key} contribution to this process is using the probabilistic method to guarantee the existence of efficient selections at each scale, described in Section 2. This selection also assigns mass uniformly on intermediate scales, akin to \cite{MalabikaRob}, ensuring that the selection procedure at a single scale is the sole reason for the Hausdorff dimension we calculate in Section 4. Furthermore, the randomization allows us to avoid the complicated queueing techniques in \cite{KeletiDimOneSet} and \cite{MalabikaRob}, which has the additional benefit that we can confront the entire behaviour of $Z$ at scales close to $l_n$ simultaneously during the $n$th step of the construction.










\section{Frequently Used Notation and Terminology}\label{notationSection}

Our argument heavily depends upon discretizing sets into unions of cubes. Throughout our argument, we use the following notation:

% DISCUSS: DOES THE SECTION PARTITIONING HELP?

\begin{enumerate}%[label=\Alph*]
	\item A {\it dyadic length} is a length $l$ equal to $2^{-k}$ for some non-negative integer $k$.

	\item Given a length $l > 0$, we let $\B^d_l$  denote the family of all half open cubes in $\RR^d$ with sidelength $l$ and corners on the lattice $(l \cdot \ZZ)^d$. That is,
	%
	\[ \B^d_l = \{ [a_1, a_1 + l] \times \cdots \times [a_d, a_d+l] : a_k \in l \cdot \ZZ \}. \]
	%
	If $E \subset \RR^d$, $\B^d_l(E)$ is the family of cubes in $\B^d_l$ intersecting $E$, i.e.
	%
	\[ \B^d_l(E) = \{ I \in \B^d_l: I \cap E = \emptyset \}. \]

	\item The {\it lower} and {\it upper Minkowski dimension} of a compact set $Z \subset \RR^d$ are defined as
	%
	%	\begin{equation} \label{minkdimdef}
	\[		\lowminkdim(Z) = \liminf_{l \to 0} \frac{\log(\# \B^d_l(Z))}{\log(1/l)}\quad \text{and}\quad \upminkdim(Z) = \limsup_{l \to 0} \frac{\log(\# \B^d_l(Z))}{\log(1/l)}. \]
	%	\end{equation}
	If $\lowminkdim(Z) = \upminkdim(Z)$, then we define $\minkdim(Z)$ equal to the common value.

	\item If $0 \leq \alpha$ and $\delta > 0$, we define the dyadic Hausdorff content of a set $E\subset\RR^d$ as 
		%
	\[ H^\alpha_\delta(E) = \inf \left\{ \sum_{k = 1}^m l_k^\alpha : E \subset \bigcup_{k = 1}^m I_k\ \text{and}\ I_k \in \B^d_{l_k}, l_k \leq \delta\ \text{for all $k$} \right\}. \]
	%
	The $\alpha$-dimensional dyadic Hausdorff measure $H^\alpha$ on $\RR^d$ is $H^\alpha(E) = \lim_{\delta \to 0} H_\delta^\alpha(E)$, and the {\it Hausdorff dimension} of a set $E$ is $\hausdim(E) = \inf \{ \alpha \geq 0 : H^\alpha(E) = 0 \}$.
\suspend{enumerate}
%
%In Section 2, we solve a discrete version of Theorem \ref{mainTheorem}. Non-diagonal cubes will play an important role in this process. 
%
\resume{enumerate}
	\item \label{stronglyNonDiagonalDef}Given $I \in \B^{dn}_l$, we can decompose $I$ as $I_1 \times \cdots \times I_n$ for unique cubes $I_1, \dots, I_n \in \B_l^d$. We say $I$ is {\it strongly non-diagonal} if the cubes $I_1, \dots, I_n$ are distinct. Strongly non-diagonal cubes will play an important role in Section \ref{discretesection}, when we solve a discrete version of Theorem \ref{mainTheorem}.
\suspend{enumerate}
%
%In Section 3, we discretize the set $Z$ in the hypothesis of Theorem \ref{mainTheorem} into a union of boxes. Our argument is aided by the following definitions:
%
\resume{enumerate}
	\item\label{strongCoverDefn} Adopting the terminology of \cite{KatzTao}, we say a collection of sets $\{ U_k \}$ is a {\it strong cover} of a set $E$ if $E \subset \limsup U_k$, which means every element of $E$ is contained in infinitely many of the sets $U_k$. This idea will be useful in Section \ref{discretizationsection}.  
\suspend{enumerate}
%
%Once $X$ has been constructed, in Section 4 we show it has the Hausdorff dimension required by Theorem \ref{mainTheorem}. Here we use a Frostman's lemma type approach.
%
\resume{enumerate}
	\item\label{frostmanItem} A {\it Frostman measure} of dimension $\alpha$ is a non-zero compactly supported probability measure $\mu$ on $\RR^d$ such that for every cube $I$ of sidelength $l$, $\mu(I) \lesssim l^\alpha$. Note that a measure $\mu$ satisfies this inequality for every cube $I$ if and only if it satisfies the inequality for cubes whose sidelengths are dyadic lengths. {\it Frostman's lemma} says that
	%
	\[ \hausdim(E) = \sup \left\{ \alpha: \begin{array}{c} \text{there is an}\ \alpha\ \text{dimensional Frostman}\\
	\text{measure supported on $E$} \end{array} \right\}. \]
\end{enumerate}









\section{Avoidance at Discrete Scales}\label{discretesection}

In this section we describe a method for avoiding $Z$ at a single scale. We apply this technique in Section \ref{discretizationsection} at many scales to construct a set $X$ avoiding $Z$ at all scales. This single scale avoidance technique is the core part of our construction, and the efficiency with which we can avoid $Z$ at a single scale has direct consequences on the Hausdorff dimension of the set $X$ obtained in Theorem \ref{mainTheorem}.

At a single scale, we solve a discretized version of the problem, where all sets are unions of cubes at two dyadic lengths $l \geq s$. In the discrete setting, $Z$ is replaced by a discretization version of itself, i.e. a union of cubes in $\B^{dn}_s$, denoted by $Z_s$. Given a set $E$, which is a union of cubes in $\B_l^d$, our goal is to construct a a union of cubes in $\B_s^d$, denoted $F$, such that $F \subset E$ and $F^n$ is disjoint from the strongly non-diagonal cubes of $Z_s$ (see Definition \ref{stronglyNonDiagonalDef}).

% DISCUSS: The double parentehesis in the `see definition' annoys me for some reason.

In order to ensure the final set $X$ obtained in Theorem \ref{mainTheorem} has large Hausdorff dimension regardless of the rapid decay of scales used in the construction of $X$, it is crucial that $F$ is spread uniformly over $E$. We achieve this by decomposing $E$ into sub-cubes in $\B_r^d$ for some intermediate scale $r \in [s,l]$, and distributing $F$ evenly among as many of these intermediate sub-cubes as possible. Assuming a mild regularity condition on the volume of $Z_s$, this is possible.

\begin{lemma} \label{discretelemma}
	Fix two dyadic lengths $l \geq s$. Let $E$ be a nonempty union of cubes in $\B^d_l$, and let $Z_s$ be a union of cubes in $\B^d_s$ such that $|Z_s| \leq l^{dn}/2$. Then there exists a dyadic length $r \in [s,l]$ such that
	%
	\begin{equation} \label{rBound}
		A_l |Z_s|^{1/d(n-1)} \leq r \leq \max(s, 2 A_l |Z_s|^{1/d(n-1)})\quad \text{where}\quad A_l = (2^{1/d}/l)^{1/(n-1)}.
	\end{equation}
	%
	For this scale, there exists a set $F \subset E$, which is a nonempty union of cubes in $\B^d_s$, satisfying the following three properties:
	%
	\begin{enumerate}
		\item\label{avoidanceItem} \emph{Avoidance}: For any distinct $J_1, \dots, J_n \in \B^d_s(F)$, $J_1 \times \dots \times J_n \not \in \B_s^{dn}(Z_s)$.
		\item\label{nonConcentrationItem} \emph{Non-Concentration}: For any $I \in \B_r^d(E)$, there is at most one $J \in \B_s^d(F)$ with $J \subset I$.
		\item\label{largeSizeItem} \emph{Large Size}: For any $I \in \B^d_l(E)$, $\# \B^d_s(F \cap I) \geq \# \B^d_r(I) / 2 = (l/r)^d / 2$.
	\end{enumerate}
	%
	In other words, $F$ avoids strongly non-diagonal cubes in $Z_s$, and contains a single sidelength $s$ portion of more than half of the sidelength $r$ cubes contained in any sidelength $l$ cube in $E$.
\end{lemma}
\begin{proof}
	Let $r$ be the smallest dyadic length larger than than $s$ and $A_l |Z_s|^{1/d(n-1)}$, so that \eqref{rBound} is satisfied. The assumption that $|Z_s| \leq l^{dn}/2$ implies
	%
	\[ A_l |Z_s|^{1/d(n-1)} \leq A_l l^{n/(n-1)} / 2^{1/d(n-1)} = l. \]
	%
	Thus we have gauranteed that $r \in [s,l]$. For each $I \in B_r^d(E)$, let $J_I$ be a random element of $\B^d_s(I)$ chosen uniformly at random, independantly from the other random variables $J_{I'}$ with $I \neq I'$. Define a random set
	%
	%\begin{equation} \label{Udefinition}
	\[ 	U = \bigcup \{ J_I : I \in \B^d_s(I) \}, \]
	%\end{equation}
	%
	and for each $U$, set
	%
	\[ \mathcal{K}(U) = \{ K \in \B^{dn}_s(Z_s) : K \in U^n, \text{$K$ strongly non-diagonal} \} \]
	%
	Then set
	%
	\begin{equation} \label{defnOfF}
		F_U = U - \{ \pi(K): K \in \mathcal{K}(U), K\ \text{is strongly diagonal} \},
	\end{equation}
	%
	where $\pi: \RR^{dn} \to \RR^d$ maps $K_1 \times \dots \times K_n$ to $K_1$ for each $K_i \in \RR^d$. Given any strongly non-diagonal cube $J_1 \times \cdots \times J_n \in \B_s^{dn}(Z_s)$, either $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(U^n)$, or $J_1 \times \cdots \times J_n \in \B_s^{dn}(U^n)$. If the former occurs then $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(F_U^n)$ since $F_U \subset U$, while if the latter occurs then $K \in \mathcal{K}(U)$, so $J_1 \not \in \B_s^d(F_U)$. In either case, $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(F_U^n)$, so $F_U$ satisfies Property \ref{avoidanceItem}. By construction, $U$ contains at most one subcube $J \in \B^{dn}_s$ for each $I \in \B^{dn}_l(E)$. Since $F_U \subset U$, $F_U$ satisfies Property \ref{nonConcentrationItem}. These properties are satisfied for any instance of $U$, but it is not true that Property \ref{largeSizeItem} holds for each $F_U$. The remainder of this proof is devoted to showing this property holds for $F_U$ with non-zero probability, guaranteeing the existence of the required set $F$ satisfying the properties of the lemma.

	For each cube $J \in \B_s^d(E)$, there is a unique `parent' cube $I \in \B_r^d(E)$ such that $J \subset I$. Since $I$ contains $(r/s)^d$ elements of $\B^d_s(E)$, and $J_I$ is chosen uniformly at random from $\B^d_s(I)$,
	%
%	\begin{equation} \label{singleCubeProb}
	\[ \Prob(J \subset U) = \Prob(J_I = J) = (s/r)^d. \]
%	\end{equation}
	%
	%Here the probability measure $\Prob(\cdot)$ is taken with respect to the randomly chosen set $U$ defined in \eqref{Udefinition}.
	The cubes $J_I$ are chosen independantly, so if $J_1, \dots, J_k$ are distinct cubes in $\B^d_s(E)$, then the last calculation combined with Property \ref{nonConcentrationItem} shows that
	%
%	\begin{equation}\label{jointprob}
\[ 		\Prob(J_1, \dots, J_k \in U) = \begin{cases} (s/r)^{dk} &: \text{if $J_1, \dots, J_k$ have distinct parents} \\ 0 &: \text{otherwise} \end{cases} \]
%	\end{equation}
	%
	Let $K = J_1 \times \dots \times J_n \in \B^{dn}_s(Z_s)$ be a strongly non-diagonal cube. Then cubes $J_1, \dots, J_n$ are distinct, so the calculation we just performed implies
	%
	%\begin{equation}\label{probaKSubsetUn}
	\[	\Prob(K \subset U^n) = \Prob(J_1, \dots, J_k \in U) \leq (s/r)^{dn}. \]
	%\end{equation}
	%
	Together with linearity of expectation, and $\eqref{rBound}$, if $K$ ranges over the strongly non-diagonal cubes of $\B^{dn}_s(Z_s)$, we find
	%
%	\begin{equation}\label{expectedNumberOfCubes}
	\begin{align*}
		\Expect(\# \mathcal{K}(U)) &= \sum_K \Prob(K \subset U^n) \leq \# \B_s^{dn}(Z_s) \cdot (s/r)^{dn} = |Z_s| r^{-dn}\\
		&= \left[ |Z_s| r^{-d(n-1)} \right] r^{-d} \leq \left[ |Z_s| (A_l |Z_s|^{1/d(n-1)})^{-d(n-1)} \right] r^{-d} = \left[ l^d/2 \right] r^{-d} = (l/r)^d /2.
	\end{align*}
	%	\end{equation}
	%
%	On the other hand, if $A_l |Z_s|^{1/d(n-1)} \leq s$, $|Z_s| \leq s^{d(n-1)} / A_l^{d(n-1)}$, then
	%
%	\[ \Expect(\# \mathcal{K}(U)) \leq |Z_s| r^{-dn} \leq s^{d(n-1)} r^{-dn} / (2/l^d) = (l/r)^d/2 \cdot (s/r)^{d(n-1)} \leq (l/r)^d/2 \]
	%
	Thus there exists at least one (non-random) set $U_0$ such that
	%
	\begin{equation}\label{KU0Small}
		\# \mathcal{K}(U_0) \leq \Expect(\# \mathcal{K}(U)) \leq (l/r)^d/2.
	\end{equation}
	%
	This means that the resultant set $F_{U_0}$ is obtained by removing at most $(l/r)^d/2$ cubes in $\B^d_s$ from $U_0$. Since $U_0$ contains $(l/r)^d$ cubes in $\B^d_s(I)$ for each $I \in \B^d_l(E)$, $F_{U_0}$ contains at least $(l/r)^d/2$ cubes in $\B^d_s(I)$ for each $I \in \B^d_l(E)$, so $F_{U_0}$ satisfies Property \ref{largeSizeItem}. Setting $F = F_{U_0}$ completes the proof.
\end{proof}

\begin{remark}
	While the existence of the set $F$ in Lemma \ref{discretelemma} was obtained by probabilistic techniques, we emphasize that it's existence is a purely deterministic statement. One can find a candidate $F$ constructively by checking all of the finitely many possible choice of $U$ to find one particular choice $U_0$ which satisfies $\eqref{KU0Small}$, and then defining $F$ by \eqref{defnOfF}.
	%The advantage of the probabilistic argument is that we are able to find an explicit bound for the minimal cardinality of $\mathcal{K}(U)$. 
	Thus the set we obtain in Theorem \ref{mainTheorem} exists by purely constructive means.
\end{remark}

Our inability to select almost every cube in Lemma \ref{discretelemma} means that repeated applications of the result will lead to a loss in Hausdorff dimension. In fact, in the worst case, applying the lemma causes us to lose as much Hausdorff dimension as is permitted by Theorem 1. Note that the value $r$ specified in Theorem \ref{discretelemma} is always bounded below by $|Z_s|$. We will later see that if $Z$ is the countable union of sets with lower Minkowski dimension $\alpha$, the scale $s$ discretization $Z_s$ satisfies $|Z_s| \leq s^{dn - \alpha - \varepsilon}$, for some small positive $\varepsilon$ converging to zero as $s \to 0$. But we can certainly find sets $Z$ with lower Minkowski dimension $\alpha$ satisfying $|Z_s| \geq s^{dn - \alpha}$ for all $s$. In this situation, \eqref{rBound} shows
%
\begin{equation} \label{rWorstCase}
	r \geq A_l |Z_s|^{1/d(n-1)} \geq A_l s^{(dn - \alpha)/d(n-1)} \geq s^{(dn - \alpha)/d(n-1)}
\end{equation}
%
If we combine this inequality with Property \ref{nonConcentrationItem} of Lemma \ref{discretelemma}, we conclude
%
%\begin{equation} \label{boxCountingBound}
\[	\frac{\log \# \B^d_s(F)}{\log(1/s)} \leq \frac{\log \# \B^d_r(E)}{\log(1/s)} = \frac{\log |E| r^{-d}}{\log(1/s)} = \frac{d \log(1/r) - \log |E|^{-1}}{\log(1/s)} \leq \frac{dn - \alpha}{n - 1}. \]
%\end{equation}
%
Given a set $F = \bigcap F_k$, where $\{ F_k \}$ are infinitely many sets obtained from an application of Lemma \ref{discretelemma} at a sequence of scales $\{ s_k \}$ with $s_k \to 0$ as $k \to \infty$, and where $|Z_{s_k}| \geq s_k^{dn - \alpha}$, then the last computation shows% \eqref{boxCountingBound} shows
%
%\begin{equation} \label{badDimension}
\[	\hausdim(F) \leq \upminkdim(F) \leq \lim_{s_k \to 0} \frac{\log \# \B^d_{s_k}(F_k)}{\log(1/s_k)} \leq \frac{dn - \alpha}{n-1}. \]
%\end{equation}
%
This is why we can only lower the Hausdorff dimension of the set $X$ obtained in Theorem \ref{mainTheorem} by $(dn - \alpha)/(n-1)$. Furthermore, we see that we must be very careful to ensure applications of the discrete lemma are the only place in our proof where dimension is lost.

\begin{remark}
	Lemma \ref{discretelemma} is the core method in our avoidance technique. The remaining argument is fairly modular. If, for a special case of $Z$, one can improve the result of Lemma \ref{discretelemma} so that $r$ is chosen on the order of $s^{\beta/d}$, then the remaining parts of our paper can be applied near verbatim to yield a set $X$ with Hausdorff dimension $\beta$, as in Theorem \ref{mainTheorem}. The last paragraph shows that when $|Z_s| \geq s^{dn - \alpha}$, which is certainly possible given the hypothesis of Theorem \ref{discretelemma}, the length $r$ is chosen on the order of $s^{(dn-\alpha)/d(n-1)}$, as we saw in \eqref{rWorstCase}, which is why we obtain a Hausdorff dimension $(dn - \alpha)/(n-1)$ set.
\end{remark}










\section{Fractal Discretization}\label{discretizationsection}
In this section we will construct the set $X$ by applying Lemma \ref{discretelemma} at many scales. Since $Z$ is a countable union of compact sets with Minkowski dimension at most $\alpha$, there exists a strong cover (see Definition \ref{strongCoverDefn}) of $Z$ by cubes restricted to a sequence of dyadic lengths $\{ l_k \}$. We will select this strong cover so that the scales $l_k$ converge to 0 very quickly.

\begin{lemma} \label{coveringlemma}
	Let $Z \subset \RR^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Let $\{ \varepsilon_k \}$ be a sequence of positive numbers and let $\{ f_k \}$ be a sequence of functions such that $f_k \colon (0,\infty) \to (0,\infty)$. Then there exists a sequence of dyadic lengths $\{ l_k \}$ and compact sets $\{ Z_k \}$ such that
	%
	\begin{enumerate}
		\item For each index $k \geq 2$, $l_k \leq f_{k-1}(l_{k-1})$.
		\item For each index $k$, $Z_k$ is a union of cubes in $\B^{dn}_{l_k}$.
		\item $Z$ is strongly covered by the sets $\{ Z_k \}$.
		\item For each index $k$, $\# \B^{dn}_{l_k}(Z_k) \leq (1/l_k)^{\alpha + \varepsilon_k}$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	Let $Z$ be the union of sets $\{ Y_k \}$ with $\lowminkdim(Y_k) \leq \alpha$ for any $k$. Let $m_1, m_2, \dots$ be a sequence of integers that repeats each integer infinitely often. For each positive integer $k$, since $\lowminkdim(Y_{m_k}) \leq \alpha$, definition (C) implies that there exists arbitrarily small lengths $l$ which satisfy $\# \B_l^{dn}(Y_{m_k}) \leq 1/l^{\alpha + (\varepsilon_k/2)}$. Replacing $l$ with a dyadic length at most twice the size of $l$, there are infinitely many {\it dyadic} scales $l$ with
	%
	%\begin{equation} \label{minkdimimplication}
	\[	\# \B^{dn}_l(Y_{m_k}) \leq \frac{1}{(l/2)^{\alpha + \varepsilon_k}} \leq \frac{2^{dn}}{l^{\alpha + (\varepsilon_k/2)}} = \frac{\left( 2^{dn} l^{\varepsilon_k/2} \right)}{l^{\alpha + \varepsilon_k}}. \]
	%\end{equation}
	%
	In particular, we may select a dyadic length $l$ such that $2^{dn} l^{\varepsilon_k/2} \leq 1$, and, if $k \geq 2$, also satisfying $l \leq f_{k-1}(l_{k-1})$. The first constraint together with the last calculation implies $\# \B^{dn}_l(Y_{m_k}) \leq 1/l^{\alpha + \varepsilon_k}$. We then set $l_k = l$, and define $Z_k$ to be the union of all cubes in $\B_{l_k}^{dn}(Y_{m_k})$.
\end{proof}

We now construct $X$ by avoiding the various discretizations of $Z$ at each scale. The aim is to find a nested decreasing family of discretized sets $\{ X_k \}$ with $X = \bigcap X_k$. One condition guaranteeing that $X$ avoids $Z$ is that $X_k^n$ is disjoint from {\it strongly non-diagonal} cubes in $Z_k$.

\begin{lemma} \label{stronglydiagonal}
	Let $Z \subset \RR^{dn}$ and let $\{ l_k \}$ be a sequence of lengths converging to zero. For each index $k$, let $Z_k$ be a union of cubes in $\B^{dn}_{l_k}$, and suppose the sets $\{ Z_k \}$ strongly cover $Z$. For each index $k$, let $X_k$ be a union of cubes in $\B^d_{l_k}$. Suppose that for any $k$, $X_k^n$ avoids strongly non-diagonal cubes in $Z_k$. If $X = \bigcap X_k$, then $(x_1, \dots, x_n) \not \in Z$ for any distinct $x_1, \dots, x_n \in X$.
\end{lemma}
\begin{proof}
	Let $z \in Z$ be a point with distinct coordinates $z_1, \dots, z_n$. Set
	%
	\[ \Delta = \{ (w_1, \dots, w_n) \in \RR^{dn}: \text{there exists $i \neq j$ such that $w_i = w_j$} \}. \]
	%
	Then $d(\Delta,z) > 0$, where $d$ is the Hausdorff distance between $\Delta$ and $z$. Since $\{ Z_k \}$ strongly covers $Z$, there is a subsequence $\{ k_m \}$ such that $z \in Z_{k_m}$ for any index $m$. For suitably large $m$, the sidelength $l_k$ cube $I$ in $Z_{k_m}$ containing $z$ is disjoint from $\Delta$. But this means $I$ is strongly non-diagonal, and so $z \not \in X_{k_m}^n$. In particular, $z$ is not an element of $X^n$.
\end{proof}

We are now ready to construct the set $X$ in Theorem \ref{mainTheorem}. Let $l_0 = 1$ and $X_0 = [0,1)^d$. For each $k \geq 1$, define $\varepsilon_k = c_0/k$, where we view $c_0 = (dn - \alpha)/4$ as a irrelevant constant small enough that $dn - \alpha - 2\varepsilon_k > 0$ for any $k$. We set
%
%\begin{equation}\label{defnFK}
\[	f_k(x) = \min \left( x^{k^2}, (x^{dn}/2)^{1/(dn - \alpha - \varepsilon_{k+1})}, (1/2A_x)^{d(n-1)/\varepsilon_{k+1}} \right). \]
%	f_k(x)=\min \left( x^{k^2}, (x^d4^{-k-1})^{\frac{1}{\varepsilon_{k+1}d(n-1)}} \right).
%\end{equation}
%
Apply Lemma \ref{coveringlemma} to $Z$ with this choice of $\{\varepsilon_k\}$ and $\{ f_k \}$; let $\{ l_k \}$ be the resulting sequence of dyadic lengths and let $\{Z_k\}$ be the resulting strong cover of $Z$. Observe that the definition of $f_k$ implies that for any index $k$,
%
\begin{equation} \label{boundOnLk}
	\quad l_{k+1} \leq l_k^{k^2}, \quad l_{k+1}^{dn - \alpha - \varepsilon_{k+1}} \leq l_k^{dn}/2, \quad \text{and} \quad 2A_{l_k} l_{k+1}^{\varepsilon_{k+1}/d(n-1)} \leq 1.
\end{equation}
%
For each index $k \geq 1$, define $l = l_k$ and $s = l_{k+1}$. Observe that $X_k$ is a non-empty union of cubes in $\B^d_l$; that $Z_{k+1}$ is a union of cubes in $\B^{dn}_s$, and that \eqref{boundOnLk} implies
%
\[ |Z_{k+1}| \leq l_{k+1}^{dn - \alpha - \varepsilon_{k+1}} \leq l_k^{dn}/2 = l^{dn}/2. \]
%
Setting $Z_s = Z_{k+1}$, we are therefore justified in applying Lemma \ref{discretelemma}. This produces a dyadic length $r$, which we denote by $r_{k+1}$. Assuming
%\footnote{We remark that this is the only time in our argument where we need to assume $\alpha \geq d$. If $\alpha < d$, then we cannot remove the maxima in the calculation directly following this footnote, which complicates the calculations later on in the argument. It isn't worth it to extend the remainder of the argument to this case since it is trivial to obtain a full dimensional set in this setting, as remarked directly after the statement of Theorem \ref{discretelemma}.}
$\alpha \geq d$, by \eqref{rBound} and \eqref{boundOnLk}, we find
%
\begin{equation} \label{rKBound}
\begin{aligned}
	r_{k+1} &\leq \max \left(l_{k+1}, 2 A_{l_k} |Z_{k+1}|^{1/d(n-1)} \right) \leq \max \left(l_{k+1}, 2 A_{l_k} l_{k+1}^{(dn - \alpha - \varepsilon_{k+1})/d(n-1)} \right)\\
	&\leq \max \left(l_{k+1}, l_{k+1}^{(dn - \alpha - 2\varepsilon_{k+1})/d(n-1)} \right) = l_{k+1}^{(dn - \alpha - 2\varepsilon_{k+1})/d(n-1)}.
\end{aligned}
\end{equation}
%
For this choice of $r$, we obtain a set $F \subset X_k$ which is a union of cubes in $\B^d_s(E)$ satisfying Properties \ref{avoidanceItem}, \ref{nonConcentrationItem}, and \ref{largeSizeItem} from the lemma, and we define $X_{k+1} = F$. Property \ref{avoidanceItem} implies $X_{k+1}$ avoids strongly non-diagonal cubes in $Z_{k+1}$, so if we define $X = \bigcap X_k$, then Lemma \ref{stronglydiagonal} implies $(x_1, \dots, x_n) \not \in Z$ for any distinct $x_1, \dots, x_n \in X$.

\begin{lemma}
	\[ \upminkdim(X) \geq \frac{dn - \alpha}{n - 1} \]
\end{lemma}
\begin{proof}
	Consider $X$ as the limit of the sequence $\{ X_k \}$. Since every cube in $\B^d_{l_{k+1}}(X_{k+1})$ intersects $X$, $\B^d_{l_{k+1}}(X_{k+1}) = \B^d_{l_{k+1}}(X)$. And so by Property \ref{largeSizeItem} of Lemma \ref{discretelemma}, \eqref{boundOnLk}, and \eqref{rKBound}, we conclude
	%
	\begin{align*}
		\frac{\log(\# \B^d_{l_{k+1}}(X))}{\log(1/l_{k+1})} &= \frac{\log(\# \B^d_{l_{k+1}}(X_{k+1}))}{\log(1/l_{k+1})} \geq \frac{\log((l_k/r_{k+1})^d \cdot \# \B^d_{l_k}(X_k))}{\log(1/l_{k+1})}\\
		&= \frac{d \log(1/r_{k+1})}{\log(1/l_{k+1})} - \frac{d \log(1/l_k)}{\log(1/l_{k+1})}\\
		&\geq \frac{d \log \left(1/l_{k+1}^{(dn - \alpha - 2\varepsilon_{k+1})/d(n-1)} \right)}{\log(1/l_{k+1})} - \frac{d \log(1/l_k)}{\log(1/l_k^{k^2})}\\
		&= \frac{dn - \alpha - 2\varepsilon_{k+1}}{n-1} - \frac{d}{k^2}\\
		&= \frac{dn - \alpha}{n-1} - o(1)
	\end{align*}
	%
	Taking $k \to \infty$, we conclude $\upminkdim(X) \geq (dn - \alpha)/(n-1)$.
\end{proof}







\section{Dimension Bounds}\label{dimensionsection}

To complete the proof of Theorem \ref{mainTheorem}, we must show that $\dim_{\mathbf{H}}(X) \geq \beta$, where
%
\[ \beta = \frac{dn - \alpha}{n - 1}. \]
%
We begin with a rough outline of our proof strategy. Recall that from the previous section, we have a decreasing sequence of lengths $\{ l_k \}$. The most convenient way to examine the dimension of $X$ at various scales is to use Frostman's lemma (see Definition \ref{frostmanItem}). We construct a probability measure $\mu$ supported on $X$ such that for all $\varepsilon > 0$, for all dyadic lengths $l$, and for all $I \in \B^d_l$, $\mu(I) \lesssim_\varepsilon l^{\beta - \varepsilon}$. We begin by proving the bound $\mu(I) \lesssim l_k^{\beta - O(1/k)}$ when $I \in \B^d_{l_k}$, which we view as saying $X$ looks like a set with dimension $\beta - O(1/k)$ at the lengths $\{ l_k \}$. To obtain the complete dimension bound, it then suffices to interpolate to get an acceptable bound at all intermediate scales. In this construction, as in \cite{MalabikaRob}, the rapid decay of the lengths $\{ l_k \}$ forced on us in the construction means interpolation poses a significant difficulty. We avoid this difficulty because of the uniform way that we have selected cubes in consecutive scales. This will imply that between the scales $l_k$ and $r_{k+1}$, the mass of $\mu$ distributes with similar properties to the full dimensional Lebesgue measure, which makes interpolation easy.

We now define the measure $\mu$, by first defining it as a premeasure on $\bigcup_{i = 1}^\infty \B^d_{l_i}[0,1)^d$. We initially set $\mu([0,1)^d) = 1$. Given $I \in \B^d_{l_k}$, we find a parent cube $I' \in \B^d_{l_{k-1}}$ with $I \subset I'$. If $I \subset X_k$, then we set
%
\begin{equation} \label{muRecurse} \mu(I) = \frac{\mu(I')}{\# \B^d_{l_k}(X_k \cap I')}. \end{equation}
%
Otherwise, if $I \not \subset X_k$, we set $\mu(I) = 0$. Notice
%
\[ \mu(I') = \sum_{I \in \B^d_{l_k}(X_k \cap I')} \frac{\mu(I')}{\# \B^d_{l_k}(X_k \cap I')} = \sum_{I \in \B^d_{l_k}(I')} \mu(I). \]
%
Thus mass is maintained at each stage of the construction, and then Proposition 1.7 of \cite{Falconer} implies $\mu$ is a premeasure, and thus extends to a measure on the entire Borel sigma algebra. The remainder of this section is devoted to showing that $\mu$ is a Frostman measure of dimension $\beta - \varepsilon$ for any $\varepsilon > 0$.

% General principle:
% Let Q_k be all dyadic cubes of sidelength 1/2^k.
% For each mu, define E_k(mu) = sum_{Q in Q_k} mu(Q)/2^k * (Lebesgue measure restricted to Q).
% Then |E_k(\mu)| <= |mu|, so E_k is a continuous operator on finite Borel measures.
% Given mu_1, mu_2, ... in M[0,1] such that E_i(f_j) = f_i, for i < j,
% let mu be a weak * limit of the mu_i.
% The E_i are continuous on weak *, so E_i(mu) = mu_i for all i.

\begin{lemma} \label{muBoundLemma}
	If $I \in \B^d_{l_k}$, then
	%
	\begin{equation} \label{muBound}
		\mu(I) \leq 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d.
	\end{equation}
\end{lemma}
\begin{proof}
	We prove the theorem inductively on $k$. For $k = 0$, the theorem is obvious, because $\mu(I) \leq 1$. For the purposes of induction, let $I \in \B^d_{l_k}$, together with a parent cube $I' \in \B^d_{l_{k-1}}$ with $I \subset I'$. If $\mu(I) > 0$, $I \subset X_k$, so $I' \subset X_{k-1}$. Because $X_k$ was obtained from $X_{k-1}$ via an application of Lemma 1, Property \ref{largeSizeItem} of that lemma states that $\# \B^d_{l_k}(X_k \cap I) \geq (l_{k-1}/r_k)^d/2$, so together with the inductive hypothesis and \eqref{muRecurse}, we conclude
	%
	%	\begin{equation} \label{oneStepBound}
	\[ \mu(I) = \frac{\mu(I')}{\# \B^d_{l_k}(X_k \cap I)} \leq \frac{\mu(I')}{(l_{k-1}/r_k)^d/2} \leq \frac{2^{k-1} \cdot \left[ \frac{r_{k-1} \dots r_1}{l_{k-2} \dots l_1} \right]^d}{(l_{k-1}/r_k)^d/2} = 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d. \qedhere \]
\end{proof}

Treating all parameters in \eqref{muBound} which depend on indices smaller than $k$ as essentially constant, and using \eqref{rKBound}, we `conclude' that
%
\[ \mu(I) \lesssim r_k^d \lesssim l_k^{\beta - 2 \cdot \varepsilon_k / (n-1)} = l_k^{\beta - O(1/k)}. \]
%
The bounds in \eqref{boundOnLk} imply $l_k$ decays very rapidly, which enables us to ignore quantities depending on previous indices, and obtain a true inequality.

\begin{corollary}
	There exists $c > 0$ such that for all $I \in \B^d_{l_k}$, $\mu(I) \lesssim l_k^{\beta - c/k}$.
\end{corollary}
\begin{proof}
	Given $\varepsilon > 0$, Lemma \ref{muBoundLemma}, Equation \eqref{rKBound}, the inequality $l_k \leq l_{k-1}^{(k-1)^2}$ from \eqref{boundOnLk}, and the fact that there exists a constant $c_0$ such that $\varepsilon_{k+1} = c_0/k$, we find
	%
	\begin{align*}
		\mu(I) &\leq 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d \leq \left( \frac{2^k}{l_{k-1}^d \dots l_1^d} \right) l_k^{\beta - \varepsilon_k / (n-1)} = \left( \frac{2^k l_k^{2d/k}}{l_{k-1}^{d(k-1)}} \right) l_k^{\beta - \varepsilon_k/(n-1) - 2d/k}\\
		&\leq \left( 2^k l_{k-1}^{(2d/k)(k-1)^2 - d(k-1)} \right) l_k^{\beta - (c_0/(n-1) + 2d)/k} = o \left(l_k^{\beta - (c_0/(n-1) + 2d)/k} \right), %\tag*{\qedhere}
	\end{align*}
	%
	so we can then set $c = c_0/(n-1) + 2d$.
\end{proof}

Corollary 3 gives a clean expression of the $\beta$ dimensional behaviour of $\mu$ at discrete scales. To obtain a Frostman measure bound at {\it all} scales, we need to apply a covering argument. This is where the uniform mass assignment technique comes into play. Because $\mu$ behaves like a full dimensional set between the scales $l_k$ and $r_{k+1}$, we won't be penalized for making the gap between $l_k$ and $r_{k+1}$ arbitrarily large. This is essential to our argument, because $l_k$ decays faster than $2^{-k^m}$ for any $m > 0$.

\begin{lemma} \label{frostmanBound}
	If $l$ is dyadic and $I \in \B_l^d$, then $\mu(I) \lesssim_k l^{\beta - c/k}$ for each integer $k$.
\end{lemma}
\begin{proof}
	We begin by assuming $l \leq l_k$. To bound $\mu(I)$, we apply a covering argument, which breaks into cases depending on the size of $l$ in proportion to the scales $l_k$ and $r_k$:
	%
	\begin{itemize}
		\item If $r_{k+1} \leq l \leq l_k$, we can cover $I$ by $(l/r_{k+1})^d$ cubes in $\B^d_{r_{k+1}}$. Because of Property \ref{nonConcentrationItem} and \ref{largeSizeItem} of Lemma \ref{discretelemma}, we know that the mass of each cube in $\B^d_{r_{k+1}}$ is bounded by at most $2 (r_{k+1}/l_{k+1})^d$ times the mass of a cube in $\B_{l_k}^d$. Thus
		%
		\[ \mu(I) \lesssim (l/r_{k+1})^d (2(r_{k+1}/l_k)^d) l_k^{\beta - c/k} \leq 2l^d/l_k^{d - \beta + c/k} \leq 2l^{\beta - c/k}, \]
		%
		where we used the fact that $d - \beta + c/k \geq 0$, so $l_k^{d - \beta + c/k} \geq l^{d - \beta + c/k}$.

		\item If $l_{k+1} \leq l \leq r_{k+1}$, we can cover $I$ by a single cube in $\B^d_{r_{k+1}}$. Because of Property \ref{nonConcentrationItem} of Lemma \ref{discretelemma}, each cube in $\B^d_{r_{k+1}}$ contains at most one cube of $\B^d_{l_{k+1}}(X_{k+1})$, so
		%
		\[ \mu(I) \lesssim l_{k+1}^{\beta - c/k} \leq l^{\beta - c/k}. \]

		\item If $l \leq l_{k+1}$, there certainly exists $m$ such that $l_{m+1} \leq l \leq l_m$, and one of the previous cases yields that $\mu(I) \lesssim l^{\beta - c/m} \leq l^{\beta - c/k}$.
	\end{itemize}
	%
	If $l \geq l_k$, then $\mu(I) \leq 1 \lesssim_k l_k^{\beta - c/k} \leq l^{\beta - c/k}$, so $\mu(I) \lesssim_k l^{\beta - c/k}$ for arbitrary dyadic $l$.
\end{proof}

Applying Frostman's lemma to Lemma \ref{frostmanBound} gives $\hausdim(X) \geq \beta - c/k$ for each $k > 0$. Taking $k \to \infty$ proves the needed dimension bound. Since we have already shown in Section \ref{discretizationsection} that $(x_1, \dots, x_n) \not \in Z$ for any distinct $x_1, \dots, x_n \in X$, this concludes the proof of Theorem \ref{mainTheorem}.









\section{Applications}\label{applications}

As discussed in the introduction, Theorem 1 generalizes Theorems 1.1 and 1.2 from \cite{MalabikaRob}. In this section, we present two applications of Theorem \ref{mainTheorem} in settings where previous methods cannot obtain any results.

\begin{theorem}[Sum-sets avoiding specified sets]
	Let $Y \subset \RR^d$ be a countable union of sets of Minkowski dimension at most $\alpha$. Then there exists a set $X \subset \RR^d$ with Hausdorff dimension at least $1 - \alpha$ such that $X + X$ is disjoint from $Y$.
\end{theorem}
\begin{proof}
	Define $Z = Z_1 \cup Z_2$, where
	%
	\[ Z_1 = \{ (x,y) : x + y \in Y \} \quad \text{and} \quad Z_2 = \{ (x,y): y \in Y/2 \}. \]
	%
	Since $Y$ is a countable union of sets of Minkowski dimension at most $\alpha$, $Z$ is a countable union of sets with lower Minkowski dimension at most $1 + \alpha$. Applying Theorem \ref{mainTheorem} with $d = 1$, $n = 2$, giving a set $X \subset \RR^d$ with Hausdorff dimension $1 - \alpha$ avoiding $Z$. Since $X$ avoids $Z_1$, whenever $x,y \in X$ are distinct, $x + y \not \in Y$. Since $X$ avoids $Z_2$, $X \cap (Y/2) = \emptyset$, and thus for any $x \in X$, $x + x \not \in Y$. Thus $X + X$ is disjoint from $Y$.
\end{proof}

\begin{remark}
	One weakness of our result is that as the number of variables $n$ increases, the dimension of $X$ tends to zero. If we try and make the $n$-fold sum $X + \cdots + X$ disjoint from $Y$, current techniques only yield a set of dimension $(1 - \alpha)/(n-1)$. We have ideas on how to improve our main result when $Z$ is `flat', in addition to being low dimension, which will enable us to remove the dependence of $\hausdim(X)$ on $n$. In particular, we expect to be able to construct a set $X$ of dimension $1 - \alpha$, such that $X$ is disjoint from $Y$, and $X$ is closed under addition, and multiplication by rational numbers. In particular, given a $\QQ$ subspace $V$ of $\RR^d$ with dimension $\alpha$, we can always find a `complementary' $\QQ$ vector space $W$ with complementary fractional dimension $d - \alpha$ such that $V \cap W = (0)$.
\end{remark}

One of the most interesting uses of our method is to construct subsets of fractals avoiding patterns. In \cite{MalabikaRob}, Fraser and the second author show that if $\gamma$ is a $C^2$ curve with non-vanishing curvature, then there exists a set $E \subset \gamma$ of Hausdorff dimension $1/2$ that does not contain isoceles triangles. Our method can extend this result from the case of curves to more general sets, which gives an example of the flexibility of our method. For simplicity, we stick to an analysis of planar sets.

\begin{theorem}[Restricted sets avoiding isoceles triangles]
	Let $Y \subset \RR^2$ and let $\pi: \RR^2 \to \RR$ be an orthogonal projection such that $\pi(Y)$ has non-empty interior. Let $d$ be an arbitrary metric on $\RR^2$. Suppose that
	%
	\[ Z_0 = \{ (y_1, y_2, y_3) \in Y^3: d(y_1,y_2) = d(y_1,y_3) \} \]
	%
	is the countable union of sets with lower Minkowski dimension at most $\alpha$, for $\varepsilon \geq 0$. Then there exists a set $X \subset Y$ with dimension at least $(3 - \alpha)/2$ so that no triple of points $(x_1, x_2, x_3) \in X^3$ form the vertices of an isoceles triangle.
\end{theorem}
\begin{proof}
	Without loss of generality, by translation and rescaling, we may assume $\pi(Y)$ contains $[0,1)$. Form the set
	%
	\[ Z = \pi(Z_0) = \{ (\pi(y_1), \pi(y_2), \pi(y_3)) : y \in Z_0 \} \]
	%
	Then $Z$ is the projection of an $\alpha$ dimensional set, and therefore has dimension at most $\alpha$. Applying Theorem \ref{mainTheorem} with $d = 1$ and $n = 3$, we construct a set $X_0 \subset [0,1)$ with Hausdorff dimension at least $(3 - \alpha)/2$ such that for any distinct $x_1,x_2,x_3 \in X_0$, $(x_1,x_2,x_3) \not \in Z$. Thus if we form a set $X$ by picking, from each $x \in X_0$, a single element of $\pi^{-1}(x)$, then $X$ avoids isoceles triangles, and has Hausdorff dimension at least as large as $X_0$.
\end{proof}

To see that Theorem 3 indeed generalizes the result of Fraser and the second author, observe that if $d$ is the Euclidean metric, then for every pair of points $x,y \in \RR^2$, the set
%
\[ \{ z \in \RR^2: d(x,z) = d(y,z) \} \]
%
is the perpendicular bisector $B_{xy}$ of $x$ and $y$. If $\gamma$ is a compact portion of a smooth curve with non-vanishing curvature, then the number of points in $\gamma \cap B_{xy}$ is bounded independantly of $x$ and $y$. Thus the set $Z_0$ in the statement of Theorem 3 has Minkowski dimension at most 2, and we can find a set with Hausdorff dimension $(3 - 2)/2 = 1/2$ on the curve avoiding isoceles triangles.

Results about slice of measures, such as those detailed in Chapter 6 of \cite{Matilla}, show that for any one dimensional set $Y$, for almost every line $L$, $L \cap Y$ consists of a finite collection of points. This suggests that if $Y$ is any set with fractional dimension one, then $Z_0$ has dimension at most 2. This implies that we can find a subset of $Y$ with dimension $1/2$ avoiding curves. We are unsure if this is true for every set with dimension one, but we provide two examples suggesting this is true for a generic set. The first result shows that for any $\varepsilon > 0$, there is an infinite family of Cantor-type sets with dimension $1 + \varepsilon$ such that $Z_0$ has dimension at most $2 + \varepsilon$. The second shows that for any rectifiable curve, $Z_0$ has dimension at most $2$. Thus Theorem 3 can be applied in settings where $Y$ is incredibly `rough', i.e. totally disconnected.

To study the first example, we consider a probabilistic model for a Cantor-type set which almost surely has the required properties. This model is obtained by considering a nested decreasing family of discretized random sets $\{ C_k \}$, with each $C_k$ a union of sidelength $1/2^k$ squares. First, we fix $p \in [0,1]$. Then we set $C_0 = [0,1]^2$. To construct $C_{k+1}$, we split each sidelength $1/2^k$ cube in $C_k$ into four sidelength $1/2^{k+1}$ squares, and keep each square in $C_{k+1}$ with probability $p$. To study this model, we employ some results about tail bounds and asymptotics for branching processes.

\begin{lemma} \label{randomdimension}
	If $p > 1/4$, then with non-zero probability, $\dim_{\mathbf{M}}(C) = 2 - \log_2(1/p)$.
\end{lemma}
\begin{proof}
	Let $p > 1/4$. For each $k$, let $Z_k$ denote the number of sidelength $1/2^k$ cubes in $[0,1]^2$. Then the sequence $\{ Z_k \}$ is a branching process, where each cube can produce between zero and four subcubes, with each of these four cubes kept with probability $p$. Thus $\Expect[Z_{k+1}|Z_k] = (4p) Z_k$. Since $4p > 1$, A simple calculation, summarized in Theorem 8.1 of \cite{Harris}, shows that the process $W_k = Z_k / (4p)^k$ is an $L^2$ bounded martingale, and so there exists a random variable $W$ such that $W_k \to W$ almost surely, and $\mathbf{E}(W|W_k) = W_k$ for all $k$. Whenever $W$ is non-zero,
	%
	\[ \minkdim(C) = \lim_{k \to \infty} \frac{\log Z_k}{k \log 2} = \lim_{k \to \infty} \frac{\log(W_k/W) + \log(W (4p)^k)}{k \log 2} = 2 - \log_2(1/p). \]
	%
	Since $\mathbf{E}(W) = \mathbf{E}(\mathbf{E}(W|W_0)) = \mathbf{E}(W_0) = 1$, $W$ is non-zero with positive probability.
\end{proof}

Similar asymptotics for branching processes show that the set $Z_0$ associated with $C$ as in Theorem 3 almost surely has Minkowski dimension $3 - \alpha$. We do this first by proving a supplementary result.

%We say a stochastic process $\{ Z_k \}$ is a $(p,M)$ {\it sub-branching process}, for $p \geq 0$ and $M > 0$, if there exists a branching process $\{ \tilde{Z_k} \}$ such that $Z_k \leq \tilde{Z}_k$ and $\mathbf{E}(\tilde{Z}_{k+1}|\tilde{Z}_k) = M \tilde{Z}_k$ holds for all $k$, and the branching process has extinction probability $p$. In the following, we assume that the offspring law of any branching process takes only finitely many values, so we have an upper bound on the maximum number of offspring that can be produced in each iteration.

\begin{lemma}\label{branchingtrick}
	Let $\{ Z_k \}$ be a supercritical branching process with extinction probability $q$. If we set $\tilde{M} = q + M$, then there exists small positive constants $\lambda$ and $\varepsilon$, depending only on the offspring law of $\{ Z_k \}$, such that $\Prob(Z_k \geq k \tilde{M}^k) \lesssim \exp \left(-\lambda k^{1 + \varepsilon} \right)$.
\end{lemma}
\begin{proof}
	Let $q_0, q_1, \dots, q_M$ denote the offspring law for the branching process, so $q = q_0$. Then there exists a grid of i.i.d discrete random variables $X_{ij}$ with $\Prob(X_{ij} = k) = q_k$ such that
	%
	\[ Z_{k+1} = \sum_{j = 1}^{Z_k} X_{ij}. \]
	%
	Now consider the branching process $\{ \tilde{Z}_k \}$ defined by setting $\tilde{Z}_0 = 1$, and
	%
	\[ \tilde{Z}_{k+1} = \sum_{j = 1}^{\tilde{Z}_k} \max(X_{ij}, 1). \]
	%
	We find $Z_k \leq \tilde{Z}_k$, and if $\tilde{M} = q + M$, then
	%
	\[ \Expect(\tilde{Z}_{k+1}|\tilde{Z}_k) = \left( q + \sum_{k = 1}^N k q_k \right) \tilde{Z}_k = (q + M) \tilde{Z}_k = \tilde{M} \tilde{Z}_k. \]
	%
	Most importantly for our purposes, $\{ \tilde{Z}_k \}$ has zero chance of extinction. Theorem 5 of \cite{Athreya} implies that for such a supercritical branching process, there exists $\lambda > 0$ depending only on the offspring distribution of $\tilde{Z}$, such that if $\tilde{W}_k = \tilde{Z}_k / \tilde{M}^k$, and $\tilde{W} = \lim \tilde{W}_k$, then
	% TODO: lambda = \theta_1^{1/3} min(1,\theta_1)^{2/3},
	% where theta_1 = inf \tilde{M}^n log g_{n-1}(e^{theta_0}), where g_{n-1} is the n-1'th iterate of g, where g is the inverse function of the generating function of the branching process.
	%
	\[ \Prob(| \tilde{W} - \tilde{W}_k | \geq t) \lesssim \exp \left( - \lambda t^{2/3} \tilde{M}^{k/3} \right) \]
	%
	In particular, this means
	%
	\begin{align*}
		\Prob \left( Z_k \geq (1 + \tilde{W}) \tilde{M}^k \right) &\leq \Prob( \tilde{Z}_k \geq (1 + \tilde{W}) \tilde{M}^k )\\
		&\leq \Prob \left( | \tilde{W} \tilde{M}^k - \tilde{Z}_k | \geq \tilde{M}^k \right)\\
		&= \Prob \left( | \tilde{W} - \tilde{W}_k| \geq 1 \right) \lesssim \exp \left( - \lambda \tilde{M}^{k/3} \right),
	\end{align*}
	%
	Theorem 2 of \cite{Biggins} implies that as $t \to \infty$, there are constants $C$ and $\varepsilon > 0$ depending only on the offspring distribution of $\tilde{Z}$ such that
	%
	\[ - \log \Prob(\tilde{W} \geq t) \geq (C + o(1)) t^{1 + \varepsilon} \]
	%
	In particular, there exists a small constant $\lambda$ such that
	%
	\[ \Prob(1 + \tilde{W} \geq k) \leq \exp \left( - \lambda k^{1 + \varepsilon} \right) \]
	%
	Applying a union bound gives
	%
	\begin{align*}
		\Prob(Z_k \geq k \tilde{M}^k ) &\leq \Prob( Z_k \geq (1 + \tilde{W}) \tilde{M}^k ) + \Prob(1 + \tilde{W} \geq k)\\
		&\lesssim \exp \left( - \lambda \tilde{M}^{k/3} \right) + \exp \left( - \lambda k^{1 + \varepsilon} \right) \lesssim \exp \left( - \lambda k^{1 + \varepsilon} \right). \qedhere
	\end{align*}
\end{proof}

For a set $E$, let $E_\delta = \{ x: d(x,E) \leq \delta \}$ denote the $\delta$ thickened version of $E$.

\begin{lemma} \label{lineCounting}
	There exists a constant $B$ such that for any $k$, we can find lines $L_{k,1}, \dots, L_{k,M}$ with $M \leq B \cdot 8^{kN}$ such that for any line $L$, there exists $i$ such that $[0,1]^2 \cap L_{1/2^{kN+1}} \subset (L_{k,i})_{2^{-kN}}$.
\end{lemma}
\begin{proof}
	For each $(x,\theta) \in [0,1]^2 \times [0,1]$, let
	%
	\[ L^{\theta,x} = \{ x + t e^{2 \pi i \theta} : t \in \mathbf{R} \} \]
	%
	Note that
	%
	\[ L^{\theta,x} \cap [0,1]^2 \subset \{ x + t e^{2 \pi i \theta} : t \in [-2,2] \} \]
	%
	Any line intersecting $[0,1]^2$ is equal to $L^{\theta,x}$ for some $\theta$ and some $x$. For any $k$, we consider the set of $8^5 \cdot 8^{kN}$ points $E = (\mathbf{Z}/2^{kN+5})^3 \cap [0,1]^3$. For any $(x_1,\theta_1)$ and $(x_2,\theta_2)$, and $t \in [-2,2]$, we calculate that
	%
	\[ |(x_1 + t e^{2 \pi i \theta_1}) - (x_2 + te^{2 \pi i \theta_2})| \leq |x_1 - x_2| + 2 \pi t |\theta_1 - \theta_2| \leq |x_1 - x_2| + 4 \pi |\theta_1 - \theta_2| \]
	%
	Thus $L^{\theta_1,x_1} \cap [0,1]^2$ is contained in the $|x_1 - x_2| + 4 \pi |\theta_1 - \theta_2|$ thickening of $L^{\theta_2,x_2}$. For any line $L^{\theta,x}$, there exists $(\theta_0,x_0) \in E$ such that $|\theta - \theta_0| \leq 1/2^{kN+2}$ and $|x - x_0| \leq \sqrt{2}/2^{kN+5}$, and so $L^{\theta,x} \cap [0,1]^2$ is contained in the $\sqrt{2}/2^{kN+5} + 4\pi/2^{kN+5} \leq 14/2^{kN+5} \leq 1/2^{kN+1}$, and thus $L^{\theta,x}_{1/2^{kN+1}} \cap [0,1]^2 \subset L_{1/2^{kN}}$. Thus we may set $B = 8^5$, completing the proof.
\end{proof}

\begin{lemma} \label{lineBounding}
	Fix $N$. If $p > 1/2$, then almost surely, there exists a value $k_0$ such that if $k \geq k_0$, and $L$ is any line, then
	%
	\[ \# \B^2_{2^{-kN}}(L_{2^{-kN}}) \leq k \cdot 10^k (2p)^{kN} \]
\end{lemma}
\begin{proof}
	Fix $N$, and for any index $k$ let $\delta_k = 1/2^{Nk}$. Given a line $L$, let $I$ be a sidelength $\delta_k$ square intersecting the $\delta_k$ thickened line $L_{\delta_k}$. Then $L$ passes from one edge of $I$ to another edge, and so if we split $I$ into $4^N$ sidelength $\delta_{k+1}$ squares, then $L_{\delta_{k+1}}$ intersects at most $5 \cdot 2^N$ of these boxes. Conditioned on $I$ being contained in $C_{kN}$, each of these subboxes occurs in $C_{(k+1)N}$ with probability $p^N$. We let $Z_k(L)$ denote the number of sidelength $1/2^{Nk}$ boxes in $C_{Nk}$ intersecting $L_{\delta_k}$. We now find $\tilde{Z_k}(L) \geq Z_k(L)$ by adding {\it exactly} $5 \cdot 2^N$ potential subboxes of each box at each subsequent stage, then $\tilde{Z_k}(L)$ is a branching process, whose offspring distribution is independant of $L$. Since each subbox is added with probability $p^N$, the extinction probability of $\tilde{Z_k}$ is $(1 - p^N)^{5 \cdot 2^N}$. Also, $\mathbf{E}(\tilde{Z}_{k+1}(L)|\tilde{Z}_k(L)) = 5 \cdot (2p)^N \tilde{Z}_k$.  Setting $M = 5 (2p)^N$ and $q = (1 - p^N)^{5 \cdot 2^N}$, Lemma \ref{branchingtrick} shows that there exists positive constants $\lambda$ and $\varepsilon$, independant of $L$, such that if $\tilde{M} = M + q$,
	%
	\[ \Prob \left( \tilde{Z}_k(L) \geq k \tilde{M}^k \right) \lesssim \exp(- \lambda k^{1 + \varepsilon}). \]
	%
	Elementary bounds on the logarithm show that
	%
	\[ 5 \cdot 2^N \log(1 - p^N) \leq \frac{-5 (2p)^N}{2 - p^N} \leq -5(2p)^N \]
	%
	so if $p > 1/2$,
	%
	\[ q = (1 - p^N)^{5 \cdot 2^N} \leq e^{-5 (2p)^N} \leq 1 \leq 5(2p)^N \]
	%
	and this implies $\tilde{M} \leq 10 (2p)^N$, so we have shown
	%
	\[ \Prob ( \tilde{Z}_k(L) \geq k \cdot 10^k (2p)^{kN}) \lesssim \exp( - \lambda k^{1 + \varepsilon}). \]
	%
	This gives an upper bound on $\tilde{Z}_k(L)$ up to a superexponentially decaying term in $k$.

	For each $k$, Lemma \ref{lineCounting} shows we can find lines $L_{k,1}, \dots, L_{k,M}$, with $M \leq B \cdot 8^{kN}$ such that for any line $L$, there exists $i$ such that $[0,1]^2 \cap L_{\delta_k/2} \subset (L_{k,i})_{\delta_k}$. Applying a union bound, we find that
	%
	\[ \Prob \left( \text{there is $i$ such that}\ Z_k(L_{k,i}) \geq k \cdot 10^k (2p)^{kN} \right) \lesssim B \cdot 8^{kN} \exp(-c k^\lambda) \]
	%
	But since $\lambda > 1$, we therefore find
	%
	\[ \sum_{k = 1}^\infty \Prob \left( \text{there is $i$ such that}\ Z_k(L_{k,i}) \geq k \cdot 10^k (2p)^{kN} \right) < \infty \]
	%
	Applying the Borel-Cantelli lemma, we conclude that almost surely, it is eventually true for sufficiently large $k$ that $Z_k(L_{k,i}) \leq k \cdot 10^k (2p)^{kN}$ for all $i$. In particular, the number of cubes intersecting $L_{\delta_k/2}$ for any line $L$ is upper bounded by $k \cdot 10^k (2p)^{kN}$.
\end{proof}

\begin{lemma}
	There exists a constant $A$ such that if $I, J \in \B^2_{1/2^{kN}}[0,1]^2$, with $d(I,J) \geq A/2^{kN}$, then
	%
	\[ \bigcup \{ L_{xy}: x \in I, y \in J \} \subset L_{1/2^{kN+1}} \]
	%
	where we recall that $L_{xy}$ is the bisector of the points $x$ and $y$.
\end{lemma}
\begin{proof}
	Denote the bottom left vertices of the boxes $I$ and $J$ by $(N_I,M_I) \cdot 1/2^{kN}$ and $(N_J,M_J) \cdot 1/2^{kN}$, with $0 \leq N_I,M_I,N_J,M_J \leq 2^{kN}$. Let $\Delta_N = |N_I - N_J|$ and $\Delta_M = |M_I - M_J|$. We may assume for simplicity that $N_I \leq N_J$ and $M_I \leq M_J$. Since $d(I,J) \geq A/2^{kN}$,
	%
	\[ (\Delta_N^2 + \Delta_M^2)^{1/2} \geq A \]
	%
	If we let $\theta_1$ and $\theta_2$ denote the minimal and maximal angle between the lines connecting pairs of points in $I$ and $J$ and the horizontal line, then
	%
	\begin{align*}
		\sin(\theta_2 - \theta_1) &= \sin(\theta_2) \cos(\theta_1) - \sin(\theta_1) \cos(\theta_2)\\
		&= \frac{(\Delta_M + 1)(\Delta_N + 1)}{\Delta_N^2 + \Delta_M^2} - \frac{\Delta_N \Delta_M}{\Delta_N^2 + \Delta_M^2}\\
		&\leq \frac{\Delta_N + \Delta_M + 1}{\Delta_N^2 + \Delta_M^2} \leq 1/A
	\end{align*}
	%
	Thus $\theta_2 - \theta_1 \leq 2/A$. Thus all the bisectors are contained in a
	%
	\[ \sqrt{2}/2^{kN} + 4\pi(2/A) \leq 1/2^{kN} \]
\end{proof}

\begin{theorem}
	If $p > 1/2$, then almost surely, the set $Z_0$ associated with $C$ has lower Minkowski dimension at most $5 - 3 \log_2(1/p)$.
\end{theorem}
\begin{proof}
	Almost surely, Lemma \ref{randomdimension} shows that for sufficiently large $k$ we can cover $C_{kN}$ by $O(2^{\alpha kN})$ boxes $I_1, \dots, I_M \in \B^2_{2^{-kN}}$, with $\alpha = 2 - \log_2(1/p)$. Lemma \ref{lineBounding} shows that if $k$ is sufficiently large, then the $1/2^{kN+1}$ thickened line $L$ intersects at most $k \cdot 10^k (2p)^{kN}$ squares in $\B^2_{2^{-kN}}$. There exists a constant $A$ such that for any $i$ and $j$, if $d(I_i, I_j) > A 2^{-kN}$, then there exists a line $L_{ij}$ such that as $x$ ranges over all points in $I_i$, and $y$ over all points in $I_j$,
	%
	\[ \bigcup_{x,y} B_{xy} \cap [0,1]^2 \subset (L_{ij})_{\delta_k/2} \]
	%
	This means that $Z_0 \cap (I_i \times I_j \times [0,1]^2) \subset I_i \times I_j \times (L_{ij})_{\delta_k/2}$, and the last paragraph implies that $(L_{ij})_{\delta_k/2}$ is covered by $k \cdot 10^k (2p)^{kN}$ cubes in $\B^2_{l_k}[0,1]^2$. On the other hand, if $d(I_i,I_j) < A \delta_k$, we can apply the obvious bound that $Z_0 \cap (I_i \times I_j \times [0,1]^2) \subset I_i \times I_j \times C_{kN}$, and $C_{kN}$ is coverable by $O(2^{\alpha kN})$ boxes. Thus we conclude that almost surely, for sufficiently large $k$,
	%
	\begin{align*}
		\# \B^6_{\delta_k}(Z_0) &= \sum_{i,j} \B^6_{\delta_k}(Z_0 \cap (I_i \times I_j \times [0,1]^2)) \\
		&\leq \sum_i \left( \sum_{d(I_i,I_j) \leq A \delta_k} \# \B^6_{\delta_k}(Z_0 \cap (I_i \times I_j \times (L_{ij})_{\delta_k/2})) \right)\\
		&\quad\quad+ \left( \sum_{d(I_i,I_j) > A \delta_k} \# \B^6_{\delta_k}(Z_0 \cap (I_i \times I_j \times C_{kN})) \right)\\
		&\leq \sum_i \left( \sum_{d(I_i,I_j) \leq A \delta_k} \# \B^2_{\delta_k}((L_{ij})_{\delta_k/2}) \right) + \left( \sum_{d(I_i,I_j) > A \delta_k} \# \B^2_{\delta_k}(C_{kN}) \right)\\
		&\lesssim \sum_i 2^{\alpha kN} \cdot k 10^k (2p)^{kN} + 2^{\alpha kN} \lesssim 2^{2\alpha kN} k 10^k (2p)^{kN}
	\end{align*}
	%
	Thus we conclude that almost surely,
	%
	\begin{align*}
		\minkdim(Z_0) &= \lim_{k \to \infty} \frac{\log \left( \# \B^6_{\delta_k}(Z_0) \right)}{\log(1/\delta_k)}\\
		&\leq \lim_{k \to \infty} \frac{\log(2^{2 \alpha kN} k 10^k (2p)^{kN}) + O(1)}{\log(2^{kN})}\\
		&= \lim_{k \to \infty} \frac{2 \alpha k N \log(2) + k \log 10 + kN \log(2p)}{kN \log(2)}\\
		&= 2 \alpha + 3/N + 1 - \log_2(1/p)\\
		&= 5 - 3\log_2(1/p) + 3/N
	\end{align*}
	%
	Taking $N \to \infty$, we obtain the required result.
\end{proof}

TODO: does a projection of $C$ have non-empty interior almost surely?

\begin{corollary}
	If $p = 1/2^{1 - \varepsilon}$, then conditioned on $C$ having Minkowski dimension $1 + \varepsilon$, we can find a subset $X$ of $C$ avoiding isoceles triangles with $\hausdim(X) \geq 1/2 - (3/2) \varepsilon$.
\end{corollary}










\section{Relation to Literature, and Future Work}\label{futureWorkSection}

Our result is part of a growing body of work finding general methods to find sets avoiding patterns. The main focus of this section is comparing our method to the two other major results in the literature. \cite{MalabikaRob} constructs sets with dimension $k/(n-1)$ avoiding the zero sets of rank $k$ $C^1$ functions. In \cite{Mathe}, sets of dimension $d/l$ are constructed avoiding a degree $l$ algebraic hypersurface specified by a polynomial with rational coefficients.

We can view our result as a robust version of Pramanik and Fraser's result. Indeed, if we try and avoid the zero set of a $C^1$ rank $k$ function, then we are really avoiding a dimension $dn - k$ dimensional manifold. Our method gives a dimension
%
\[ \frac{dn - (dn - k)}{n - 1} = \frac{k}{n - 1} \]
%
set, which is exactly the result obtained in \cite{MalabikaRob}.

That our result generalizes \cite{MalabikaRob} should be expected because the technical skeleton of our construction is heavily modeled after their construction technique. Their result also reduces the problem to a discrete avoidance problem. But they {\it deterministically} select a particular side length $S$ cube in every side length $R$ cube. For arbitrary $Z$, this selection procedure can easily be exploited for a particularly nasty $Z$, so their method must rely on smoothness in order to ensure some cubes are selected at each stage. Our discrete avoidance technique was motivated by other combinatorial optimization problems, where adding a random quantity prevents inefficient selections from being made in expectation. This allows us to rely purely on combinatorial calculations, rather than employing smoothness, and greatly increases the applicability of the sets $Z$ we can apply our method to. Furthermore, it shows that the underlying problem is robust to changes in dimension; slightly `thickening' $Z$ only slightly perturbs the dimension of $X$.

One useful technique in \cite{MalabikaRob}, and its predecessor \cite{KeletiDimOneSet}, is the use of a Cantor set construction `with memory'; a queue in the construction algorithm for their sets allows storage of particular discrete versions of the problem to be stored, and then retrieved at a much later stage of the construction process. This enables them to `separate' variables in the discrete version of the problem, i.e. instead of forming a single set $F$ from a set $E$, they from $n$ sets $F_1, \dots, F_n$ from disjoint sets $E_1, \dots, E_n$. The fact that our result is more general, yet does not rely on this technique is an interesting anomaly. An obvious advantage is that the description of the technique is much more simple. But an additional advantage is that we can attack `one scale' of the problem at a time, rather than having to rely on stored memory from a vast number of steps before the current one. We believe that we can exploit the single scale approach to the problem to generalize our theorem to a much wider family of `dimension $\alpha$' sets $Z$, which we plan to discuss in a later paper.

As a generalization of the result in \cite{MalabikaRob}, our result has the same issues when compared to the result of \cite{Mathe}. When the parameter $n$ is large, the dimension of our result suffers greatly, as with the $n$ fold sum application in the last section. Furthermore, our result can't even beat trivial results if $Z$ is almost full dimensional, as the next example shows.

\begin{example}
	Consider an $\alpha$ dimensional set of angles $Y$, and try and find $X \subset \RR^2$ such that the angle formed from any collection of three points in $X$ avoids $Y$. If we form the set
	%
	\[ Z = \left\{ (x,y,z): \text{There is $\theta \in Y$}\ \text{such that}\ \frac{(x - y) \cdot (x - z)}{|x - y||x - z|} = \cos \theta \right\} \]
	%
	Then we can find $X$ avoiding $Z$. But one calculates that $Z$ has dimension $3d + \alpha - 1$, which means $X$ has dimension $(1 - \alpha) / 2$. Provided the set of angles does not contain $\pi$, the trivial example of a straight line beats our result.
\end{example}

Nonetheless, we still believe our method is a useful inspiration for new techniques in the `high dimensional' setting. Most prior literature studies sets $Z$ only implicitly as zero sets of some regular function $f$. The features of the function $f$ imply geometric features of $Z$, which are exploited by these results. But some geometric features are not obvious from the functional perspective; in particular, the fractional dimension of the zero set of $f$ is not an obvious property to study. We believe obtaining methods by looking at the explicit geometric structure of $Z$ should lead to new techniques in the field, and we already have several ideas in mind when $Z$ has geometric structure in addition to a dimension bound, which we plan to publish in a later paper.

We can compare our randomized selection technique to a discrete phenomenon that has been recently noticed, for instance in \cite{BaloghMorrisSamotij}. There, certain combinatorial problems can be rephrased as abstract problems on hypergraphs, and one can then generalize the solutions of these problems using some strategy to improve the result where the hypergraph is sparse. Our result is a continuous analogue of this phenomenon, where sparsity is represented by the dimension of the set $Z$ we are trying to avoid. One can even view Lemma 1 as a solution to a problem about independent sets in hypergraphs. In particular, we can form a hypergraph by taking the cubes $\B^d_s(E)$ as vertices, and adding an edge $(I_1, \dots, I_n)$ between $n$ distinct cubes $I_k \in \B^d_s(E)$ if $I_1 \times \dots \times I_n$ intersects $Z_s$. An independent set of cubes in this hypergraph corresponds precisely to a set $F$ with $F^n$ disjoint except on a discretization of the diagonal. And so Lemma 1 really just finds a `uniformly chosen' independent set in a sparse graph. Thus we really just applied the discrete phenomenon at many scales to obtain a continuous version of the phenomenon.

\endinput