%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Avoiding Rough Sets}
\label{ch:RoughSets}

In the last chapter, we saw that many authors have considered the pattern avoidance problem for configurations $\C$ which take the form of many general classes of smooth shapes; in Math\'{e}'s work, $\C$ can take the form of an algebraic variety of low degree, and in Pramanik and Fraser's work, $\C$ can take the form of a smooth manifold. In this chapter, we consider the pattern avoidance problem for an even more general class of `rough' patterns, that are the countable union of sets with controlled lower Minkowski dimension.
%
\begin{theorem}\label{mainTheorem}
	Let $\alpha \geq d$, and suppose $\C \subset \C^n(\RR^d)$ is the countable union of precompact sets, each with lower Minkowski dimension at most $\alpha$. Then there exists a set $X \subset [0,1]^d$ with Hausdorff dimension at least $(nd - \alpha)/(n-1)$ avoiding $\C$.
\end{theorem}

% CHANGE: Made Remarks section an AMSTHM class so that things are properly spaced / the code is neater. Also split up remarks that addressed two different points into two separate remarks. Also moved the proof discussion from the remarks since it is a bit too long for a remark.
\begin{remarks}
	\
	\begin{enumerate}
		\item[(1)] When $\alpha < d$, the pattern avoidance problem is trivial, since $X = [0,1)^d - \pi(Z)$ is full dimensional and solves the pattern avoidance problem, where $\pi(x_1, \dots, x_n) = x_1$ is a projection map from $\RR^{dn}$ to $\RR^d$. We will therefore assume that $\alpha \geq d$ in our proof of the theorem. Note that obtaining a full dimensional set in the case $\alpha = d$, however, is still interesting.

		\item[(2)] Theorem \ref{mainTheorem} is trivial when $\alpha = dn$, since we can set $X = \emptyset$. We will therefore assume that $\alpha < dn$ in our proof of the theorem.

		\item[(3)] When $Z$ is a countable union of smooth manifolds in $\RR^{nd}$ of co-dimension $m$, we have $\alpha = nd - m$. In this case Theorem \ref{mainTheorem} yields a set in $\RR^d$ with Hausdorff dimension at least $(nd - \alpha)/(n-1) = m/(n-1)$. This recovers Theorem 1.1 and 1.2 from \cite{MalabikaRob}, making Theorem \ref{mainTheorem} a generalization of these results.

		\item[(4)] Since Theorem \ref{mainTheorem} does not require any regularity assumptions on the set $Z$, it can be applied in contexts that cannot be addressed using previous methods. Two such applications, new to the best of our knowledge, have been recorded in Section \ref{applications}; see Theorems \ref{sumset-application} and \ref{C1IsoscelesThm} there.
	\end{enumerate}
\end{remarks}

The set $X$ in Theorem \ref{mainTheorem} is obtained as a limit of discretized sets $\{ X_k \}$, each of which avoids a certain discretization of the configuration $\C$ at the scale $l_k$. While this proof strategy is not new, our method for constructing the sets $\{X_k\}$ has several innovations that simplify the analysis of the resulting set $X=\bigcap X_k$. In particular, through a probabilistic selection process we are able to avoid the complicated queuing techniques used in \cite{KeletiDimOneSet} and \cite{MalabikaRob}, that required storage of data from each step of the iterated construction to be retrieved at a much later stage of the construction process.

At the same time, our construction shares certain features with \cite{MalabikaRob}, in particular, the strategy of iterative discretization. The details of a single step of this construction are described in Section \ref{discretesection}. In Section \ref{discretizationsection}, we explain how the length scales $l_k$ and $r_k$ for $X$ are chosen, and prove its avoidance property. In Section \ref{dimensionsection} we analyze the size of $X$ and show that it satisfies the conclusions of Theorem \ref{mainTheorem}.









\section{Avoidance at Discrete Scales}\label{discretesection}

In this section we describe a method for avoiding $Z$ at a single scale. We apply this technique in Section \ref{discretizationsection} at many scales to construct a set $X$ avoiding $Z$ at all scales. This single scale avoidance technique is the core building block of our construction, and the efficiency with which we can avoid $Z$ at a single scale has direct consequences on the Hausdorff dimension of the set $X$ constructed obtained in Theorem \ref{mainTheorem}.

% Change: Using B_s^{dn}(Z) is not correct here, i.e if Z is a dense set. Also reference definition when using strongly non diagonal cubes for the first time.
% Original: At a single scale, we solve a discretized version of the problem, where all sets are unions of cubes at two dyadic lengths $l \geq s$ (later, we will choose $l=l_n$ and $s=l_{n+1}$). Given a set $E \subseteq [0,1)^d$ that is a union of cubes in $\B_l^d$, our goal is to construct a set $F\subset E$ that is a union of cubes in $\B_s^d$ such that $F^n$ is disjoint from the strongly non-diagonal cubes of $\B_{s}^{dn}(Z)$.
At a single scale, we solve a discretized version of the problem, where all sets are unions of cubes at two dyadic lengths $l > s$. In this discrete setting, $Z$ is replaced by a discretized version of itself, a union of cubes in $\B^{dn}_s$ denoted by $G$. Given a set $E$, which is a union of cubes in $\B_l^d$, our goal is to construct a set $F \subset E$ that is a union of cubes in $\B_s^d$, such that $F^n$ is disjoint from strongly non-diagonal cubes (see Definition \ref{defStronglyNonDiagonal}) in $\B^{dn}_s(G)$. Using the setup introduced at the end of the introduction, we will later choose $l = l_k$, $s = l_{k+1}$, and $E = X_k$. The set $X_{k+1}$ will be defined as the set $F$ constructed.
%(see Definition \ref{defStronglyNonDiagonal}).
% DISCUSS: Don't we want to reference definitions when we first use them?

In order to ensure the final set $X$ obtained in Theorem \ref{mainTheorem} has large Hausdorff dimension regardless of the rapid decay of scales used in the construction of $X$, it is crucial that $F$ is uniformly distributed at intermediate scales between $l$ and $s$.
%
% CHANGE: This is a bad choice of language to use, because it is really a combination of non-concentration and large size which gives the uniform distribution (taking F to be empty would satisfy non concentration).
% ORIGINAL: This is the `non-concentration' property discussed below. The next lemma constructs a set $F$ with these properties. 
We achieve this by decomposing $E$ into sub-cubes in $\B^d_r$ for some intermediate scale $r \in [s,l]$, and distributing $F$ as evenly among these intermediate sub-cubes as possible. This is possible assuming a mild regularity condition on the number of cubes in $G$, i.e. Equation \eqref{ZsLarge}.
%

\begin{lemma} \label{discretelemma}
	Fix two distinct dyadic lengths $l$ and $s$, with $l > s$. Let $E \subseteq [0,1)^d$ be a nonempty union of cubes in $\B^d_l$, and let $G\subset\RR^{dn}$ be a nonempty union of cubes in $\B_s^{dn}$ such that
	%
	\begin{equation}\label{ZsLarge}
		(l/s)^d \leq \# \B^{dn}_s(G)  \leq \frac{1}{2}(l/s)^{dn}.
	\end{equation} 
	%
	Then there exists a dyadic length $r \in [s,l]$ of size
	%
	\begin{equation} \label{rBound}
	 	r \sim \left( l^{-d}s^{dn} \# \B^{dn}_s(G) \right)^{\frac{1}{d(n-1)}},
	\end{equation}
	%
	and a set $F \subset E$ that is a nonempty union of cubes in $\B^d_s(E)$ satisfying the following three properties:
	%
	\begin{enumerate}
		\item\label{avoidanceItem} \emph{Avoidance}: For any choice of distinct cubes $J_1, \dots, J_n \in \B^d_s(F)$, $J_1 \times \dots \times J_n \not \in \B_s^{dn}(G)$.

		\item\label{nonConcentrationItem} \emph{Non-Concentration}: For every $I' \in \B_r^d(E)$, there is at most one $J \in \B_s^d(F)$ with $J \subset I'$.

		\item\label{largeSizeItem} \emph{Large Size}: For every $I \in \B^d_l(E)$, $\# \B^d_s(F \cap I) \geq \# \B^d_r(I) / 2 = (l/r)^d / 2$.
	\end{enumerate}
\end{lemma}

\begin{remark}
	Property \ref{avoidanceItem} says that $F$ avoids strongly non-diagonal cubes in $\B^{dn}_s(G)$. Properties \ref{nonConcentrationItem} and \ref{largeSizeItem} together imply that for every $I \in \B^d_l(E)$, at least half the cubes $I'\in \B_r^d(I)$ contribute a single sub-cube of sidelength $s$ to $F$; the rest contribute none. 
	%contains a single cube of sizelength $s$ inside of $I$. 
\end{remark}

\begin{proof}
	Let $r$ be the smallest dyadic length at least as large as $R$, where
	%
	\begin{equation} \label{What-is-r}
		R = \big(2 l^{-d}s^{dn}\# \B^{dn}_s(G)\big)^{\frac{1}{d(n-1)}}.
		%r\geq\max\Big(s,\ \big(l^{-d}s^{dn}\# \B^{dn}_s(G)\big)^{\frac{1}{d(n-1)}}\Big).
	\end{equation} 
	%
	%By the first inequality in \eqref{ZsLarge}, 
	This choice of $r$ satisfies \eqref{rBound}. 
	%Define $A_l = (2^{1/d}/l)^{1/(n-1)}.$ By the second inequality in \eqref{ZsLarge}, we have
	%
	%	\[ A_l (s^{dn}\#\B^{dn}_s(G))^{1/d(n-1)} \leq A_l l^{n/(n-1)} / 2^{1/d(n-1)} = l. \]
	%Since $l$ is a dyadic length, we conclude that $r\leq l$ and thus 
	The inequalities in \eqref{ZsLarge} ensure that $r \in [s,l]$; more precisely, the left inequality in \eqref{ZsLarge} implies $R$ is bounded from below by $s$, and the right inequality implies $R$ is bounded from above by $l$. The minimality of $r$ ensures $s \leq r \leq l$.

	For each $I' \in \B_r^d(E)$, let $J_{I'}$ be an element of $\B^d_s(I)$ chosen uniformly at random; these choices are independent as $I'$ ranges over the elements of $\B_r^d(E)$. Define
	%
	\[ 	U = \bigcup \left\{ J_{I'} \setcolon I' \in \B_r^d(E) \right\}, \]
	%
	and
	%
	\[ \mathcal{K}(U) = \{ K \in \B^{dn}_s(G) \setcolon K \in U^n, \text{$K$ strongly non-diagonal} \}. \]
	%
	Note that the sets $U$ and $\mathcal{K}(U)$ are random sets, in the sense that they depend on the random variables $\{ J_{I'} \}$. Define
	%
	\begin{equation} \label{defnOfF}
		F(U) = U - \{ \pi(K) \setcolon K \in \mathcal{K}(U) \},
	\end{equation}
	%
	where $\pi \colon \RR^{dn} \to \RR^d$ is the projection map $(x_1, \dots, x_n) \mapsto x_1$, for $x_i \in \RR^d$. Thus $\pi$ sends the cube $J_1 \times \dots \times J_n\in \B^{dn}_s$ to the cube $J_1 \in \B^d_s$. Given any strongly non-diagonal cube $K = J_1 \times \cdots \times J_n \in \B_s^{dn}(G)$, either $K \not \in \B_s^{dn}(U^n)$, or $K \in \B_s^{dn}(U^n)$. If the former occurs then $K \not \in \B_s^{dn}(F(U)^n)$ since $F(U) \subset U$, so $\B_s^{dn}(F(U)^n) \subset \B_s^{dn}(U^n)$. If the latter occurs then $K \in \mathcal{K}(U)$, and since $\pi(K) = J_1$, $J_1 \not \in \B_s^d(F(U))$. In either case, $K \not \in \B_s^{dn}(F(U)^n)$, so $F(U)$ satisfies Property \ref{avoidanceItem}. By construction, $U$ contains at most one subcube $J \in \B^{dn}_s$ for each $I \in \B^{dn}_l(E)$. Since $F(U) \subset U$, $F(U)$ satisfies Property \ref{nonConcentrationItem}. Thus the set $F(U)$ satisfies Properties \ref{avoidanceItem} and \ref{nonConcentrationItem} regardless of which values are assumed by the random variables $\{ J_{I'} \}$. Next we will show that with non-zero probability, the set $F(U)$ satisfies Property \ref{largeSizeItem}. 

	For each cube $J \in \B_s^d(E)$, there is a unique `parent' cube $I' \in \B_r^d(E)$ such that $J \subset I'$. Since $I'$ contains $(r/s)^d$ cubes of sidelength $s$, and $J_{I'}$ is chosen uniformly at random from $\B^d_s(I')$,
	%
%	\begin{equation} \label{singleCubeProb}
	\[ \prob(J \subset U) = \prob(J_{I'} = J) = (s/r)^d. \]
%	\end{equation}
	%
	%Here the probability measure $\Prob(\cdot)$ is taken with respect to the randomly chosen set $U$ defined in \eqref{Udefinition}.
	The cubes $J_{I'}$ are chosen independently, so if $J_1, \dots, J_n$ are distinct cubes in $\B^d_s(E)$, then %the last calculation combined with Property \ref{nonConcentrationItem} shows that
	%
	\begin{equation}\label{jointprob}
	\prob(J_1, \dots, J_n \in U) = \begin{cases} (s/r)^{dn} & \text{if $J_1, \dots, J_n$ have distinct parents,} \\ 0 & \text{otherwise}. \end{cases} 
	\end{equation}
	%
	Let $K = J_1 \times \dots \times J_n \in \B^{dn}_s(G)$. If the cubes $J_1, \dots, J_n$ are distinct, we deduce from \eqref{jointprob} that
	%
	\begin{equation}\label{probaKSubsetUn}
		\prob(K \subset U^n) = \prob(J_1, \dots, J_n \in U) \leq (s/r)^{dn}.
	\end{equation}
	%
	By \eqref{probaKSubsetUn}, linearity of expectation, and \eqref{What-is-r},
	%
	\begin{align*}
		\expect(\# \mathcal{K}(U)) &= \sum_{K \in \B^{dn}_s(G)} \prob(K \subset U^n) \leq \# \B_s^{dn}(G) \cdot (s/r)^{dn}
		% (l/r)^{dn}/2
	%	&= \left[ s^{dn}\#\B^{dn}_s(G) r^{-d(n-1)} \right] r^{-d} \\
	%	& \leq \left[ s^{dn}\#\B^{dn}_s(G) (A_l (s^{dn}\#\B^{dn}_s(G))^{1/d(n-1)})^{-d(n-1)} \right] r^{-d} \\
		\leq 0.5 \cdot (l/r)^d.
		%& = (l/r)^d /2.
	\end{align*}
	%
	In particular, there exists at least one (non-random) set $U_0$ such that
	%
	\begin{equation}\label{KU0Small}
		\# \mathcal{K}(U_0) \leq \expect(\# \mathcal{K}(U)) \leq 0.5 \cdot (l/r)^d.
	\end{equation}
	%
	 In other words, $F(U_0) \subset U_0$ is obtained by removing at most $0.5 \cdot (l/r)^d$ cubes in $\B^d_s$ from $U_0$. For each $I \in \B_l^d(E)$, we know that $\# \B_{s}^d(I \cap U_0) = (l/r)^d$. Combining this with \eqref{KU0Small}, we arrive at the estimate 
	%
	% Change: Some of the manipulations of the old version of this inequality are not technically true using the notation provided.
	\begin{align*}
		\# \B_s^d(I \cap F(U_0)) &= \B_s^d(I \cap U_0) - \# \{ \pi(K) \setcolon K \in \mathcal{K}(U_0), \pi(K) \in F(U_0) \}\\
		&\geq \B_s^d(I \cap U_0) - \#(\mathcal{K}(U_0))\\
		&\geq (l/r)^d - 0.5 \cdot (l/r)^d \geq 0.5 \cdot (l/r)^d
%		\# \B_{s}^d(I \cap F_{U_0}) &= \# \B_{s}^d(I \cap F_{U_0}) - \# \B_{s}^d \bigl[ I \cap \pi(\mathcal K(U_0)) \bigr] \\  
%		&\geq \# \B_{s}^d(I \cap F_{U_0}) - \# \B_{s}^d (\pi(\mathcal K(U_0))) \\ 
%		&\geq \# \B_{s}^d(I \cap F_{U_0}) - \# \B_{s}^d (\mathcal K(U_0))\\
%		&\geq (l/r)^d - 0.5 \cdot (l/r)^d \geq 0.5 \cdot (l/r)^d.  
	\end{align*}  
	%
	In other words, $F(U_0)$ satisfies Property \ref{largeSizeItem}. Setting $F = F(U_0)$ completes the proof.
\end{proof}

\begin{remarks}
	\
	\begin{enumerate}
		\item[(1)] While Lemma \ref{discretelemma} uses probabilistic arguments, the conclusion of the lemma is not a probabilistic statement. In particular, one can find a suitable $F$ constructively by checking every possible choice of $U$ (there are finitely many) to find one particular choice $U_0$ which satisfies \eqref{KU0Small}, and then defining $F$ by \eqref{defnOfF}. Thus the set we obtain in Theorem \ref{mainTheorem} exists by purely constructive means.
		
		\item[(2)] At this point, it is possible to motivate the numerology behind the dimension bound $\dim(X) \geq (dn-\alpha)/(n-1)$ from Theorem \ref{mainTheorem}, albeit in the context of Minkowski dimension. We will pause to do so here before returning to the proof of Theorem \ref{mainTheorem}. For simplicity, let $\alpha > d$, and suppose that $Z \subset \RR^{dn}$ satisfies 
		%
		\begin{equation}\label{specialCase}
			\#\B_{s}^{dn}(Z) \sim s^{-\alpha} \quad \textrm{for every}\ s \in (0,1].
		\end{equation}
		%
		Let $l = 1$, $E = [0,1)^d$, and let $s > 0$ be a small parameter. If $s$ is chosen sufficiently small compared to $d,n$, and $\alpha$, then \eqref{ZsLarge} is satisfied with $G = \bigcup \B^{dn}_s(Z)$. We can then apply Lemma \ref{discretelemma} to find a dyadic scale $r \sim s^{(dn-\alpha)/d(n-1)}$ and a set $F$ that avoids the strongly non-diagonal cubes of $\B_{s}^{dn}(Z)$. The set $F$ is a union of approximately $r^{-d} \sim s^{-(dn-\alpha)/(n-1)}$ cubes of sidelength $s$. Thus informally, the set $F$ resembles a set with Minkowski dimension $\alpha$ when viewed at scale $s$. 

		The set $X$ constructed in Theorem \ref{mainTheorem} will be obtained by applying Lemma \ref{discretelemma} iteratively at many scales. At each of these scales, $X$ will resemble a set of Minkowski dimension $(dn - \alpha)/(n-1)$. A careful analysis of the construction (performed in Section \ref{dimensionsection}) shows that $X$ actually has Hausdorff dimension at least $(dn - \alpha)/(n-1)$.

		\item[(3)] Lemma \ref{discretelemma} is the core method in our avoidance technique. The remaining argument is fairly modular. If, for a special case of $Z$, one can improve the result of Lemma \ref{discretelemma} so that $r$ is chosen on the order of $s^{\beta/d}$, then the remaining parts of our paper can be applied near verbatim to yield a set $X$ with Hausdorff dimension $\beta$, as in Theorem \ref{mainTheorem}. 
	\end{enumerate} 
\end{remarks}









\section{Fractal Discretization}\label{discretizationsection}

% CHANGE: Now this section has been organized, you talk about the sets Z_k before you even introduce them. This needs to be reworded.
% ORIGINAL: In this section we will construct the set $X$ from Theorem \ref{mainTheorem} by applying Lemma \ref{discretelemma} at many scales. The goal is to find a nested decreasing family of discretized sets $\{ X_k \}$ and to set $X = \bigcap X_k$. One condition guaranteeing that $X$ avoids $Z$ is that $X_k^n$ is disjoint from {\it strongly non-diagonal} cubes in $Z_k$.
In this section we construct the set $X$ from Theorem \ref{mainTheorem} by applying Lemma \ref{discretelemma} at many scales. Let us start by fixing a strong cover $Z$ that we will work with in the sequel.

%Since $Z$ is a countable union of bounded sets with Minkowski dimension at most $\alpha$, there exists a strong cover (see Definition \ref{defStrongCover}) of $Z$ by cubes restricted to a sequence of dyadic lengths $\{ l_k \}$, with a quantitative bound on the number of cubes at each scale. We fix a cover so that the scales $l_k$ converge to $0$ very quickly.

\begin{lemma}\label{coveringLemma}
	Let $Z \subset \RR^{dn}$ be a countable union of bounded sets with Minkowski dimension at most $\alpha$, and let $\epsilon_k \searrow 0$ with $2\epsilon_k < dn - \alpha$ for all $k$. Then there exists a sequence of dyadic lengths $\{ l_k \}$ and a strong cover of $Z$ by a sequence of sets $\{ Z_k \}$, such that
	%
	\begin{enumerate}
		\item\label{DiscretenessProperty} \emph{Discreteness}: For all $k \geq 0$, $Z_k$ is a union of cubes in $\B^{dn}_{l_k}$.

		\item\label{SparsityProperty} \emph{Sparsity}: For all $k \geq 0$, $l_k^{-d} \leq \#\B^{dn}_{l_k}(Z_k) \leq l_k^{-\alpha-\epsilon_k}$.

		\item\label{RapidDecayProperty} \emph{Rapid Decay}: For all $k > 1$,
			\begin{align}
				l_k^{dn-\alpha-\varepsilon_k} & \leq 0.5 \cdot l_{k-1}^{dn} \label{coverBoundRequirement}, \\
				l_k^{\epsilon_k} & \leq l_{k-1}^{2d}\label{quadDecayRequirement}.
			\end{align}
	\end{enumerate}
\end{lemma}
\begin{proof}
	We can write $Z = \bigcup_{i = 1}^\infty Y_i$, with $\lowminkdim(Y_i) \leq \alpha$ for each $i$. Consider the $d$ dimensional hyperplane
	%
	\[ H = \{ (x_1,\dots, x_1) \setcolon x_1 \in [0,1)^d \}. \]
	%
	Let $Y_i' = Y_i \cup H$. In particular, this means for any $l$,
	%
	\begin{equation}\label{YPrimeLowerBound}
		\# \B^{nd}_l(Y_i') \geq \# \B^{nd}_l(H) = l^{-d}.
	\end{equation}
	%
	Note that $\lowminkdim(Y_i') \leq \alpha$ for each index $i$. Let $\{ i_k \}$ be a sequence of integers that repeats each integer infinitely often.

	The lengths $\{ l_k \}$ and sets $\{ Z_k \}$ are defined inductively. As a base case, set $l_0 = 1$ and $Z_0 = [0,1)^d$. Suppose that the lengths $l_0, \ldots, l_{k-1}$ have been chosen. Since $\lowminkdim(Y_{i_k}) \leq \alpha$, Definition \ref{defnMinkowskiDim} implies that there exists arbitrarily small lengths $l$ that satisfy
	%
\[ \# \B^{dn}_l(Y_{i_k}') \leq l^{-\alpha - \frac{\varepsilon_k}{4}}. \]
Since $\varepsilon_k>0$, this means that there exist arbitrarily small dyadic lengths $l$ that satisfy
	\begin{equation}\label{coveringOfBdnlZk}
		\# \B^{dn}_l(Y_{i_k}') \leq l^{-\alpha - \frac{\varepsilon_k}{2}}.
	\end{equation}
	%
	In particular, we can choose a dyadic length $l = l_k$ small enough to satisfy \eqref{coverBoundRequirement}, \eqref{quadDecayRequirement}, and \eqref{coveringOfBdnlZk}. With this choice of $l_k$, we have that Property \ref{RapidDecayProperty} is satisfied. Define $Z_k$ to be the union of the cubes in $\B^{dn}_{l_k}(Y_{i_k}')$.  This choice of $Z_k$ clearly satisfies Property \ref{DiscretenessProperty}, and Property \ref{SparsityProperty} is implied by \eqref{YPrimeLowerBound} and \eqref{coveringOfBdnlZk}.

	It remains to verify that the sets $\{Z_k\}$ strongly cover $Z$. Fix a point $z \in Z$. Then there exists an index $i$ such that $z \in Y_i$, and there is a subsequence $k_1, k_2, \dots$ such that $i_{k_j} = i$ for each $j$. But then $z \in Y_i \subset Y_i' \subset Z_{i_{k_j}}$, so $z$ is contained in each of the sets $Z_{i_{k_j}}$, and thus $z \in \limsup Z_i$.
\end{proof}

To construct $X$, we consider a nested, decreasing family of discretized sets $\{ X_k \}$, where $X_k$ is a union of cubes in $\B^d_{l_k}(X_k)$. We then set $X = \bigcap X_k$. The goal is to choose $X_k$ such that $X_k^n$ is disjoint from {\it strongly non diagonal} cubes in $Z_k$.

\begin{lemma} \label{stronglydiagonal}
	Let $Z \subset \RR^{dn}$, let $\{Z_k\}$ be a sequence of sets that strongly cover $Z$, and let $\{ l_k \}$ be a sequence of lengths converging to zero. For each index $k$, let $X_k$ be a union of cubes in $\B^d_{l_k}$. Suppose that for each $k$, $X_k^n$ avoids strongly non-diagonal cubes in $\B^{dn}_{l_k}(Z_k)$. If $X = \bigcap X_k$, then for any distinct $x_1, \dots, x_n \in X$, we have $(x_1, \dots, x_n) \not \in Z$.
\end{lemma}
\begin{proof}
	Let $z \in Z$ be a point with distinct coordinates $z_1, \dots, z_n$. Define
	%
	\[ \Delta = \{ (w_1, \dots, w_n) \in \RR^{dn} \setcolon \text{there exists $i \neq j$ such that $w_i = w_j$} \}. \]
	%
	Then $d(\Delta,z) > 0$, where $d$ is the Hausdorff distance between $\Delta$ and $z$. Since $\{ Z_k \}$ strongly covers $Z$, there is a subsequence $\{ k_m \}$ such that $z \in Z_{k_m}$ for every index $m$. Since $l_k$ converges to 0 and thus $l_{k_m}$ converges to $0$, if $m$ is sufficiently large then $\sqrt{dn} \cdot l_{k_m} < d(\Delta,z)$. Note that $\sqrt{dn} \cdot l_{km}$ is the diameter of a cube in $\B_{l_{k_m}}^{dn}$. For such a choice of $m$, if $I\in \B_{l_{k_m}}^{dn}(Z_{k_m})$ is the (unique) cube in $\B_{l_{k_m}}^{dn}$ containing $z$, then $I \cap \Delta = \emptyset$. But this means $I$ is strongly non-diagonal. Since $X_{k_m}$ avoids the strongly non-diagonal cubes of $Z_{k_m}$, we conclude that $z \not \in X_{k_m}^n$. In particular, this means $z \not\in X^n$.
\end{proof}

All that remains is to apply the discrete lemma to choose the sets $X_k$.

\begin{lemma} 
	Given a sequence of dyadic length scales $\{l_k\}$ obeying, \eqref{coverBoundRequirement}, \eqref{quadDecayRequirement}, and \eqref{coveringOfBdnlZk} as above, there exists a sequence of sets $\{X_k\}$ and a sequence of dyadic intermediate scales $\{ r_k \}$ with $l_k \leq r_k \leq l_{k-1}$ for each $k \geq 1$, such that each set $X_k$ is a union of cubes in $\B_{l_k}^d(X_{k-1})$ that avoids the strongly non-diagonal cubes of $\mathcal B_{l_k}^{dn}(Z_k)$. Furthermore, for each index $k\geq 1$ we have
	%
	\begin{align}
		& r_k \lesssim l_k^{(dn-\alpha -\epsilon_k)/d(n-1)},\label{rkSizeBound}\\
		& \# \B^d_{l_k}(X_k \cap I) \geq 0.5 \cdot (l_{k-1}/r_k)^d \quad \text{for each}\ I\in \B_{l_{k-1}}^d(X_{k-1}), \label{manyIkInIkm1}\\
		&\# \B^d_{l_k}(X_k \cap I') \leq 1 \quad \text{ for each}\ I' \in \B_{r_{k}}^d(X_{k-1}).\label{XkWellDistributed}
	\end{align}
\end{lemma}
\begin{proof}
	We construct $X_k$ by induction, using Lemma \ref{discretelemma} at each step. Set $X_0=[0,1)^d$. Next, suppose that the sets $X_0, \ldots, X_{k-1}$ have been defined. Our goal is to apply Lemma \ref{discretelemma} to $E = X_{k-1}$ and $G = Z_k$ with $l = l_{k-1}$ and $s = l_k$. This will be possible once we verify the hypothesis \eqref{ZsLarge}, which in this case takes the form
	%
	\begin{equation}
		(l_{k-1}/l_k)^d \leq \#\B_{l_k}^{dn}(Z_k) \leq 0.5 \cdot (l_{k-1}/l_k)^{dn}. \label{need-to-check}
	\end{equation}
	%
	The right hand side follows from Property \ref{SparsityProperty} of Lemma \ref{coveringLemma} and \eqref{quadDecayRequirement}. 
%imply that 
%$$
%\#\B_{l_k}^{dn}(Z_k)\leq\frac{1}{2}(l_{k-1}/l_k)^{dn}.
%$$
	On the other hand, Property \ref{SparsityProperty} and the fact that $l_{k-1} \leq 1$ implies that
	%
	\[ (l_{k-1}/l_k)^d\leq l_{k}^{-d}\leq \#\B_{l_k}^{dn}(Z_k), \]
	%
	establishing the left inequality in \eqref{need-to-check}. Applying Lemma \ref{discretelemma} as described above now produces a dyadic length
	%
	\begin{equation}\label{definOfr}
		r \sim \big(l_{k-1}^{-d}l_k^{dn} \# \B^{dn}_{l_k}(Z_k)\big)^{\frac{1}{d(n-1)}} 
	\end{equation}
	%
	and a set $F\subset X_{k-1}$ that is a union of cubes in $\B_{l_k}^{d}$. The set $F$ satisfies Properties \ref{avoidanceItem}, \ref{nonConcentrationItem}, and \ref{largeSizeItem} from the statement of Lemma \ref{discretelemma}. Define $r_k=r$ and $X_k=F$. The estimate  \eqref{rkSizeBound} on $r_k$ follows from \eqref{definOfr} using the known bounds \eqref{quadDecayRequirement} and \eqref{coveringOfBdnlZk}:
	%
	\[ r_k \lesssim \bigl( l_{k-1}^{-d}  l_k^{dn -\alpha - 0.5 \epsilon_k} \bigr)^{\frac{1}{d(n-1)}} = \bigl( l_{k-1}^{-d} l_k^{0.5 \epsilon_k} l_k^{dn -\alpha - \epsilon_k} \bigr)^{\frac{1}{d(n-1)}} = \bigl( l_{k-1}^{-2d} l_k^{\epsilon_k}\bigr)^{\frac{1}{2d(n-1)}} l_{k}^{\frac{dn-\alpha -\epsilon_k}{d(n-1)}} \lesssim l_{k}^{\frac{dn-\alpha -\epsilon_k}{d(n-1)}}. \]
	%
	The requirements \eqref{manyIkInIkm1} and \eqref{XkWellDistributed} follow from Properties \ref{nonConcentrationItem} and \ref{largeSizeItem} of Lemma \ref{discretelemma} respectively.
\end{proof} 

Now we have defined the sets $\{ X_k \}$, we set $X = \bigcap X_k$. Since $X_k$ avoids strongly non-diagonal cubes in $Z_k$, Lemma \ref{stronglydiagonal} implies that if $x_1, \dots, x_n \in X$ are distinct, then $(x_1, \dots, x_n) \not \in Z$. To finish the proof of Theorem \ref{mainTheorem}, we must show that $\hausdim(X) \geq (dn - \alpha)/(n - 1)$. This will be done in the next section. 







\section{Dimension Bounds}\label{dimensionsection}

To complete the proof of Theorem \ref{mainTheorem}, we must show that $\hausdim(X) \geq (dn - \alpha)/(n - 1)$.  %, where
%
% \[ \beta = \frac{dn - \alpha}{n - 1}. \]
In view of Definition \ref{defFrostmanItem}, we will do this by constructing a Frostman measure of appropriate dimension supported on $X$. 
%
% We begin with a rough outline of our proof strategy. Recall that from the previous section, we have a decreasing sequence of lengths $\{ l_k \}$. The most convenient way to examine the dimension of $X$ at various scales is to use Frostman's lemma (see Definition \ref{frostmanItem}). We construct a probability measure $\mu$ supported on $X$ such that for all $\varepsilon > 0$, for all dyadic lengths $l$, and for all $I \in \B^d_l$, $\mu(I) \lesssim_\varepsilon l^{\beta - \varepsilon}$. We begin by showing that for each $k\geq 1$,
% \begin{equation}\label{muIScalek}
% \mu(I) \lesssim l_k^{\beta - O(1/k)}\quad\textrm{for all}\ I \in \B^d_{l_k}.
% \end{equation}
% Heuristically, this inequality stays that $X$ looks like a set with dimension $\beta - O(1/k)$ at the scale $l_k$. Our next task will be understand the behavior of $\mu$ (and thus $X$) at scales between $l_{k-1}$ and $l_k$. This task is complicated by the fact that $l_{k}$ might be much smaller than $l_{k-1}$ (indeed, we have no effective control on how quickly the length scales $\{l_k\}$ converge to 0). Thankfully, however, the sets $X_k$ defined in the previous section are unions of cubes of sidelength $I_{l_k}$ that are somewhat uniformly distributed at scales larger than $l_k$ (this Property \ref{nonConcentrationItem} in Lemma \ref{discretelemma}); this fact will allow us to establish an analogue of \eqref{muIScalek} at intermediate scales between $l_k$ and $l_{k+1}$. 
%

We start by defining a premeasure on $\bigcup_{i = 1}^\infty \B^d_{l_i}[0,1)^d$. Set $\mu([0,1)^d) = 1$. Suppose now that $\mu(I)$ has been defined for all cubes in $\B^d_{l_{k-1}}[0,1)^d$, and let $J \in \B^d_{l_k}$. Consider the unique `parent cube' $I \in \B^d_{l_{k-1}}$ for which $J \subset I$. Define
%
\begin{equation} \label{muRecurse} 
	\mu(J) = \begin{cases} {\mu(I)}/{\# \B^d_{l_k}(X_k \cap I)} & \textrm{if}\ J \subset X_k,\\
0 & \textrm{otherwise}.
\end{cases}
\end{equation}
Observe that for each index $k\geq 1$ and each $I \in \B_{l_{k-1}}^d$, 
%
\begin{equation}\label{muBreakDown}
	\sum_{J \in \B_{l_k}^d(I)} \mu(J) = \sum_{J \in \B_{l_k}^d(X_k\cap I)} \mu(J) = \mu(I).
\end{equation}
In particular, for each index $k$ we have
%
\[ \sum_{I\in\B_{l_k}}\mu(I)=1. \]
%
By a standard argument involving the Caratheodory extension theorem \cite[Proposition 1.7]{Falconer}, the premeasure $\mu$ extends to a measure on the Borel subsets of $[0,1)^d$. Note that for each $k \geq 1$, $\mu$ is supported on $X_k$. Thus $\mu$ is supported on $\bigcap X_k = X$. To complete the proof of Theorem \ref{mainTheorem} we will show that $\mu$ is a Frostman measure of dimension $(dn - \alpha)/(n - 1)-\epsilon$ for every $\epsilon>0$. 



\begin{lemma}\label{massSomeScales}
	For each $k\geq 1$ and each $J \in \B^d_{l_k}(X)$, 
	%
	\[ \mu(J) \lesssim l_k^{\frac{dn-\alpha}{n-1}- \eta_k}, \quad \text{ where } \quad \eta_k = \frac{n+1}{2(n-1)} \cdot \epsilon_k \searrow 0 \text{ as } k \rightarrow \infty. \]
\end{lemma}
\begin{proof}
	Let $J \in \B^d_{l_k}$ and let $I \in \B^d_{l_{k-1}}$ be the parent cube of $J$. Since $\mu$ is a probability measure, we have $\mu(I) \leq 1$. Combining \eqref{muRecurse}, \eqref{manyIkInIkm1}, \eqref{rkSizeBound}, and \eqref{quadDecayRequirement} we obtain
	%
	\[ \mu(J)\leq \frac{2r_k^d}{l_{k-1}^d}\mu(I)\leq \frac{2r_k^d}{l_{k-1}^d}\lesssim \frac{l_{k}^{\frac{dn-\alpha - \epsilon_k}{n-1}}}{l_{k-1}^d}=l_k^{\frac{dn-\alpha}{n-1}-\eta_k}\big(l_k^{0.5 \epsilon_k}/l_{k-1}^d\big)\leq l_k^{\frac{dn-\alpha}{n-1}-\eta_k}.\qedhere \]
\end{proof}

\begin{corollary}\label{muAtScaleRk}
For each $k\geq 1$ and each $I' \in \B^d_{r_k} (X_{k-1})$, 
	\begin{equation} 
	\mu(I') \lesssim (r_k/l_{k-1})^d l_{k-1}^{\frac{dn-\alpha}{n-1}-\eta_{k-1}}. \label{mu-Rk}
	\end{equation} 
\end{corollary}
\begin{proof}
%Lemma \ref{massSomeScales} allows us to control $\mu$ at the scales $\{l_k\}$. 
Let us fix a cube $I' \in \B^d_{r_k}(X_{k-1})$, and let $I$ denote its unique parent cube in $\B_{l_{k-1}}^d (X_{k-1})$. According to \eqref{XkWellDistributed}, $I'$ contains at most one cube in $\B_{l_k}^d(I)$; let us denote this cube by $J$ if it exists. Then the mass distribution rule given by \eqref{muRecurse} dictates that zero
\begin{align*}
\mu(I') = \mu(X_k \cap I') = \begin{cases} \mu(J) = {\mu(I)}/{\# \B_{l_k}^d(X_k \cap I)}  &\text{ if } \# \B_{l_k}^d(X_k \cap I') = 1, \\ 0 &\text{ if } \# \B_{l_k}^d(X_k \cap I') = 0. \end{cases} 
\end{align*}
Using the estimate \eqref{manyIkInIkm1} and applying Lemma \ref{massSomeScales} to $I \in \mathcal B_{l_{k-1}}^d(X)$, we arrive at the claimed bound \eqref{mu-Rk}. 
\end{proof}
Lemma \ref{massSomeScales} and Corollary \ref{muAtScaleRk} allow us to control the behavior of $\mu$ at all scales. %To understand the behavior of $\mu$ at other scales, we will obtain a Frostman measure bound at {\it all} scales, we need to apply a covering argument. This is where the uniform mass assignment technique comes into play. Because $\mu$ behaves like a full dimensional set between the scales $l_k$ and $r_{k+1}$, we won't be penalized for making the gap between $l_k$ and $r_{k+1}$ arbitrarily large. This is essential to our argument, because $l_k$ decays faster than $2^{-k^m}$ for any $m > 0$.

\begin{lemma} \label{frostmanBound}
For every $\alpha \in [d, dn)$, and for each $\epsilon>0$, there is a constant $C_\epsilon$ so that for all dyadic lengths $l\in (0,1]$ and all $I \in \B_l^d$, we have
	\begin{equation} 
	\mu(I) \leq C_{\epsilon} l^{\frac{dn - \alpha}{n - 1} - \epsilon}. \label{mu-ball-condition} 
	\end{equation} 
\end{lemma}
\begin{proof}
	Fix $\epsilon > 0$. Since $\eta_k \searrow 0$ as $k\to\infty$, there is a constant $C_{\epsilon}$ so that $l_k^{-\eta_k}\leq C_{\epsilon}l_k^{-\epsilon}$ for each $k \geq 1$. For instance, if $\varepsilon_k$ is decreasing, we could choose $C_{\epsilon}=l_{k_0}^{-\eta_{k_0}}$, where $k_0$ is the largest integer for which $\eta_{k_0} \geq \epsilon$. Next, let $k$ be the (unique) index so that $l_{k+1}\leq l < l_{k}$. We will split the proof of \eqref{mu-ball-condition} into two cases, depending on the position of  $l$ within $[l_{k+1}, l_k]$. 
	%We now consider several cases. 
	%\begin{itemize}
	%\item If $k<k_0$, then $l\geq l_{k_0}$ and thus 
	%$$
	%\mu(I)\leq 1 = \big(l^{\frac{dn - \alpha}{n - 1} - \epsilon}\big)^{-1}\big(l^{\frac{dn - \alpha}{n - 1} - \epsilon}\big)\leq C_{\epsilon}\big(l^{\frac{dn - \alpha}{n - 1} - \epsilon}\big).
	%$$

	{\em{Case 1: }} If $r_{k+1} \leq l \leq l_k$, 
	we can cover $I$ by $(l/r_{k+1})^d$ cubes in $\B^d_{r_{k+1}}$. By Corollary \ref{muAtScaleRk},
	\begin{equation}
	\begin{split}
	\mu(I) & \lesssim (l/r_{k+1})^d (r_{k+1}/l_k)^d l_k^{\frac{dn-\alpha}{n-1}-\eta_k} \\
	& = (l/l_k)^d l_k^{\frac{dn-\alpha}{n-1}-\eta_{k}}\\
	& = l^{\frac{dn-\alpha}{n-1}} (l/l_k)^{\frac{\alpha - d}{n-1}} l_k^{-\eta_k}\\
	& \leq l^{\frac{dn-\alpha}{n-1} - \eta_k}  \\
	& \leq C_{\epsilon}l^{\frac{dn-\alpha}{n-1}-\epsilon}.
	\end{split}
	\end{equation}
The penultimate inequality is a consequence of our assumption $\alpha \geq d$. 

	{\em{Case 2: }} If $l_{k+1} \leq l \leq r_{k+1},$ we can cover $I$ by a single cube in $\B^d_{r_{k+1}}$. By \eqref{XkWellDistributed}, each cube in $\B^d_{r_{k+1}}$ contains at most one cube $I_0 \in \B^d_{l_{k+1}}(X_{k+1})$, so by Lemma \ref{massSomeScales},
	%
	\[ 
		\mu(I) \leq \mu(I_0) \lesssim l_{k+1}^{\frac{dn - \alpha}{n - 1} - \eta_{k+1}} 
		% \lesssim l_{k+1}^{\frac{dn - \alpha}{n - 1}}r_{k+1}^{-\eta_{k+1}\frac{d(n-1)}{dn-\alpha-\epsilon_{k+1}}}
		% \leq C_{\epsilon}l_{k+1}^{\frac{dn - \alpha}{n - 1}}r_{k+1}^{-\epsilon}
		\leq C_{\epsilon}l_{k+1}^{\frac{dn - \alpha}{n - 1} - \epsilon}
		\leq C_{\epsilon}l^{\frac{dn - \alpha}{n - 1} - \epsilon}.\qedhere
	\]
	%\end{itemize}

\end{proof}

Applying Frostman's lemma to Lemma \ref{frostmanBound} gives $\hausdim(X) \geq \frac{dn - \alpha}{n - 1} - \epsilon$ for every $\epsilon>0$, which concludes the proof of Theorem \ref{mainTheorem}.









\section{Applications}\label{applications}

As discussed in the introduction, Theorem \ref{mainTheorem} generalizes Theorems 1.1 and 1.2 from \cite{MalabikaRob}. In this section, we present two applications of Theorem \ref{mainTheorem} in settings where previous methods do not yield any results.

\subsection{Sum-sets avoiding specified sets}

\begin{theorem} \label{sumset-application} 
	Let $Y \subset \RR^d$ be a countable union of sets of Minkowski dimension at most $\beta < d$. Then there exists a set $X \subset \RR^d$ with Hausdorff dimension at least $d - \beta$ such that $X + X$ is disjoint from $Y$.
\end{theorem}
\begin{proof}
	Define $Z = Z_1 \cup Z_2$, where
	%
	\[ Z_1 = \{ (x,y) \setcolon x + y \in Y \} \quad \text{and} \quad Z_2 = \{ (x,y) \setcolon y \in Y/2 \}. \]
	%
	Since $Y$ is a countable union of sets of Minkowski dimension at most $\beta$, $Z$ is a countable union of sets with lower Minkowski dimension at most $d + \beta$. Applying Theorem \ref{mainTheorem} with $n = 2$ and $\alpha = d + \beta$ produces a set $X \subset \RR^d$ with Hausdorff dimension $2d  - (d + \beta) = d - \beta$ such that $(x,y) \not \in Z$ for all $x,y \in X$ with $x \neq y$. We claim that $X+ X$ is disjoint from $Y$. To see this, first suppose $x, y \in X$, $x \ne y$. Since $X$ avoids $Z_1$, we conclude that $x + y \not \in Y$. Suppose now that $x = y \in X$. Since $X$ avoids $Z_2$, we deduce that $X \cap (Y/2) = \emptyset$, and thus for any $x \in X$, $x + x = 2x \not \in Y$. This completes the proof.
\end{proof}


\subsection{Subsets of Lipschitz curves avoiding isosceles triangles}

\subsection{Subsets of Lipschitz curves avoiding isosceles triangles}

In \cite{MalabikaRob}, Fraser and the second author prove that there exists a set $S \subset [0,1]$ with dimension $\log_3 2$ such that for any simple $C^2$ curve $\gamma \colon [0,1] \to \RR^n$ with bounded non-vanishing curvature, $\gamma(S)$ does not contain the vertices of an isosceles triangle. Our method enables us to obtain a result that works for a Lipschitz curve. Currently, we are able to provide a slightly worse dimensional bound ($1/2$ instead of $\log_3 2$), and are unable to ensure uniformity across all Lipschitz curves with a given Lipschitz constant.

\begin{theorem}\label{C1IsoscelesThm}
	Let $f\colon [0,1] \to \RR^{n-1}$ be Lipschitz with $\| f \|_{\text{Lip}} < 1$. Then there is a set $X \subset [0,1]$ of Hausdorff dimension $1/2$ so that the set $\{(t,f(t)) \setcolon t\in X\}$ does not contain the vertices of an isosceles triangle.
\end{theorem}
\begin{proof}
	Set
	%
	\[ Z = \left\{ (x_1,x_2,x_3) \in [0,1]^3\setcolon \begin{array}{c} (x_1,f(x_1)), (x_2,f(x_2)), (x_3,f(x_3))\\
		\textrm{form the vertices of an isosceles triangle} \end{array} \right\}. \]
	%
	In the next lemma, we show $Z$ has lower Minkowski dimension at most two. By Theorem \ref{mainTheorem}, there is a set $X_1\subset[0,1]$ of Hausdorff dimension $1/2$ so that for each distinct $x_1,x_2,x_3\in X_1$, we have $(x_1,x_2,x_3)\not\in Z$. This is precisely the statement that for each $x_1,x_2,x_3\in X$, the points $(x_1,f(x_1)),\ (x_2,f(x_2))$, and $(x_3,f(x_3))$ do not form the vertices of an isosceles triangle. To complete the proof, let $X = \{ (x,f(x)) : x \in X_1 \}$.
\end{proof}

\begin{lemma}
	Let $f\colon [0,1] \to \RR^{n-1}$ be Lipschitz with $\| f \|_{\text{Lip}} < 1$. Then the set
	%
	\[ Z = \left\{ (x_1,x_2,x_3) \in [0,1]^3\setcolon \begin{array}{c} (x_1,f(x_1)), (x_2,f(x_2)), (x_3,f(x_3))\\
		\textrm{form the vertices of an isosceles triangle} \end{array} \right\} \]
	%
	has Minkowski dimension at most two.
\end{lemma}
\begin{proof}
	First, notice that three points $p,q,r \in \RR^n$ form an isosceles triangle, with $r$ as the apex, if and only if $r \in H_{p,q}$, where
	%
	\[ H_{p,q} = \left\{ x \in \RR^n : \left( x - \frac{p + q}{2} \right) \cdot (q - p) = 0 \right\}. \]
	%
	To prove $Z$ has Minkowski has dimension at most two, it suffices to show that the set
	%
	\[ W = \left\{ x \in [0,1]^3 : (x_3,f(x_3)) \in H_{(x_1,f(x_1)), (x_2,f(x_2))} \right\} \]
	%
	has Minkowski dimension at most 2, because $Z$ is the union of three copies of $W$, obtained by permuting coordinates.

	Fix $0 < \delta < 1$, and consider $I_1, I_2 \in \B^1_\delta[0,1]$, together with an integer $k > 0$ such that $d(I_1,I_2) = k \cdot \delta$. Let $x_1$ be the midpoint of $I_1$, and $x_2$ the midpoint of $I_2$. Suppose $(y_1,y_2,y_3) \in W \cap I_1 \times I_2 \times [0,1]$. Then
	%
	\[ \left( y_3 - \frac{y_1 + y_2}{2} \right) \cdot (y_2 - y_1) + \left( f(y_3) - \frac{f(y_2) + f(y_1)}{2} \right) \cdot (f(y_2) - f(y_1)) = 0. \]
	%
	We know $|x_1 - y_1|, |x_2 - y_2| \leq \delta/2$, so
	%
	\begin{align} \label{xyDiff}
		&\left| \left( y_3 - \frac{y_1 + y_2}{2} \right) (y_2 - y_1) - \left( y_3 - \frac{x_1 + x_2}{2} \right) (x_2 - x_1) \right| \nonumber\\
		&\ \ \ \ \ \leq \frac{|y_1 - x_1| + |y_2 - x_2|}{2} |y_2 - y_1| + \Big( |y_1 - x_1| + |y_2 - x_2| \Big) \left| y_3 - \frac{x_1 + x_2}{2} \right|\\
		&\ \ \ \ \ \leq (\delta/2) \cdot 1 + \delta \cdot 1 \leq 3\delta/2. \nonumber
	\end{align}
	%
	Conversely, we know $|f(x_1) - f(y_1)|, |f(x_2) - f(y_2)| \leq \delta/2$ because $\| f \|_{\text{Lip}} < 1$, and a similar calculation yields
	%
	\begin{align} \label{fnDiff}
	\begin{split}
		&\Big| \left( f(y_3) - \frac{f(y_1) + f(y_2)}{2} \right) \cdot (f(y_2) - f(y_1))\\
		\\&\ \ \ \ \ - \left( f(y_3) - \frac{f(x_1) + f(x_2)}{2} \right) \cdot (f(x_2) - f(x_1)) \Big|\leq 3\delta/2.
	\end{split}
	\end{align}
	%
	Putting \eqref{xyDiff} and \eqref{fnDiff} together, we conclude that
	%
	\begin{equation} \label{hyperplanethick}
		\left| \left( y_3 - \frac{x_1 + x_2}{2} \right) (x_2 - x_1) + \left( f(y_3) - \frac{f(x_2) + f(x_1)}{2} \right) \cdot (f(x_2) - f(x_1)) \right| \leq 3\delta.
	\end{equation}
	%
	Since $|(x_2-x_1,f(x_2)-f(x_1))| \geq k\delta$, we can interpret \eqref{hyperplanethick} as saying $(y_1,y_2,y_3)$ is contained in a $3/k$ thickening of the hyperplane $H_{(x_1,f(x_1)), (x_2,f(x_2))}$. Given another $y'$ contained in a $3/k$ thickening of the hyperplane, it satisfies a variant of the inequality \eqref{hyperplanethick}, we can subtract the difference between the two inequalities to conclude
	%
	\begin{equation} \label{diffinequality}
		\left| \left( y_3 - y_3' \right) (x_2 - x_1) + (f(y_3) - f(y_3')) \cdot (f(x_2) - f(x_1)) \right| \leq 6\delta.
	\end{equation}
	%
	The triangle difference inequality applied with \eqref{diffinequality} implies
	%
	\begin{align} \label{yylowbound}
	\begin{split}
		(f(y_3) - f(y_3')) \cdot (f(x_2) - f(x_1)) &\geq |y_3 - y_3'||x_2-x_1| - 6\delta \geq k\delta \cdot |y_3 - y_3'| - 6 \delta.
	\end{split}
	\end{align}
	%
	Conversely,
	%
	\begin{align} \label{yyupbound}
	\begin{split}
		(f(y_3) - f(y_3')) \cdot (f(x_2) - f(x_1)) &\leq \| f \|_{\text{Lip}}^2 |y_3 - y_3'| |x_2 - x_1| \leq \| f \|_{\text{Lip}}^2 (k+1) \delta |y_3 - y_3'|.
	\end{split}
	\end{align}
	%
	Combining \eqref{yylowbound} and \eqref{yyupbound} and rearranging gives that if $k$ is sufficiently large, depending only on $\| f \|_{\text{Lip}}$, %$k \geq 2|f|^2/(1 - |f|^2)$,
	%
	\begin{equation} |y_3 - y_3'| \leq \frac{6}{k - (k+1) \| f \|_{\text{Lip}}^2} \lesssim 1/k \end{equation} %\leq \frac{12}{k (1 - |f|^2)}. \]
	%
	so $\# \B^3_\delta(W \cap I_1 \times I_2 \times [0,1]) \lesssim 1/k$. If $k$ is too small to use this bound, we just conclude the trivial bound that $\# \B^3_\delta(W \cap I_1 \times I_2 \times [0,1]) \lesssim 1/\delta$.

	For each value of $k$, there are at most $O(1/\delta)$ pairs $(I_1,I_2)$ with $d(I_1,I_2) = k \delta$. And the maximum value of $k$ for any pairs $I_1,I_2$ is $O(1/\delta)$. Thus
	%
	\begin{align*}
		\# \B^3_\delta(W) &= \sum_{k = 0}^{O(1)} \sum_{d(I_1,I_2) = k\delta} \# \B^3_\delta(W \cap I_1 \times I_2 \times [0,1])\\
		&\ \ \ \  + \sum_{k = O(1)}^{O(1/\delta)} \sum_{d(I_1,I_2) = k\delta} \# \B^3_\delta(W \cap I_1 \cap I_2 \times [0,1])\\
		&= O(1) \cdot O(1/\delta) \cdot O(1/\delta) + O \left( \sum_{k = O(1)}^{O(1/\delta)} 1/k \right) \cdot O(1/\delta) \cdot O(1/\delta)\\
		&= O(\log(1/\delta) \cdot (1/\delta^2)).
	\end{align*}
	%
	This shows $W$ has upper Minkowski dimension at most 2.
\end{proof}

\endinput