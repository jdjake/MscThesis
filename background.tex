%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Background}
\label{ch:Background}

In this chapter we discuss the required background to understand the techniques of the pattern avoidance problem. The majority of the background in geometric measure theory can be found in other resources, e.g. in \cite{Falconer}, \cite{MattilaGeomMeasure}, or \cite{TaoHausdorff}, though not geared in particular towards the pattern avoidance problem.

\section{Configuration Avoidance}

Our main focus in this thesis is the \emph{pattern avoidance problem}. In this section, we formalize the notion of a pattern, and what it means to avoid it. Given a set $\mathbf{A}$, we let
%
\[ \Config^n(\AAA) = \{ (a_1, \dots, a_n) \in \AAA^n: a_i \neq a_j\ \text{if $i \neq j$} \}. \]
%
and
%
\[ \Config(\AAA) = \bigcup_{n = 1}^\infty \Config^n(\AAA). \]
%
We call $\Config(\AAA)$ the \emph{configuration space} of $\mathbf{A}$.

\begin{example}[Non-Colinearity]
	We say a set $X \subset \RR^d$ \emph{avoids colinear points} if no three points $x_1,x_2,x_3 \in X$ lie on a common line in $\RR^d$. Define
	%
	\[ \C = \left\{ (x, x + av, x + 2av) \in \C^3(\RR^d) : a \in \RR - \{ 0 \}, v \in \RR^d - \{ 0 \} \right\}. \]
	%
	Then $X$ avoids colinear points if and only if for any $x_1,x_2,x_3 \in X$, $(x_1,x_2,x_3) \not \in \C$.
\end{example}

\begin{example}[Isosceles Triangle Configuration]
	We say a set $X \subset \RR^2$ \emph{avoids isosceles triangles} if no three points $x_1,x_2,x_3 \in X$ form the vertices of a non-degenerate isosceles triangle. Define
	%
	\[ \C = \left\{ (x_1, x_2, x_3) \in \Config^3(\RR^2) : |x_1-x_2| = |x_1-x_3| \right\}. \]
	%
	A set $X$ avoids isosceles triangles if and only for any $x_1,x_2,x_3 \in X$, $(x_1,x_2,x_3) \not \in \C$. %Notice that $|x_1 - x_2| = |x_1 - x_3|$ holds if and only if $|x_1 - x_2|^2 = |x_1 - x_3|^2$, which is an algebraic equation in the coordinates of $x_1,x_2$, and $x_3$. Thus $\C$ is an algebraic hypersurface of degree two in $\RR^6$.
\end{example}

\begin{example}[Linear Independence Configuration]
	Let $V$ be a vector space over a field $K$. We set
	%
	\[ \C = \bigcup_{n = 1}^\infty \left\{ (x_1, \dots, x_n) \in \Config^n(V): \begin{array}{c}
			\text{there is $a_1, \dots, a_n \in K$ such that}\\
			\text{$a_1x_1 + \dots + a_nx_n = 0$}
		\end{array} \right\}. \]
	%
	A set $X \subset V$ is linearly independent in $V$ if, for any $n$, and any set of $n$ points $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in \C$. In this thesis, we will be interested in the case where $K = \QQ$, and $V = \RR$.
\end{example}

\begin{example}[Sum Set Configuration]
	Let $G$ be an abelian group, and fix $Y \subset G$. Set
	%
	\[ \C^1 = \{ g \in \Config^1(G): g + g \in Y \} \quad \text{and} \quad \C^2 = \{ (g_1,g_2) \in \Config^2(G): g_1 + g_2 \in Y \}. \]
	%
	Define $\C = \C^1 \cup \C^2$. Then $(X + X) \cap Y = \emptyset$ if and only if for any $x_1,x_2 \in X$, $(x_1,x_2) \not \in \C^2$, and for any $x \in X$, $x \not \in \C^1$.
\end{example}

All the configurations we discuss in this thesis can be specified in terms of subsets of $\Config(\AAA)$. Thus we formally define a \emph{configuration} on $\AAA$ to be a subset of $\Config(\AAA)$, and an \emph{$n$ point configuration} if it is a subset of $\Config^n(\AAA)$. For a fixed configuration $\C$ on $\AAA$, we say a set $X \subset \AAA$ \emph{avoids} $\C$ if $\Config(X)$ is disjoint from $\C$. The \emph{pattern avoidance problem} asks to find sets $X$ of maximal size avoiding a fixed configuration $\C$. Often, the configuration $\C$ describes algebraic or geometric structure, and the pattern avoidance problem asks to find the maximal size of a set before it is guaranteed to have such structure.

%\begin{example}[General Position Configuration]
%	Suppose we wish to find a subset $X$ of $\RR^d$ such that for each positive integer $k \leq d$, and for each collection of $k+1$ distinct points $x_1, \dots, x_{k+1} \in X$, the points do not lie in a $k-1$ dimensional hyperplane. For each $k \leq d$, set
	%
%	\[ \C^{k+1} = \{ (x_0, x_1, \dots, x_k) \in \Config^{k+1}(\RR^d): x_1-x_0, \dots, x_k - x_0\ \text{are linearly dependant} \}. \]
	%
%	If we define $\C = \bigcup_{k = 2}^d \C^k$, then a set $X$ avoids $\C$ precisely when all finite collection of distinct points in $X$ lie in general position. Notice that
	%
%	\[ \C^{k+1} = \bigcup \left\{ \text{span}(y_1, \dots, y_k) \times \{ y \} : y = (y_1, \dots, y_k) \in \Config^k(\RR^d) \right\} \cap \Config^{k+1}(\RR^d). \]
	%
%	so each $\C^{k+1}$ is essentially a union of $k$ dimensional hyperplanes.
%\end{example}

Depending on the structure of the ambient space $\AAA$ and the configuration $\C$, there are various ways of measuring the size of sets $X \subset \AAA$ for the purpose of the pattern avoidance problem. If $\AAA$ is finite, for instance, a natural choice is the cardinality of $X$. But our goal is to study pattern avoidance where $\AAA = \RR^d$. In certain cases, one can use the Lebesgue measure to determine the size of a pattern avoiding set. But this really only works for `discrete' configurations on $\RR^d$, as the next theorem shows, under the often true assumption that $\C$ is \emph{translation invariant}, i.e. that if $(a_1, \dots, a_n) \in \C$ and $b \in \RR^d$, $(a_1 + b, \dots, a_n + b) \in \C$.

\begin{theorem}
	Let $\C$ be a $n$-point configuration on $\RR^d$. Suppose
	%
	\begin{enumerate}
		\item \label{translationinvariance} $\C$ is translation invariant.
		\item \label{nonDiscreteConfig} For any $\varepsilon > 0$, there is $(a_1, \dots, a_n) \in \C$ with $\diam \{ a_1, \dots, a_n \} \leq \varepsilon$.
	\end{enumerate}
	%
	Then no set with positive Lebesgue measure avoids $\C$.
\end{theorem}
\begin{proof}
	Let $X \subset \RR^d$ have positive Lebesgue measure. The Lebesgue density theorem shows that there exists a point $x \in X$ such that
	%
	\begin{equation} \label{densityApplication} \lim_{l(Q) \to 0} \frac{|X \cap Q|}{|Q|} = 1, \end{equation}
	%
	where $Q$ ranges over all axis-oriented cubes in $\RR^d$ with $x \in Q$, and $l(Q)$ denotes the sidelength of $Q$. Fix $\varepsilon > 0$, to be specified later, and choose $r$ small enough that $|X \cap Q| \geq (1 - \varepsilon) |Q|$ for any cube $Q$ with $x \in Q$ and $l(Q) \leq r$. Now let $Q_0$ denote a cube centered at $x$ with $l(Q_0) \leq r$. Applying Property \ref{nonDiscreteConfig}, we find $C = (a_1, \dots, a_n) \in \C$ such that
	%
	\begin{equation} \label{equation690346024} \diam \{ a_1, \dots, a_n \} \leq l(Q_0)/2. \end{equation}
	%
	For each $p \in Q_0$, let $C(p) = (a_1(p), \dots, a_n(p))$, where $a_i(p) = p + (a_i - a_1)$. A union bound shows
	%
	\begin{equation} \label{equation548} \left| \{ p \in Q_0 : C(p) \not \in \C(X) \} \right| \leq \sum_{i = 1}^n \left| \{ p \in Q_0 : a_i(p) \not \in X \} \right|.
	\end{equation}
	%
	We have $a_i(p) \not \in X$ precisely when $p + (a_i - a_1) \not \in X$, so
	%
	\begin{equation} \label{equation1243462}
		|\{ p \in Q_0 : a_i(p) \not \in X \}| = |(Q_0 + (a_i - a_1)) \cap X^c|.
	\end{equation}
	%
	Note $Q_0 + (a_i - a_1)$ is a cube with the same sidelength as $Q_0$. Equation \eqref{equation690346024} implies $|a_i - a_1| \leq l(Q_0)/2$, so $x \in Q_0 + (a_i - a_1)$. Thus \eqref{densityApplication} shows
	%
	\begin{equation} \label{equation543} |Q_0 + (a_i - a_1)) \cap X^c| \leq \varepsilon |Q_0|. \end{equation}
	%
	Combining \eqref{equation548}, \eqref{equation1243462}, and \eqref{equation543}, we find
	%
	\[ \left| \{ p \in Q_0 : C(p) \not \in \C(X) \} \right| \leq \varepsilon n |Q_0|. \]
	%
	Provided $\varepsilon n < 1$, this means there is $p \in Q_0$ with $C(p) \in \C(X)$. Property \ref{translationinvariance} implies $C(p) \in \C$, so $X$ does not avoid $\C$.
\end{proof}

% TO DO: SWAPPING THIS RESULT FOR A DENSITY RESULT, IF WE CAN OBTAIN IT.

Since no set of positive Lebesgue measure can avoid non-discrete, translation invariant configurations, we cannot use the Lebesgue measure to quantify the size of pattern avoiding sets in this setting. Geometric measure theory provides us with a quantity which can distinguish between the size of sets of measure zero. This is the \emph{fractal dimension} of a set.

There are many variants of fractal dimension. Here we choose to use the Minkowski dimension, and the Hausdorff dimension. They assign the same dimension to any smooth manifold, but can differ for rougher sets. One major difference is that Minkowski dimension measures relative density at a single scale, whereas Hausdorff dimension measures relative density at countably many scales.









\section{Minkowski Dimension}

Given $l > 0$, and a bounded set $E \subset \RR^d$, we let $N(l,E)$ denote the \emph{covering number} of $E$, i.e. the minimum number of sidelength $l$ cubes required to cover $E$. We define the \emph{lower} and \emph{upper} Minkowski dimension as
%
\[ \lowminkdim(E) = \liminf_{l \to 0} \left[ \frac{\log(N(l,E))}{\log(1/l)} \right] \quad\text{and}\quad \upminkdim(E) = \limsup_{l \to 0} \left[ \frac{\log(N(l,E))}{\log(1/l)} \right]. \]
%
If $\upminkdim(E) = \lowminkdim(E)$, then we refer to this common quantity as the \emph{Minkowski dimension} of $E$, denoted $\minkdim(E)$. Thus $\lowminkdim(E) < s$ if there exists a sequence of lengths $\{ l_k \}$ converging to zero such that for each $k$, $E$ is covered by fewer than $(1/l_k)^s$ sidelength $l_k$ cubes, and $\upminkdim(E) < s$ if $E$ is covered by fewer than $(1/l)^s$ sidelength $l$ cubes for \emph{any} suitably small $l$.

\begin{remark}
	Any cube with sidelength $r$ is covered in $O_d(1)$ balls of radius $r$. Conversely, any ball of radius $r$ is covered by $O_d(1)$ cubes of sidelength $r$. Thus for any $r > 0$, if we temporarily define $N_B(r,E)$ to be the optimal number of radius $r$ \emph{balls} it takes to cover $E$, then $N(r,E) \sim_d N_B(r,E)$. As $r \to 0$, this means
	%
	\[ \frac{\log(N(r,E))}{\log(1/r)} = \frac{\log(N_B(r,E))}{\log(1/r)} + o(1). \]
	%
	In particular, $\lowminkdim(E) < s$ if and only if there exists a sequence of lengths $\{ r_k \}$ such that $E$ is covered by $(1/r_k)^s$ radius $r_k$ \emph{balls}, and $\upminkdim(E) < s$ if and only if $E$ is covered by $(1/r)^s$ radius $r$ \emph{balls}, for any suitably small $r > 0$.
\end{remark}

It is often easy to upper bound the Minkowski dimension of a set, simply by providing a cover of the set and counting the number of cubes that cover it. Let us now consider an example. We say a set $S \subset \RR^d$ is an $s$ dimensional \emph{Lipschitz manifold} if there exists a family of bounded, open subsets $\{ U_\alpha \}$ of $\RR^s$, together with a family of bi-Lipschitz maps $\{ f_\alpha: U_\alpha \to S \}$, such that the sets $\{ f_\alpha(U_\alpha) \}$ form a relatively open cover of $S$. Every $C^1$ manifold in $\RR^d$ is a Lipschitz manifold. This example proves useful in Chapter \ref{ch:RoughSets}.

\begin{theorem} \label{ManifoldDimensionThm}
	Let $S \subset \RR^d$ be a Lipschitz manifold of dimension $s$. Then for any compact set $K \subset S$, $\upminkdim(K) \leq s$.
\end{theorem}
\begin{proof}
	Since $K$ is compact, we can find finitely many bi-Lipschitz maps $f_1, \dots, f_N$ such that the family $\{ f_i(U_i) : 1 \leq i \leq N \}$ covers $K$. Then there is $C$ such that for each $i$, if $x,y \in U_i$,
	%
	\[ |f_i(x) - f_i(y)| \leq C \cdot |x-y|. \]
	%
	Since each $U_i$ is bounded, for any $r > 0$, we can find a family of balls $B_{i,1}, \dots, B_{i,M_i}$ of radius $(r/C)$ covering $U_i$, such that the centers $x_{i,1}, \dots, x_{i,M_i}$ of the balls also lie in $U_i$, and $M_i \lesssim (C/r)^s$. But then the balls of radius $r$ with centers lying in
	%
	\[ \{ f_i(x_{i,j}) : 1 \leq i \leq N, 1 \leq j \leq M_i \} \]
	%
	cover $K$, and there are $\sum_{i = 1}^N M_i \lesssim (N/C^s) r^{-s}$ such balls. Since $C$ and $N$ are independent of $r$, and $r > 0$ was arbitrary, this shows $\upminkdim(K) \leq s$.
\end{proof}

\section{Hausdorff Dimension}

For $E \subset \RR^d$ and $\delta > 0$, we define the \emph{Hausdorff content}
%
\[ H_\delta^s(E) = \inf \left\{ \sum_{k = 1}^\infty l(Q_k)^s : E \subset \bigcup_{k = 1}^\infty Q_k, l(Q_k) \leq \delta \right\}. \]
%
The \emph{$s$-dimensional Hausdorff measure} of $E$ is
%
\[ H^s(E) = \lim_{\delta \to 0} H_\delta^s(E) = \sup \left\{ H^s_\delta(E) : \delta > 0 \right\}. \]
%
It is easy to see $H^s$ is an exterior measure on $\RR^d$, and $H^s(E \cup F) = H^s(E) + H^s(F)$ if the Hausdorff distance $d(E,F)$ between $E$ and $F$ is positive. So $H^s$ is actually a metric exterior measure, and the Caratheodory extension theorem shows all Borel sets are measurable with respect to $H^s$. Sometimes, it is convenient to use the exterior measure
%
\[ H^s_\infty(E) = \inf \left\{ \sum_{k = 1}^\infty l(Q_k)^s : E \subset \bigcup_{k = 1}^\infty Q_k \right\}. \]
%
The majority of Borel sets which occur in practice fail to be measurable with respect to $H^s_\infty$, but the exterior measure $H^s_\infty$ has the useful property that $H^s_\infty(E) = 0$ if and only if $H^s(E) = 0$.

\begin{lemma} \label{HausdorffBoundary}
	Consider $t < s$, and $E \subset \RR^d$.
	%
	\begin{enumerate}
		\item[(i)] If $H^t(E) < \infty$, then $H^s(E) = 0$.
		\item[(ii)] If $H^s(E) \neq 0$, then $H^t(E) = \infty$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	Suppose that $H^t(E) = A < \infty$. Then for any $\delta > 0$, there is a cover of $E$ by a collection of intervals $\{ Q_k \}$, such that $l(Q_k) \leq \delta$ for each $k$, and
	%
	\[ \sum_{k = 1}^\infty l(Q_k)^t \leq A < \infty. \]
	%
	But then
	%
	\[ H^s_\delta(E) \leq \sum_{k = 1}^\infty l(Q_k)^s \leq \sum_{k = 1}^\infty l(Q_k)^{s-t} l(Q_k)^t \leq \delta^{s-t} A. \]
	%
	As $\delta \to 0$, we conclude $H^s(E) = 0$, proving \emph{(i)}. And \emph{(ii)} is just the contrapositive of (i), and therefore immediately follows.
\end{proof}

\begin{corollary} \label{corollaryhausdorffzero}
	If $s > d$, $H^s = 0$.
\end{corollary}
\begin{proof}
	The measure $H^d$ is just the Lebesgue measure on $\RR^d$, so
	%
	\[ H^d[-N,N]^d = (2N)^d. \]
	%
	If $s > d$, Lemma \ref{HausdorffBoundary} shows $H^s[-N,N]^d = 0$. By countable additivity, taking $N \to \infty$ shows $H^s(\RR^d) = 0$. Since $H^s$ is a positive measure, $H^s(E) = 0$ for all $E$.
\end{proof}

Given any Borel set $E$, Corollary \ref{corollaryhausdorffzero}, combined with Lemma \ref{HausdorffBoundary}, implies there is a unique value $s_0 \in [0,d]$ such that $H^s(E) = 0$ for $s > s_0$, and $H^s(E) = \infty$ for $0 \leq s < s_0$. We refer to $s_0$ as the \emph{Hausdorff dimension} of $E$, denoted $\hausdim(E)$.

\begin{theorem}
	For any bounded set $E$, $\hausdim(E) \leq \lowminkdim(E) \leq \upminkdim(E)$.
\end{theorem}
\begin{proof}
	Given $l > 0$, we have a simple bound $H^s_l(E) \leq N(l,E) \cdot l^s$. If $\lowminkdim(E) < s$, then there exists a sequence $\{ l_k \}$ with $l_k \to 0$, and $N(l_k,E) \leq (1/l_k)^s$. We conclude that
	%
	\[ H^s(E) = \lim_{k \to \infty} H^s_{l_k}(E) \leq \lim_{k \to \infty} N(l_k,E) \cdot l_k^s \leq 1, \]
	%
	Thus Lemma \ref{HausdorffBoundary} implies $\hausdim(E) \leq s$. Taking infima over all $s > \lowminkdim(E)$ shows $\hausdim(E) \leq \lowminkdim(E)$.
\end{proof}

\begin{remark}
	If $\hausdim(E) < d$, then $|E| = H^d(E) = 0$. Thus any set with fractal dimension less than $d$ (either Hausdorff of Minkowski) must have measure zero. This means we can use the dimension as a way of distinguishing between sets of measure zero, which is precisely what we need to study the configuration avoidance problem for non-discrete configurations.
\end{remark}

The fact that Hausdorff dimension is defined over multiple scales simultaneously makes it more stable under analytical operations. In particular, for any family of at most countably many sets $\{ E_k \}$,
%
\[ \hausdim \left\{ \bigcup E_k \right\} = \sup \left\{ \hausdim(E_k) \right\}. \]
%
This need not be true for the Minkowski dimension; a single point has Minkowski dimension zero, but $\mathbf{Q} \cap [0,1]$, which is a countable union of points, has Minkowski dimension one. An easy way to make Minkowski dimension countably stable is to define the \emph{modified Minkowski dimensions}
%
\begin{align*}
	\lmbdim(E) &= \inf \left\{ s : E \subset \bigcup_{i = 1}^\infty E_i, \lowminkdim(E_i) \leq s\ \text{for each $i$} \right\}
\end{align*}
%
and
%
\begin{align*}
	\umbdim(E) &= \inf \left\{ s : E \subset \bigcup_{i = 1}^\infty E_i, \upminkdim(E_i) \leq s\ \text{for each $i$} \right\}.
\end{align*}
%
This notion of dimension, in a disguised form, appears in Chapter \ref{ch:RoughSets}.







\section{Fourier Dimension}

A popular technique in current research in geometric measure theory is exploiting Fourier analysis to obtain additional structural information about configurations in sets. A key insight to this technique is that the Frostman dimension of any finite Borel measure $\mu$ is equal to
%
\[ \sup \left\{ s > 0 : \int \frac{|\widehat{\mu}(\xi)|^2}{|\xi|^{d-s}} d\xi < \infty \right\}. \]
%
For brevity, we leave the proof to other sources, e.g. \cite[Section 3.5]{Matilla}. Note that if
%
\[ \int \frac{|\widehat{\mu}(\xi)|^2}{|\xi|^{d-s}}\; d\xi < \infty, \]
%
then there exists a constant $C$ such that for \emph{most} values $\xi \in \RR^d$,
%
\begin{equation} \label{fourierdimensioncondition}
    |\widehat{\mu}(\xi)| \leq C |\xi|^{-s/2}.
\end{equation}
%
We obtain a strengthening of the Frostman measure condition if we require \eqref{fourierdimensioncondition} to hold for \emph{all} values $\xi$. In particular, we say a measure $\mu$ has \emph{Fourier dimension} $s$ if \eqref{fourierdimensioncondition} holds for all $\xi \in \RR^d$. If this is true, then for all $t < s$,
%
\[ \int \frac{|\widehat{\mu}(\xi)|^2}{|\xi|^{d-t}}\; d\xi < \infty \]
%
so $\mu$ has Frostman dimension $t$ for all $t < s$. Thus if we define the \emph{Fourier dimension} of a set $E$ as
%
\[ \fordim(E) = \sup \left\{ s : \begin{array}{c} \text{there is a Borel probability measure $\mu$}\\ \text{supported on $E$ with Fourier dimension $s$} \end{array} \right\}, \]
%
then $\fordim(E) \leq \hausdim(E)$.

We view the Fourier dimension as a refinement of the Hausdorff dimension which gives greater structural control on the set in the `frequency domain'. Most classical examples of fractals, like the middle-thirds Cantor set, have Fourier dimension zero. Nonetheless, one heuristic is that the Fourier dimension of \emph{random} families of sets tend to almost surely have Fourier dimension equal to their Hausdorff dimension. Our main technique in Chapter \ref{ch:RoughSets} involves a random selection strategy, and so in Section 6.2, we attempt to utilize this random selection strategy to find sets with large Fourier dimension avoiding configurations.










\section{Dyadic Scales} \label{sec:Dyadics}

It is now useful to introduce the dyadic notation we utilize throughout this thesis. At the cost of losing access to the continuous structure of $\RR^d$, applying dyadic techniques often allows us to elegantly discretize problems in Euclidean space.

Fix an integer $N$. The classic family of dyadic cubes with \emph{branching factor} $N$ is given by setting, for each integer $k \geq 0$,
%
\[ \DD_k^d = \left\{ \prod_{i = 1}^d \left[ \frac{n_i}{N^k}, \frac{n_i + 1}{N^k} \right] : n \in \ZZ^d \right\}, \]
%
and then setting $\DD^d = \bigcup_{k \geq 0} \DD_k^d$. Elements of $\DD^d$ are known as \emph{dyadic cubes}, and elements of $\DD_k^d$ are known as \emph{dyadic cubes of generation $k$}. The most important properties of the dyadic cubes is that for each $k$, $\DD_k^d$ is a cover of $\RR^d$ by cubes of sidelength $1/N^k$, and for any two cubes $Q_1,Q_2 \in \DD^d$, either their interiors are disjoint, or one cube is nested in the other.
%
\begin{itemize}
	\item For each cube $Q_1 \in \DD_{k+1}^d$, there is a unique cube $Q_2 \in \DD_k^d$ such that $Q_1 \subset Q_2$. We refer to $Q_2$ as the \emph{parent} of $Q_1$, and $Q_1$ as a \emph{child} of $Q_2$. Each cube in $\DD$ has exactly $N^d$ children. For $Q \in \DD_{k+1}^d$, we let $Q^* \in \DD_k^d$ denote its parent.

	\item We say a set $E \subset \RR^d$ is \emph{$\DD_k$ discretized} if it is a union of cubes in $\DD_k^d$. If $E$ is $\DD_k$ discretized, we define
	%
	\[ \DD_k(E) = \{ Q \in \DQ_k^d : Q \subset E \}. \]
	%
	Then $E = \bigcup \DD_k(E)$.

	\item Given $k \geq 0$, and $E \subset \RR^d$, we let
	%
	\[ E(1/N^k) = \bigcup \{ Q \in \DD_k^d : Q \cap E \neq \emptyset \}. \]
	%
	Then $E(1/N^k)$ is the smallest $\DD_k$ discretized set containing $E$ in its interior. Our choice of notation invites thinking of $E(1/N^k)$ as a discretized version of the classic $1/N^k$ thickening
	%
	\[ \{ x \in \RR^d : d(x,E) < 1/N^k \}. \]
	%
	We have no need for the standard notion of thickening in this thesis, so there is no notational conflict.
\end{itemize}
%
Since any cube is covered by at most $O_d(1)$ cubes in $\DD$ of comparable sidelength, from the perspective of geometric measure theory, working with dyadic cubes is normally equivalent to working with the class of all cubes.

Our main purpose with working with dyadic cubes is to construct \emph{fractal-type sets}. By this, we mean defining sets $X$ as the intersection of a nested family of sets $\{ X_k \}$, where each $X_k$ is $\DD_k$ discretized, and each successive set $X_{k+1}$ is obtained from $X_k$ by application of a simple, recursive procedure. Such a construction satisfies the following three properties of Falconer's definition of a fractal, as detailed in the introduction to \cite{Falconer}:
%
\begin{itemize}
	\item[(i)] $X$ has detail on arbitrarily small scales.
	\item[(ii)] $X$ is too irregular to be described in traditional geometric language.
	\item[(v)] $X$ is defined recursively.
\end{itemize}
%
This justifies the term `fractal' when used to referring about these sets.

\begin{example}
	Let us construct the middle thirds Cantor set $C$ as a fractal-type set. We form $C$ from the family of dyadic cubes with branching factor $N = 3$. We initially set $C_0 = [0,1]$. Then, given the $\DD_k$ discretized set $C_k$, we consider each $I \in \DD_k^1(C_k)$, and let $\DD_{k+1}^1(I) = \{ I_1, I_2, I_3 \}$, where $I_1, I_2, I_3$ are given in increasing order with respect to their appearance in $I$. We set
	%
	\[ C_{k+1} = \bigcup \{ I_1 \cup I_3 : I \in \DD_k^1(C_k) \}. \]
	%
	Then $C = \bigcap_{k \geq 0} C_k$ is the Cantor set.
\end{example}

Unfortunately, a \emph{constant} branching factor is not sufficient to describe the types of recursive procedures we discuss in this thesis. Thus, we introduce a more general family of cubes. Instead of a single branching factor $N$, we fix a sequence of positive integers $\{ N_k : k \geq 1 \}$, with $N_k \geq 2$ for all $k$, which gives the branching factor at each stage of the class of cubes we define.
%
\begin{itemize}
	\item For each $k \geq 0$, we define 
	%
	\[ \DQ_k^d = \left\{ \prod_{i = 1}^d \left[ \frac{m_i}{N_1 \dots N_k}, \frac{m_i + 1}{N_1 \dots N_k} \right] : m \in \ZZ^d \right\}. \]
	%
	These are the \emph{dyadic cubes of generation $k$}. We let $\DQ^d = \bigcup_{k \geq 0} \DQ_k^d$. Note that any two cubes $\DQ^d$ are either nested within one another, or their interiors are disjoint.

	\item We set $l_k = (N_1 \dots N_k)^{-1}$. Then $l_k$ is the sidelength of the cubes in $\DQ_k^d$.

	\item Given $Q \in \DQ_{k+1}^d$, we let $Q^* \in \DQ_k^d$ denote the \emph{parent cube} of $Q$, i.e. the unique dyadic cube of generation $k$ such that $Q \subset Q^*$.

	\item We say a set $E \subset \RR^d$ is \emph{$\DQ_k$ discretized} if it is a union of cubes in $\DQ_k^d$. In this case, we let
	%
	\[ \DQ_k(E) = \{ Q \in \DQ_k^d: Q \subset E \} \]
	%
	denote the family of cubes whose union is $E$.

	\item For $E \subset \RR^d$ and $k \geq 0$, we let $E(l_k) = \{ Q \in \DQ_k^d : Q \cap E = \emptyset \}$.
\end{itemize}
%
%The most common class of dyadic cubes in analysis is obtained by setting $N_k = 2$ for each $k$. We reserve a special notation for this class of dyadic cubes; the class of all such cubes is denoted by $\DD^d$, and the generation $k$ cubes by $\DD^d_k$. The fact that the sequence $\{ N_k \}$ is constant makes these cubes more easy to analyze. But in our methods, it is necessary for the sequence $\{ N_k \}$ to become unbounded as $k \to \infty$. This is why we have to introduce the more general family of dyadic cubes introduced above.
%
Sometimes, our recursive constructions need a family of `intermediary' cubes that lie between the scales $\DQ_k^d$ and $\DQ_{k+1}^d$. In this case, we consider a supplementary sequence $\{ M_k : k \geq 1 \}$ with $M_k \divides N_k$ for each $k$.
%
\begin{itemize}
	\item For $k \geq 1$, we define
	%
	\[ \DR_k^d = \left\{ \prod_{i = 1}^d \left[ \frac{m_i}{N_1 \dots N_{k-1} M_k} , \frac{m_i + 1}{N_1 \dots N_{k-1} M_k} \right] : m \in \mathbf{Z}^d \right\}. \]

	\item We set $r_k = (N_1 \dots N_{k-1} M_k)^{-1}$. Then $r_k$ is the sidelength of a cube in $\DR_k^d$.

	\item The notions of being $\DR_k^d$ discretized, the collection of cubes $\DR_k^d(E)$, and the sets $E(r_k)$, are defined as should be expected.
\end{itemize}
%
The cubes in $\DR_k^d$ are coarser than those in $\DQ_k^d$, but finer than those in $\DQ_{k-1}^d$.

\begin{remark}
	We note that there is some notational conflict between the cubes $\DD^d$ and the cubes $\DQ^d$, but since we never use both families simultaneously in a single argument, it should be clear which notation we are using.
\end{remark}

%For the purposes of discretization, and to simplify notation, it is very useful to identify those cubes in $\DQ_k^d$ which are subsets of $[0,1]^d$ with the set
%
%\[ \Sigma_k^d = [N_1]^d \times \dots \times [N_k]^d. \]
%
%Given $j \in \Sigma_m^d$, we let $Q_j \in \DQ_m^d$ denote the cube with left-hand corner $a = \sum_{k = 1}^m j_kl_k$. Thus subcubes of a cube corresponding to an index $j \in \Sigma_k^d$ correspond to indices obtained by appending additional integers onto $j$. In the case of intermediary scales, we abuse notation, writing $[N_k] = [K_k] \times [M_k]$, we have
%
%\[ \Sigma_k^d = \big([K_1] \times [M_1] \big)^d \times \dots \times \big([K_k] \times [M_k] \big)^d, \]
%
%where $n \in [N_k]$ is equal to $(k,m) \in [K_k] \times [M_k]$, where $k M_k + m = n$.

%One very useful property of the cubes in $\DQ^d$ is that cubes are either nested within one another, or \emph{almost disjoint} from one another, in the sense that only their boundaries intersect. Thus we can think of $\DQ^d$ as a forest under the partial ordering of inclusion, with the roots corresponding to the elements of $\DQ_0^d$. Each cube $Q \in \DQ^d_k$ has $N_{k+1}^d$ children. For each cube $Q \in \DQ_{k+1}^d$, we will let $Q^* \in \DQ_k^d$ denote it's parent, i.e. the unique cube in $\DQ_k^d$ with $Q \subset Q^*$. Similarily, given an index $I = (I_0, \dots, I_{k+1}) \in \Sigma_{k+1}$, we let $I^* = (I_0, \dots, I_k) \in \Sigma_k$, so that $Q_I \subset Q_{I^*}$.

%We often construct configuration avoiding sets as limits of dyadic discretizations. It is most convenient to describe this construction in terms of a sequence of sets $\{ S_k \}$ with $S_k \subset \Sigma_k^d$ for each $k$, and $(S_{k+1})^* \subset S_k$ for each $k$. We refer to such a sequence as a \emph{constructing sequence}. We can define $E_k = \bigcup \{ Q_j : j \in S_k \}$. Then $E_{k+1} \subset E_k$ for each $k$, and we can form a set $\bigcap E_k$, which is the final, non discretized limit of the sequence of discretizations.

%We can also give the spaces $\Sigma_k^d$ and $\Sigma^d$ a metric space structure, by defining, for $I \neq J$, $d(I,J) = l_k$, where $k$ is the smallest index such that $I_k \neq J_k$. Aside from the fact that some points in $\RR^d$ are duplicated in $\Sigma^d$, the main difference between the two spaces is that the balls in $\Sigma^d$ are discretized to the scales $\{ l_k \}$. From the point of view of geometric measure theory, the first point is neglible, but we shall find that discretization does matter. The degree to which the geometry of $\Sigma^d$ models the geometry of $\RR^d$ from the perspective of geometric measure theory is a key topic in this thesis. We shall find that the rate at which the lengths $l_k$ tend to zero will be a key factor in this relationship.

\section{Frostman Measures}

%\begin{example}
%	Let $s = 0$. Then $H_\delta^0(E)$ is the number of $\delta$ balls it takes to cover $E$, which tends to $\infty$ as $\delta \to 0$ unless $E$ is finite, and in the finite case, $H_\delta^0(E) \to \# E$. Thus $H^0$ is just the counting measure.
%\end{example}

%\begin{example}
%	Let $s = d$. If $E$ has Lebesgue measure zero, then for any $\varepsilon > 0$, there exists a sequence of balls $\{ B(x_k,r_k) \}$ covering $E$ with
	%
%	\[ \sum_{k = 1}^\infty r_k^d < \varepsilon^d. \]
	%
%	Then we know $r_k < \varepsilon$, so $H^s_\varepsilon(E) < \varepsilon^d$. Letting $\varepsilon \to 0$, we conclude $H^d(E) = 0$. Thus $H^d$ is absolutely continuous with respect to the Lebesgue measure. The measure $H^d$ is translation invariant, so $H^d$ is actually a constant multiple of the Lebesgue measure.
%\end{example}

It is often easy to upper bound Hausdorff dimension, but non-trivial to \emph{lower bound} the Hausdorff dimension of a given set. A key technique to finding a lower bound is \emph{Frostman's lemma}, which says that a set has large Hausdorff dimension if and only if it supports a Borel measure obeying a decay law on small sets. We say a finite Borel measure $\mu$ is a \emph{Frostman measure} of dimension $s$ if it is non-zero, compactly supported, and there exists $C > 0$ such that for any cube $Q$, $\mu(Q) \leq C \cdot l(Q)^s$. The proof of Frostman's lemma will utilize a technique often useful, known as the \emph{mass distribution principle}. To prove the mass distribution principle, we apply weak convergence.

\begin{comment}

\begin{lemma}
	For each $k \geq 0$, let $\mathcal{E}_k$ be a finite collection of non-empty, compact, disjoint subsets of $\RR^d$, such that for each $A \in \mathcal{E}_{k+1}$, there is a unique $A^* \in \mathcal{E}_k$ such that $A \subset A^*$, and for any $A^* \in \mathcal{E}_k$, there is at least one $A \in \mathcal{E}_{k+1}$ with $A \subset A^*$. Let $E_k = \bigcup \mathcal{E}_k$, and let $E_\infty = \bigcap E_k$. Let $\mu: \bigcup_{k \geq 0} \mathcal{E}_k \to [0,\infty)$ be a function such that for any $i$, and for any $A \in \mathcal{E}_i$,
	%
	\begin{equation} \label{equation124069350740597} \mu(A) = \sum \{ \mu(B) : B \in \mathcal{E}_{i+1}, B \subset A \}. \end{equation}
	%
	Then $\mu$ extends to a finite Borel measure on $\RR^d$ supported on $E_\infty$.
\end{lemma}
\begin{proof}
	Let $\mathcal{E} = \bigcup_{k \geq 0} \mathcal{E}_k \cup \mathcal{P}(\RR^d - E_k)$. Then $\mathcal{E}$ is a \emph{semi-ring} of sets:
	%
	\begin{itemize}
		\item \emph{$\mathcal{E}$ is closed under intersections}: Let $A, B \in \mathcal{E}$. Then without loss of generality, swapping $A$ and $B$ if necessary, there exists $i \leq j$ such that $A \in \mathcal{E}_i$ or $A \subset \RR^d - E_i$, and $B \in \mathcal{E}_j$ or $B \subset \RR^d - E_j$.

		If $A \in \mathcal{E}_i$, and $B \in \mathcal{E}_j$, then either $A \cap B = \emptyset$, or $B \subset A$, and $A \cap B = B$. In either case, $A \cap B \in \mathcal{E}$.

		If $A \subset \RR^d - E_i$, then $A \cap B \subset A \subset \RR^d - E_i$, so $A \cap B \in \mathcal{E}$. Similarily, if $B \subset \RR^d - E_j$, then $A \cap B \subset \RR^d - E_j$, so $A \cap B \in \mathcal{E}$.

		This addresses all cases.

		\item \emph{$\mathcal{E}$ is closed under relative complements}: Let $A,B \in \mathcal{E}$. Then there exists $i,j$ such that $A \in \mathcal{E}_i$ or $A \subset \RR^d - E_i$, and $B \in \mathcal{E}_j$ or $B \subset \RR^d - E_j$.

		Suppose $A \in \mathcal{E}_i$ and $B \in \mathcal{E}_j$. If $i \geq j$, then either $A \cap B = \emptyset$, or $A \subset B$. In either case, $A - B = \emptyset \in \mathcal{E}$. If $i \leq j$, then either $A \cap B = \emptyset$, or $B \subset A$. In the latter case,
		%
		\[ A - B = \left( \bigcup \{ C : C \in \mathcal{E}_j, C \neq B, C \subset A \} \right) \cup \{ A - E_j \}. \]
		%
		This gives $A - B$ as a disjoint union of elements of $\mathcal{E}$.

		Suppose $A \in \mathcal{E}_i$, and $B \subset \RR^d - E_j$. If $i \geq j$, then $A \subset E_i \subset E_j$, so $A - B = A$. If $i \leq j$, then
		%
		\[ A - B = (A \cap E_j) \cup (A \cap (\RR^d - B)). \]
		%
		The former set can be written as $\bigcup \{ A' \in \mathcal{E}_j : A' \subset A \}$, and the latter set is a subset of $\RR^d - E_j$. This gives $A - B$ as a disjoint union of elements of $\mathcal{E}$.

		If $A \subset \RR^d - E_i$, then $A - B \subset \RR^d - E_i$, so $A - B \in \mathcal{E}$.

		This addresses all cases.
	\end{itemize}
	%
	The function $\mu$ extends to a function on $\mathcal{E}$ by setting $\mu(E) = 0$ if $E \subset \RR^d - E_k$ for some $k$. This does not conflict with our previous definition, since if $A \in \mathcal{E}_i$, then $A \cap E_j \neq \emptyset$ for all $j \geq 0$. We claim that $\mu$ is then a \emph{pre-measure} on the semi-ring:
	%
	\begin{itemize}
		\item It is certainly true that $\mu(\emptyset) = 0$.

		\item Let $A \in \mathcal{E}$, and suppose $A = \bigcup_i A_i$, where $\{ A_i \}$ is an at most countable subcollection of disjoint sets from $\mathcal{E}$. We fix $k$ such that $A \in \mathcal{E}_k$, or $A \subset \RR^d - E_k$, and for each $i$, fix $k_i$ such that $A_i \in \mathcal{E}_{k_i}$, or $A \subset \RR^d - E_{k_i}$.

		If $A \in \RR^d - E_k$ for some $k$, then $A_i \in \RR^d - E_k$ for each $i$, and thus $\mu(A_i) = 0$ for all $i$. Since $\mu(A) = 0$, this means $\mu(A) = \sum \mu(A_i)$.

		Suppose $A \in \mathcal{E}_k$, and let $A_\infty = A \cap E_\infty$. If $B \in \mathcal{E}_k$ for any $k$, then $B \cap A_\infty$ is \emph{relatively open} in $A_\infty$ because the sets in $\mathcal{E}_k$ cover $A_\infty$ and are separated. Note that $A_\infty \cap (\RR^d - E_k) = \emptyset$ for all $k$. Thus the family of sets $\{ A_i : A_i \in \mathcal{E}_{k_i} \}$ is a relatively open cover of $A_\infty$. Since $A_\infty$ is compact, it must have a finite subcover. But applying compactness, $A_i \cap A_\infty \neq \emptyset$ for all $i$ with $A_i \in \mathcal{E}_{k_i}$, so we conclude the set $\{ A_i : A_i \in \mathcal{E}_{k_i} \}$ is finite.

		Since the family of $A_i$ with $A_i \in \mathcal{E}_{k_i}$ is finite, we can repeatedly apply \eqref{equation124069350740597} so that, without loss of generality, we may assume there is a common integer $N$ such that $A_i \in \mathcal{E}_N$ for all $i$ with $\mu(A_i) > 0$. To prove that $\mu(A) = \sum \mu(A_i)$, it now suffices to show that for each $B \in \mathcal{E}_N$ with $B \subset A$, $B = A_i$ for some $i$. But this is obvious, since $\{ A_i : A_i \in \mathcal{E}_N \}$ covers $A_\infty$, and every such $B$ satisfies $B \cap A_\infty \neq \emptyset$.
	\end{itemize}
	%
	The Caratheodory extension theorem guarantees that $\mu$ extends to a measure on the $\sigma$ algebra generated by $\mathcal{E}$, denoted $\sigma(\mathcal{E})$. We claim this $\sigma$ algebra contains all Borel sets. Let $F$ be a closed set. Then
	%
	\[ F \cap E_\infty = \bigcap_k \left[ \bigcup \{ A : A \in \mathcal{E}_k, A \cap F \neq \emptyset \} \right] = \bigcap_k \left[ G_k \right]. \]
	%
	Each of the sets $G_k$ is a finite union of elements in $\mathcal{E}_k$, hence $G_k \in \sigma(\mathcal{E})$, and so $F \cap E_\infty = \bigcap_k G_k \in \sigma(\mathcal{E})$. We also find
	%
	\[ F \cap E_\infty^c = \bigcup_k F \cap (\RR^d - E_k) = \bigcup_k G_k'. \]
	%
	Since $G_k' \in \mathcal{E}$ for all $k$, we conclude $F \cap E_\infty^c \in \sigma(\mathcal{E})$. Thus
	%
	\[ F = (F \cap E_\infty) \cup (F \cap E_\infty^c) \in \sigma(\mathcal{E}). \]
	%
	Since $F$ was an arbitrary closed set, this implies all Borel sets are measurable with respect to $\sigma(\mathcal{E})$.
\end{proof}

\end{comment}

\begin{lemma} \label{weakstarcompleteness}
	Suppose $\{ \mu_i \}$ is a Cauchy sequence of non-negative, regular Borel measures on $\RR^d$, in the sense that for any $f \in C_c(\RR^d)$, the sequence
	%
	\[ \left\{ \int f d\mu_i \right\} \]
	%
	is Cauchy. Then there is a regular Borel measure $\mu$ such that $\mu_i \to \mu$ weakly, in the sense that for any $f \in C_C(\RR^d)$,
	%
	\[ \int f d\mu = \lim_{i \to \infty} \int f d\mu_i. \]
\end{lemma}
\begin{proof}
	Fix a compact set $K$. Then we can find a function $\varphi \in C_c(\RR^d)$ such that $\mathbf{I}_K \leq \varphi$. This means that
	%
	\[ \mu_i(K) = \int \mathbf{I}_K d\mu_i \leq \int \varphi d\mu_i. \]
	%
	Since $\{ \int \varphi d\mu_i \}$ is Cauchy, the values $\int \varphi d\mu_i$ are uniformly bounded in $i$. In particular, $\mu_i(K)$ is uniformly bounded in $i$. Applying the Banach Alaoglu theorem, we conclude that the collection of measures $\{ \mu_i|_K \}$ is contained in a compact subset of the space of non-negative Borel measures with respect to the weak $*$ topology. But every compact subset of a locally convex space is complete, and so we can therefore find a finite Borel measure $\mu^K$ supported on $K$ such that $\mu_i|_K \to \mu^K$ weakly.

	If $f \in C_c(\RR^d)$ is supported on $K_1 \cap K_2$, for two compact sets $K_1$ and $K_2$, then
	%
	\[ \int f d\mu^{K_1} = \lim_{i \to \infty} \int_{K_1} f d\mu_i = \lim_{i \to \infty} \int_{K_2} f d \mu_i = \int f d\mu^{K_2}. \]
	%
	Thus we can define a measure $\mu$ such that for each $f \in C_c(\RR^d)$, if $f$ is supported on a compact set $K$, then
	%
	\[ \int f d\mu = \int f d\mu^K. \]
	%
	For any $f \in C_c(\RR^d)$, $f$ is supported on some compact set $K$, and then
	%
	\[ \int f d\mu = \int f d\mu^K = \lim_{i \to \infty} \int_K f d\mu_i = \lim_{i \to \infty} \int f d\mu_i. \]
	%
	Since $f$ was arbitrary, $\mu_i \to \mu$ weakly.
\end{proof}

\begin{comment}

\begin{lemma}
	For each $k$, let $\mathcal{E}_k$ be a finite collection of closed sets, such that for any $A \in \mathcal{E}_{k+1}$, we fix $A^* \in \mathcal{E}_k$ such that $A \subset A^*$. Suppose that for any $A' \in \mathcal{E}_k$, there is at least one $A \in \mathcal{E}_{k+1}$ such that $A^* = A'$. Let $f: \bigcup_k \mathcal{E}_k \to [0,\infty)$ be a function such that for any $A' \in \mathcal{E}_k$,
	%
	\begin{equation} \label{equation73234091} \sum \{ f(A) : A^* = A' \} = f(A'). \end{equation}
	%
	Then there exists a regular Borel measure $\mu$ supported on
	%
	\[ \bigcap_{k = 1}^\infty \bigg\{ \overline{\bigcup \{ A : A \in \mathcal{E}_k : f(A) > 0 \}} \bigg\} \]
	%
	such that for each $k$, and each $A \in \mathcal{E}_k$,
	%
	\begin{equation} \label{massdissupperbound} \mu(A) \geq f(A), \end{equation}
	%
	and for any Borel $E$,
	%
	\begin{equation} \label{massdisslowerbound} \mu(E) \leq \sum f(A), \end{equation}
	%
	where $A$ ranges over elements of $\mathcal{E}_k$ with $A \cap E \neq \emptyset$.
\end{lemma}

\end{comment}

\begin{theorem}[Mass Distribution Principle] \label{massdistributionprinciplelem}
	Let $w: \DQ^d \to [0,\infty)$ be a function such that for any $Q_0 \in \DQ^d$,
	%
	\begin{equation} \label{equation73234091} \sum_{Q^* = Q_0} w(Q) = w(Q_0). \end{equation}
	%
	Then there exists a regular Borel measure $\mu$ supported on
	%
	\[ \bigcap_{k = 1}^\infty \left[ \bigcup \{ Q \in \DQ_k^d : w(Q) > 0 \} \right], \]
	%
	such that for each $Q \in \DQ^d$,
	%
	\begin{equation} \label{massdissupperbound} \mu(Q^\circ) \leq w(Q) \leq \mu(Q), \end{equation}
	%
	and for any set $E$ and $k \geq 0$, if $\mathcal{E}_k = \DQ_k(E(l_k))$, then
	%
	\begin{equation} \label{massdisslowerbound} \mu(E) \leq \sum_{Q \in \mathcal{E}_k} w(Q). \end{equation}
\end{theorem}
\begin{proof}
	For each $i$, let $\mu_i$ be a regular Borel measure such that for each $j \leq i$, and $Q \in \DQ_j^d$, $\mu_i(Q) = \mu_i(Q^\circ) = w(Q)$. One such choice is given, for each $\varphi \in C_c(\RR^d)$, by the equation
	%
	\[ \int \varphi d\mu_i = \sum_{Q \in \DQ_i^d} \frac{w(Q)}{|Q|} \int_Q \varphi\; dx. \]
	%
	We claim that $\{ \mu_i \}$ is a Cauchy sequence. Fix $\varphi \in C_c(\RR^d)$, and choose some $N$ such that $\varphi$ is supported on $[-N,N]^d$. Set $Q' = [-N,N]^d$, and for each $i$, set $\mathcal{Q}'_i = \DQ_i(Q')$. Since $\varphi$ is compactly supported, $\varphi$ is \emph{uniformly continuous}, so for each $\varepsilon > 0$, if $i$ is suitably large, there is a sequence of values $\{ a_Q : Q \in \DQ_i^d(Q') \}$ such that if $x \in Q$, $|\varphi(x) - a_Q| \leq \varepsilon$. But this means
	%
	\[ \sum_{Q \in \mathcal{Q}'_i} (a_Q - \varepsilon) \mathbf{I}_Q \leq \varphi \leq \sum_{Q \in \mathcal{Q}'_i} (a_Q + \varepsilon) \mathbf{I}_Q. \]
	%
	Thus for any $j \geq i$,
	%
	\[ \int \varphi\; d\mu_j\leq \sum_{Q \in \mathcal{Q}'_i} (a_Q + \varepsilon) \mu_j(Q) = \sum_{Q \in \mathcal{Q}'_i} (a_Q + \varepsilon) w(Q) \]
	%
	and
	%
	\[ \int \varphi\; d\mu_j \geq \sum_{Q \in \mathcal{Q}'_i} (a_Q - \varepsilon) \mu_j(Q) = \sum_{Q \in \mathcal{Q}'_i} (a_Q - \varepsilon) w(Q). \]
	%
	In particular, if $j,j' \geq i$,
	%
	\[ \left| \int \varphi d\mu_j - \int \varphi d\mu_{j'} \right| \leq 2 \varepsilon \sum_{Q \in \mathcal{Q}'_i} w(Q). \]
	%
	Repeated applications of \eqref{equation73234091} show that
	%
	\[ \sum_{Q \in \mathcal{Q}'_i} w(Q) = \sum_{Q \in \mathcal{Q}'_0} w(Q), \]
	%
	which is therefore bounded independently of $i$. Since $\varepsilon$ and $\varphi$ were arbitrary, this shows $\{ \mu_i \}$ is Cauchy.

	Applying Lemma \ref{weakstarcompleteness}, we find a regular Borel measure $\mu$ such that $\mu_i \to \mu$ weakly. For any $Q \in \DQ^d$, since $Q$ is a closed set,
	%
	\[ \mu(Q) \geq \limsup_{i \to \infty} \mu_i(Q) = w(Q), \]
	%
	and since $Q^\circ$ is an open set,
	%
	\[ \mu(Q^\circ) \leq \liminf_{i \to \infty} \mu_i(Q^\circ) = w(Q). \]
	%
	This establishes \eqref{massdissupperbound}. Conversely, if $E$ is arbitrary, then $E \subset E(l_i)^\circ$ for any $i$, so if $\mathcal{E}_i = \DQ_i(E(l_i))$, then
	%
	\[ \mu(E) \leq \liminf_{i \to \infty} \mu_i(E(l_i)^\circ) \leq \liminf_{i \to \infty} \mu_i(E(l_i)) = \sum_{Q \in \mathcal{E}_i} w(Q). \]
	%
	This establishes \eqref{massdisslowerbound}.
\end{proof}

\begin{remark}
	The reason why we cannot necessarily find a function $\mu$ which \emph{precisely} extends $w$ is that in the weak limit, mass from cubes can `leak' into the mass of adjacent cubes. This is why we must use the weaker `extension bounds' \eqref{massdissupperbound} and \eqref{massdisslowerbound}. This doesn't cause us to `gain' or `lose' any mass in the weak limit, as \eqref{massdissupperbound} shows, so the result is still a `mass distribution' result. It just means that the mass specified by $w$ may be shared by adjacent cubes in the weak limit. If, for each $Q' \in \DQ^d$,
	%
	\[ \lim_{k \to \infty} \sum_{Q \in \mathcal{Q}'_k} w(Q) = 0, \]
	%
	where $\mathcal{Q}'_k = \DQ_k(Q'(l_k)) - \DQ_k(Q')$, then \eqref{massdissupperbound} and \eqref{massdisslowerbound} together imply we actually have $\mu(Q) = w(Q)$ for all $Q \in \DQ$. Thus $\mu$ is a measure extending $w$. One such condition that guarantees this is that $w(Q) \lesssim l(Q)^s$ for some $s > d-1$. Another is that for any $k \geq 0$, and distinct $Q_0, Q_1 \in \DQ_k^d$ with $Q_0 \cap Q_1 \neq \emptyset$, either $w(Q_0) = 0$ or $w(Q_1) = 0$.
\end{remark}

%\begin{lemma}
%	let $\mu^+$ be a function from $\B$ to $[0,\infty)$ such that for any $I \in \B(1/M^k,\RR^d)$,
	%
%	\[ \sum \left\{ \mu^+(J) :J \in \B(1/M^{k+1},I) \right\} \leq \mu^+(I) \]
	%
%	Assume there exists $c > 0$ such that for all $k$,
	%
%	\[ \sum \left\{ \mu^+(I) : I \in \B(1/M^k,I) \right\} \geq c \]
	%
%	and
	%
%	\[ \sum \left\{ \mu^+(I) : I \in \B(1,I) \right\} < \infty \]	
	%
%	Then there exists a non-zero Borel measure $\mu$ such that $\mu(I) \leq \mu^+(I)$ for $I \in \B$.
%\end{lemma}
%\begin{proof}
%	As in the last lemma, define the operators $E_k$ and the measures $\mu_k$. By weak compactness, a subsequence of these measures converge weakly to some measure $\mu$, and $E_k(\mu) = \lim E_k(\mu_{j_k}) \leq \mu_k$. The measure $\mu$ is nonzero, since $\| \mu_{j_k} \| \geq c$ for each $k$, and so $\| \mu \| \geq c$.
%\end{proof}

\begin{theorem}[Frostman's Lemma]
	If $E$ is a Borel set, $H^s(E) > 0$ if and only if there exists an $s$ dimensional Frostman measure supported on $E$.
\end{theorem}
\begin{proof}
	Suppose that $\mu$ is $s$ dimensional and supported on $E$. If $H^s(F) = 0$, then for each $\varepsilon > 0$ there is a sequence of cubes $\{ Q_k \}$ whose union covers $F$, with $\sum_{k = 1}^\infty l(Q_k)^s \leq \varepsilon$. But then
	%
	\[ \mu(F) \leq \sum_{k = 1}^\infty \mu(Q_k) \lesssim \sum_{k = 1}^\infty l(Q_k)^s \leq \varepsilon. \]
	%
	Taking $\varepsilon \to 0$, we conclude $\mu(F) = 0$. Thus $\mu$ is absolutely continuous with respect to $H^s$. Since $\mu(E) > 0$, this means that $H^s(E) > 0$.

	To prove the converse, we will suppose for simplicity that $E$ is compact. We work dyadically with the classical family of dyadic cubes $\DD$, with branching factor $N = 2$.  By translating, we may assume that $H^s(E \cap [0,1]^d) > 0$, and so without loss of generality we may assume $E \subset [0,1]^d$. For each $Q \in \DD^d$, define $w^+(Q) = H^s_\infty(E \cap Q)$. Then
	%
	\begin{equation} \label{equation7099014901209} w^+(Q) \leq l(Q)^s, \end{equation}
	%
	and $w^+$ is subadditive. We now recursively define a function $w$ such that for any $Q \in \DQ^d$, \eqref{equation73234091} and
	%
	\begin{equation} \label{equation104-240-640954} w(Q) \leq w^+(Q), \end{equation}
	%
	are satisfied at each stage of the definition of $w$. We initially define $w$ by setting $w([0,1]^d) = w^+([0,1]^d)$. Given $Q \in \DD_k^d$, we enumerate its children as $Q_1, \dots, Q_M \in \DD_{k+1}^d$. We then consider any values $A_1, \dots, A_M \geq 0$ such that
	%
  	\begin{equation} \label{equation3424209034}
  		A_1 + \dots + A_M = w(Q),
  	\end{equation}
  	%
  	and for each $k$,
  	%
  	\begin{equation} \label{equation12039123012}
  		A_k \leq w(Q_k).
  	\end{equation}
	%
	This is feasible to do because $w^+(Q_1) + \dots + w^+(Q_M) \geq w^+(Q)$, and \eqref{equation104-240-640954} holds for the previous definition of $w$. We then define $w(Q_k) = A_k$ for each $k$. Equation \eqref{equation3424209034} implies \eqref{equation73234091} holds for this new set of definitions, and \eqref{equation12039123012} implies \eqref{equation104-240-640954} holds. Thus $w$ is a well defined function. Furthermore, \eqref{equation3424209034} implies \eqref{equation73234091} of Lemma \ref{massdistributionprinciplelem}, and so the mass distribution principle gives the existence of a measure $\mu$ supported on $E$, satisfying \eqref{massdisslowerbound} and \eqref{massdissupperbound}. In particular, \eqref{massdisslowerbound} implies $\mu$ is non-zero. For each $Q' \in \DD_k^d$, $\#[\DD_k^d(Q(l_k))] = 3^d = O_d(1)$, so if we define $\mathcal{Q}' = \DD_k^d(Q(l_k))$, then \eqref{massdissupperbound}, \eqref{equation7099014901209}, and \eqref{equation104-240-640954} imply
	%
	\[ \mu(Q') \lesssim_d \max_{Q \in \mathcal{Q}'} w^+(Q) \leq 1/2^{ks} = l(Q)^s. \]
	%
	where $Q'$ ranges over the cubes in $\DD_k^d(Q(l_k))$. Given any cube $Q$, we find $k$ with $1/2^{k-1} \leq l(Q) \leq 1/2^k$. Then $Q$ is covered by $O_d(1)$ dyadic cubes in $\DD_k^d$, and so $\mu(Q) \lesssim l(Q)^s$. Thus $\mu$ is a Frostman measure of dimension $s$.
\end{proof}

Given any finite Borel measure $\mu$, we let
%
\[ \hausdim(\mu) = \left\{ s : \mu\ \text{is a Frostman measure of dimension $s$} \right\}. \]
%
Frostman's lemma says that for any Borel set $E$, $\hausdim(E)$ is the supremum of $\hausdim(\mu)$, over all measures $\mu$ supported on a closed subset of $E$. We refer to $\hausdim(\mu)$ as the \emph{Frostman dimension} of the measure $\mu$.

\begin{comment}

Frostman's lemma implies that to study the Hausdorff dimension of the set, it suffices to understand the class of measures which can be supported on that set. The Fourier dimension of a set also studies this perspective, by slightly refining the measure bound required by the Frostman dimension in frequency space.












\section{Fourier Dimension}

The applicability of Fourier analysis to the analysis of dimension begins by converting the measure bound required on the Frostman dimension onto a condition on the Fourier transform of the measure. For a Borel measure $\mu$, we define the \emph{$s$ energy} of $\mu$ as
%
\[ I_s(\mu) = \int \int \frac{d\mu(x) d\mu(y)}{|x - y|^s}. \]
%
A simple rearrangement shows that for each $y$,
%
\[ \int \int \frac{d\mu(x) d\mu(y)}{|x - y|^s} = s \int_0^\infty \frac{\mu(B(x,r))}{r^{s+1}}\; dr, \]
%
where $B(x,r)$ is the open ball of radius $r$ about the point $x$. This enables us to relate the Frostman bound with energy integrals.

\begin{theorem}
	For any set $E$,
	%
	\[ \hausdim(E) = \sup \{ s : \text{there is $\mu$ supported on $E$ with $I_s(\mu) < \infty$} \}. \]
\end{theorem}
\begin{proof}
	For each $x \in \RR^d$ and $r > 0$, let $B(x,r)$ denote the open ball of radius $r$ centered at $x$. We note $\mu$ is an $s$ dimensional Frostman measure if and only if $\mu(B(x,r)) \lesssim r^s$, since every dyadic cube with sidelength $r$ is contained in $O_d(1)$ balls of radius $r$, and every ball of radius $r$ is contained in $O_d(1)$ dyadic cubes with sidelength $r$. Thus if $\mu$ is a Frostman measure with dimension less than $s$, then $I_s(\mu) < \infty$. Conversely, if $I_s(\mu) < \infty$, then for $\mu$ almost every $y$,
	%
	\[ \int \frac{d\mu(x)}{|x - y|^s} < \infty \]
	%
	In particular, there is $M < \infty$, and $E_0$ with $\mu(E_0) > 0$ such that for any $y \in E_0$,
	%
	\[ \int \frac{d\mu(x)}{|x - y|^s} \leq M. \]
	%
	If we let $\nu(E) = \mu(E \cap E_0)$, then for any $y \in \RR^d$, if $\nu(B(y,r)) > 0$, there is $y_0 \in E \cap B(y,r)$, so $B(y,r) \subset B(y_0,2r)$, and this implies
	%
	\[ \nu(B(y,r)) \leq \nu(B(y_0,2r)) \leq \int_{B(y_0,2r)} d\nu(x) \leq 2^s r^s \int_{B(y_0,2r)} \frac{d\nu(x)}{|x - y|^s} \leq (2^s M) r^s. \]
	%
	Thus $\nu$ is a Frostman measure of dimension $s$ supported on $E$.
\end{proof}

\begin{lemma}
	There exists a constant $C(d,s)$ such that
	%
	\[ I_s(\mu) = C(d,s) \int k_{d-s}(\xi) |\widehat{\mu}(\xi)|^2\; d\xi. \]
\end{lemma}
\begin{proof}
	We can convert the energy integral into a condition on the Fourier transform. If we define the \emph{Riesz kernels} $k_s(x) = 1/|x|^s$, for $0 < s < d$, then
	%
	\[ I_s(\mu) = \int (k_s * \mu) d\mu. \]
	%
	We use the fact that the Fourier transform of $k_s$ is equal to $C(d,s) k_{d-s}$ for some constant $C(d,s)$. Naively applying the multiplication formula for the Fourier transform, we find
	%
	\begin{align*}
		\int (k_s * \mu)(x) d\mu(x) &= \int \widehat{k_s * \mu}(\xi) \widehat{\mu}(\xi)\; dx\\
		&= \int \widehat{k_s}(\xi) |\widehat{\mu}(\xi)|^2\; d\xi\\
		&= C(d,s) \int k_{d-s}(\xi) |\widehat{\mu}(\xi)|^2\; d\xi.
	\end{align*}
	%
	This is not a rigorous argument, because the kernels $k_s$ and the measure $\mu$ do not lie in $L^1(\RR^d)$. Nonetheless, the equation can be interpreted in a distribution sense. In particular, if $d\mu = fdx$, then the argument is rigorous, and approximating measures $\mu$ be Schwartz functions establishes the argument. We leave the technical argument to other sources, e.g. BLAH.
\end{proof}

Thus the application of energy integrals translates the problem of finding a Frostman measure bound to frequency space. In particular, if $\mu$ is a Frostman measure of dimension $s$, then
%
\[ \int \frac{|\widehat{\mu}(\xi)|^2}{|\xi|^{d-s}}\; d\xi < \infty. \]
%
A weak type bound implies that we should have
%
\begin{equation} \label{equation89041094242} |\widehat{\mu}(\xi)|^2 \lesssim |\xi|^{-s/2} \end{equation}
%
for \emph{most} values $\xi$. Thus we obtain a stronger condition if we require that \eqref{equation89041094242} holds for \emph{all} values $\xi$. We say a measure $\mu$ is a measure with \emph{Fourier dimension} $s$ if there exists a constant $C$ such that for all $\xi$,
%
\[ |\widehat{\mu}(\xi)| \leq C \cdot |\xi|^{-s/2}. \]
%
If this is true, then $I_t(\mu) < \infty$ for all $t < s$, so $\mu$ has Frostman dimension $t$ for all $t < s$. Thus if we define the \emph{Fourier dimension} of a set $E$ as
%
\[ \fordim(E) = \sup \left\{ s : \begin{array}{c} \text{there is $\mu$ supported on $E$ with}\\ \text{Fourier dimension $s$} \end{array} \right\}, \]
%
then $\fordim(E) \leq \hausdim(E)$. A set $E$ is \emph{Salem} if $\fordim(E) = \hausdim(E)$. Most classical, self-similar fractals (for instance, the classical Cantor set) have Fourier dimension zero, and are therefore not Salem. Nonetheless, it is a general principle that most \emph{random} families of sets are almost surely Salem. As of now, except in very particular cases, the only way to find large Salem sets is to incorporate randomness into their construction. Using randomness, in Chapter BLAH we are able to find Salem sets with large Fourier dimension.

Later on, we will use two important principles to calculate the Fourier transforms of measures supported $\DQ_k$ discretized sets. The first property is an instance of the Heisenberg uncertainty principle, which says that the Fourier transform of a function $f$ supported on a sidelength $r$ intervals has fast decay outside of a sidelength $1/r$ interval. The second is an instance of the Poisson summation formula, which says that the Fourier transform of a measure $\mu$ supported on $[0,1]^d$ can be read off from it's Fourier series $\{ \widehat{\mu}(k) : k \in \ZZ^d \}$.

\end{comment}






\section{Dyadic Fractal Dimension}

It is often natural for us to establish results about fractal dimension `dyadically', working with the family of cubes $\DQ^d$ and branching factors $\{ N_k : k \geq 1 \}$. We begin with Minkowski dimension. For each $m$, let $N_{\DQ}(m,E)$ denote the minimal number of cubes in $\DQ_m^d$ required to cover $E$. This is often easy to calculate, up to a multiplicative constant, by greedily selecting cubes which intersect $E$.

\begin{lemma} \label{comparableCovers}
	For any set $E$,
	%
	\[ N_{\DQ}(m,E) \sim_d \# \{ Q \in \DQ_m^d : Q \cap E \neq \emptyset \} \sim_d N(l_m,E). \]
\end{lemma}
\begin{proof}
	Let $\mathcal{E} = \{ Q \in \DQ_m^d : Q \cap E \neq \emptyset \}$. Then $N(l_m,E) \leq N_{\DQ}(m,E) \leq \#(E)$. Conversely, let $\{ Q_k \}$ be a minimal cover of $E$ by cubes. Then each cube $Q_k$ intersects at most $3^d$ cubes in $\DQ_k^d$, so $\#(\mathcal{E}) \leq 3^d \cdot N(l_m,E) \leq 3^d \cdot N_{\DQ}(m,E)$.
\end{proof}

Thus it is natural to ask whether it is true that for any set $E$,
%
\begin{equation} \label{definingSequence}
	\begin{aligned}
		\lowminkdim(E) &= \liminf_{k \to \infty} \frac{\log[N_{\DQ}(k,E)]}{\log[1/l_k]}\\
		\text{and}\\
		\upminkdim(E) &= \limsup_{k \to \infty} \frac{\log[N_{\DQ}(k,E)]}{\log[1/l_k]}.
	\end{aligned}
\end{equation}
%
The answer depends on the choice of $\{ N_k \}$. In particular, a sufficient condition (and as we see later, essentially necessary) is that
%
\begin{equation} \label{definingsequencegrowthrate}
	N_{k+1} \lesssim_\varepsilon (N_1 \dots N_k)^\varepsilon \quad \text{for any $\varepsilon > 0$}.
\end{equation}
%
We will see that this condition allows us to work dyadically in many scenarios when it comes to fractal dimension.

%Subsets of $\Sigma^d$ can also be assigned a Minkowski dimension. We define
%
%\[ \lowminkdim(E) = \liminf_{k \to \infty} \frac{\log(\#(\sigma_k^d(E)))}{\log(1/l_k)}\quad\text{and}\quad\upminkdim(E) = \limsup_{k \to \infty} \frac{\log(\#(\sigma_k^d(E)))}{\log(1/l_k)}. \]
%
%This makes sense, because $\Sigma^d$ only really has `balls' of radius $\{ l_k \}$, for each $k$, and \emph{any} cover of $E$ by balls of radius $l_k$ contains $\sigma_k^d(E)$. In order 
%we have $N(E,l_k) = \# (\Sigma_k^d(E))$, since \emph{any} cover of $E$ by balls of radius $l_k$

\begin{theorem} \label{definingsequenceminkowski}
	If \eqref{definingsequencegrowthrate} holds, then \eqref{definingSequence} holds.
\end{theorem}
\begin{proof}
	Fix a length $l$, and find $k$ with $l_{k+1} \leq l \leq l_k$. Applying Lemma \ref{comparableCovers} shows
	%
	\[ N(l,E) \leq N(l_{k+1},E) \lesssim_d N_{\DQ}(k+1,E) \]
	%
	and
	%
	\[ N(l,E) \geq N(l_k,E) \gtrsim_d N_{\DQ}(k,E). \]
	%
	Thus
	%
	\[ \frac{\log[N(l,E)]}{\log[1/l]} \leq \left[ \frac{\log(1/l_{k+1})}{\log(1/l_k)} \right] \frac{\log[N_{\DQ}(k+1,E)]}{\log[1/l_{k+1}]} + O_d(1/k) \]
	%
	and
	%
	\[ \frac{\log[N(l,E)]}{\log[1/l]} \geq \left[ \frac{\log(1/l_k)}{\log(1/l_{k+1})} \right] \frac{\log[N_{\DQ}(k,E)]}{\log[1/l_k]} + O_d(1/k). \]
	%
	Provided that
	%
	\begin{equation} \label{equivalenceofscales}
		\frac{\log(1/l_{k+1})}{\log(1/l_k)} \to 1,
	\end{equation}
	%
	the conclusion of the theorem is true. But \eqref{equivalenceofscales} is equivalent to the condition that
	%
	\[ \frac{\log(N_{k+1})}{\log(N_1) + \dots + \log(N_k)} \to 0, \]
	%
	and this is equivalent to \eqref{definingsequencegrowthrate}.
\end{proof}

Any constant branching factor satisfies \eqref{definingsequencegrowthrate} for the Minkowski dimension. In particular, we can work fairly freely with the classical dyadic cubes without any problems occurring. But more importantly for our work, we can let the sequence $\{ N_k \}$ increase rapidly.

\begin{theorem} \label{rapidBranching}
	If $N_k = 2^{\lfloor 2^{k \psi(k)} \rfloor}$, where $\psi(k)$ is any decreasing sequence of positive numbers tending to zero, such that
	%
	\begin{equation} \label{definingsequencegrowthassumption} \psi(k) \geq \log_2(k)/k, \end{equation}
	%
	then \eqref{definingsequencegrowthrate} holds.
\end{theorem}
\begin{proof}
	We note that $\log(N_k) = 2^{k \psi(k)} + O(1)$, and that \eqref{definingsequencegrowthassumption} implies that
	%
	\[ 2^{\psi(1)} + \dots + 2^{k \psi(k)} \geq k. \]
	%
	Putting these two facts together, we conclude that
	%
	\begin{align*}
		\frac{\log(N_{k+1})}{\log(N_1) + \dots + \log(N_k)} &= \frac{2^{(k+1) \psi(k+1)} + O(1)}{2^{\psi(1)} + 2^{2 \psi(2)} + \dots + 2^{k \psi(k)} + O(k)}\\
		&\lesssim \frac{2^{(k+1) \psi(k+1)}}{2^{\psi(k)} + 2^{2 \psi(k)} + \dots + 2^{k \psi(k)}}\\
		&\lesssim \frac{2^{(k+1) \psi(k+1)}}{2^{(k+1) \psi(k)}} ( 2^{\psi(k)} - 1 )\\
		&\leq (2^{\psi(k)} - 1) \to 0.
	\end{align*}
	%
	This is equivalent to \eqref{definingsequencegrowthrate}.
\end{proof}
%
We refer to any sequence $\{ l_k \}$ constructed by $\{ N_k \}$ satisfying \eqref{definingsequencegrowthassumption} for some function $\psi$ as a \emph{subhyperdyadic} sequence. If a sequence $\{ l_k \}$ is generated by a sequence $\{ N_k \}$ such that for some fixed $c > 0$,
%
\[ N_k = 2^{\lfloor 2^{ck} \rfloor}, \]
%
then the values $\{ l_k \}$ are referred to as \emph{hyperdyadic}. The next (counter) example shows that hyperdyadic sequences are essentially the `boundary' for sequences that can be used to measure the Minkowski dimension.

\begin{example}
	We consider a multi-scale dyadic construction, utilizing the two families $\DQ^d$ and $\DR^d$. Fix $0 \leq c < 1$, and define $N_k = 2^{\lfloor 2^{ck} \rfloor}$, and $M_k = 2^{\lfloor c 2^{ck} \rfloor}$. Then $M_k \divides N_k$ for each $k$. We recursively define a nested family of sets $\{ E_k \}$, with each $E_k$ a $\DQ_k^d$ discretized set, and set $E = \bigcap E_k$. We define $E_0 = [0,1]$. Then, given $E_k$, for each $Q \in \DQ_k(E_k)$, we select a \emph{single} cube $R_Q \in \DR_{k+1}(E_k)$, and define $E_{k+1} = \bigcup R_Q$. Then $\#(\DQ_0(E_0)) = 1$, and
	%
	\[ \#(\DQ_{k+1}(E_{k+1})) = (N_{k+1}/M_{k+1}) \#(\DQ_k(E_k)), \]
	%
	which we can simplify to read
	%
	\begin{equation} \label{equation12623} \#(\DQ_k(E_k)) = \frac{N_1 \dots N_k}{M_1 \dots M_k}. \end{equation}
	%
	Noting that $\log(N_i) = 2^{ci} + O(1)$, and $\log(M_i) = c2^{ci} + O(1)$, we conclude that
	%
	\begin{align*}
		\frac{\log \#(\DQ_k(E_k))}{\log(1/l_k)} &= \frac{(1-c)(2^c + \dots + 2^{ck}) + O(k)}{(2^c + \dots + 2^{ck}) + O(k)} \to 1-c.
	\end{align*}
	%
	On the other hand, for each $k$,
	%
	\[ \#(\DR_{k+1}^d(E_k)) = \#(\DQ_k(E_k)) = \frac{N_1 \dots N_k}{M_1 \dots M_k}, \]
	%
	and so
	%
	\begin{align*}
		\frac{\log \#(\DR_{k+1}^d(E_k))}{\log(1/r_{k+1})} &= \frac{(1-c)(2^c + \dots + 2^{ck}) + O(k)}{(2^c + \dots + 2^{ck}) + c2^{c(k+1)} + O(k)} \\
		&= \frac{(1-c) \cdot 2^{c(k+1)} + O(k)}{(1 - c + c 2^c) \cdot 2^{c(k+1)} + O(k)}\\
		&\to \frac{1 - c}{1 - c + c2^c} < 1 - c.
	\end{align*}
%
%	Fix $0 \leq c < 1$. Let $\{ M_k \}$ be a sequence of integers such that $M_k \divides N_k$ for each $k$. We recursively define a sequence of sets $\{ E_k \}$, with $E_k$ a union of length $l_k$ intervals
%
%	Construct a subset of $\RR$ as follows. Let $N_k = K_kM_k$, where $N_k$, $K_k$, and $M_k$ are parameters to be specified later. Define $E_0 = [0,1]$. Given $E_k$, define $E_{k+1}$ by dividing each sidelength $l_k$ dyadic interval in $E_k$ into $K_{k+1}$ intervals, and then keeping only the first interval. Then $\#(\DQ_{k+1}^d(E_{k+1})) = M_k \cdot \#(\DQ_k^d(E_k))$, and since $\#(\DQ_0^d(E_0)) = 1$, $\#(\DQ_k^d(E_k)) = M_1 \dots M_k$. Thus
%	\begin{align*}
%		\frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} &\sim \frac{\log \left[ \#(\DQ_k^d(E_k)) \right]}{\log(1/l_k)}\\
%		&= \frac{\log(M_1) + \dots + \log(M_k)}{\log(N_1) + \dots + \log(N_k)}\\
%		&= 1 - \frac{\log(K_1) + \dots + \log(K_k)}{\log(N_1) + \dots + \log(N_k)}.
%	\end{align*}
	%
%	On the other hand, if $r_k = l_k/K_{k+1}$, $N(r_k,E) \sim_d \#(S_k) = M_1 \dots M_k$, so
	%
%	\begin{align*}
%		\frac{\log \left[ N(r_k,E) \right]}{\log(1/r_k)} &\sim \frac{\log \left[ \#(\DQ_k^d(E_k)) \right]}{\log(1/r_k)}\\
%		&= \frac{\log(M_1) + \dots + \log(M_k)}{\log(N_1) + \dots + \log(N_k) + \log(K_{k+1})}\\
%		&= 1 - \frac{\log(K_1) + \dots + \log(K_{k+1})}{\log(N_1) + \dots + \log(N_k) + \log(K_{k+1})}.
%	\end{align*}
	%
%	Set $N_k = 2^{\lfloor 2^{ck} \rfloor}$, and $K_k = 2^{\lfloor c 2^{ck} \rfloor}$. Then
	%
%	\[ \log(K_1) + \dots + \log(K_k) = O(k) + c \sum_{i = 1}^k 2^{ck} = O(k) + c \frac{2^{c(k+1)} - 2^c}{2^c - 1} \]
	%
%	and
	%
%	\[ \log(N_1) + \dots + \log(N_k) = O(k) + \sum_{i = 1}^k 2^{ck} = O(k) + \frac{2^{c(k+1)} - 2^c}{2^c - 1}. \]
	%
%	Thus
	%
%	\[ \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} \to 1 - c \quad \text{and} \quad \frac{\log \left[ N(r_k,E) \right]}{\log(1/l_k)} \to \frac{1 - c}{1 - c + c2^c}. \]
	In particular,
	%
	\[ \lowminkdim(E) \neq \liminf_{k \to \infty} \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)}, \] % = \liminf_{k \to \infty} \frac{\log[N_{\DQ}(k,E)]}{\log(1/l_k)}, \]
	%
	so measurements at hyperdyadic scales fail to establish general results about the Minkowski dimension.

%	\[ \lim_{k \to \infty} \frac{\log(K_1) + \dots + \log(K_k)}{2^{c(k+1)} - 2^c} \neq \lim_{k \to \infty} \frac{\log(K_1) + \dots + \log(K_{k+1})}{2^{c(k+1)} - 2^c} \frac{1}{1 + \log(K_{k+1}) (2^c - 1)/(2^{c(k+1)} - 2^c)} \]

%	First, assume $N_k/N_{k-1} \in \mathbf{Z}$ for each $k$, and for convenience, set $N_0 = 1$. Define $S_0 = \{ 0 \}$, and then given $S_k$, recursively define
	%
%	\[ S_{k+1} = \{ (j,1), \dots, (j,N_{k+1}/N_k) : j \in S_k \} \]
	%
%	We then set $E = \pi(\lim S_k)$. If we let $E_k = \bigcup \{ Q_j : j \in S_k \}$, then $E_{k+1}$ can be constructed by dividing each sidelength $l_k$ dyadic interval in $E_k$ into $N_{k+1}$ intervals, and selecting the initial $N_{k+1}/N_k$ intervals, which have total length $1/(N_1 \dots N_k^2)$. Then $\#(S_{k+1}) = (N_{k+1}/N_k) \#(S_k)$, and since $\#(S_0) = 1$, $\#(S_k) = N_k$. Thus
	%
%	\[ \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} \sim_d \frac{\log \left[ \# (S_k) \right]}{\log(1/l_k)} = \frac{\log(N_k)}{\log(N_1) + \dots + \log(N_k)}. \]
	%
%	On the other hand, if $r_k = 1/(N_1 \dots N_k^2) = l_k/N_k$, then $N(l,E) = \#(S_k) = N_k$, so
	%
%	\[ \frac{\log \left[ N(r_k,E) \right]}{\log(1/r_k)} \sim_d \frac{\log \left[ \#(S_k) \right]}{\log(1/r_k)} = \frac{\log(N_k)}{\log(N_1) + \dots + 2\log(N_k)}. \]
%	In any case to which Lemma \ref{definingsequenceminkowski} applies, both of these estimates converge to zero as $k \to \infty$, so that $E$ has Minkowski dimension zero. On the other hand, if $N_k = 2^{\lfloor \psi(k) 2^k \rfloor}$ where $\psi(k)$ is an increasing sequence tending to $\infty$, then
	%
%	\begin{align*}
%		\frac{2^{(k-1) \psi(k-1)}}{2^{\psi(1)} + 2^{2 \psi(2)} + \dots + 2^{(k-1) \psi(k-1)}} &\geq \frac{\left(2^{(k-1) \psi(k-1)} \right) \left( 2^{\psi(k-1)} - 1 \right)}{2^{k \psi(k-1)} - 2^{\psi(k-1)}} \sim 1.
%	\end{align*}
	%
%	Thus
	%
%	\[ \lim_{k \to \infty} \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} = 1. \]
	%
%	On the other hand,
	%
%	\[ \frac{\log \left[ N(r_k, E) \right]}{\log(1/r_k)} = \frac{\log(N_k)}{\log(N_1) + \dots + 2\log(N_k)} \leq 1/2. \]
	%
%	Thus we cannot possibly have
	%
%	\[ \lowminkdim(E) = \liminf_{k \to \infty} \frac{\log \left( N(l_k,E) \right)}{\log(1/l_k)}, \]
	%
	%
%	A simple calculation shows this result even fails if $N_k = 2^{\lfloor 2^{ck} \rfloor}$, where $c > 1$.
\end{example}

%In particular, we can define the Minkowski dimensions of $E \subset \Sigma$ as
%
%\[ \lowminkdim(E) = \liminf_{k \to \infty} \frac{\log(\#(\Sigma_k^d(E)))}{\log(1/l_k)}\quad\text{and}\quad\upminkdim(E) = \limsup_{k \to \infty} \frac{\log(\#(\Sigma_k^d(E)))}{\log(1/l_k)}. \]
%
%Similarily, the Hausdorff measures $H^s$ are obtained by setting
%
% TODO: Fix this
%\[ H^s(E) = \left\{ \sum_m l_{k_m} : Q_m \in \Sigma_{k_m}^d\ \text{for each $k$}, \text{For any} \right\} \]
%
%and define the Hausdorff dimension correspondingly. A natural question is whether $\dim(\pi(E)) = \dim(E)$ for the various fractal dimensions we consider in this thesis. This is addressed in the next section.

We now move on to calculating Hausdorff dimension dyadically. The natural quantity to consider is the measure defined for any set $E$ as
%
\[ H^s_{\DQ}(E) = \lim_{m \to \infty} H^s_{\DQ,m}(E), \]
%
where
%
\[ H^s_{\DQ,m}(E) = \inf \left\{ \sum_k l(Q_k)^s : E \subset \bigcup_k^\infty Q_k,\ Q_k \in \bigcup_{i \geq m} \DQ_i^d\ \text{for each $k$} \right\}. \]
%
A similar argument to the standard Hausdorff measures shows there is a unique $s_0$ such that $H^s_{\DQ}(E) = \infty$ for $s < s_0$, and $H^s_{\DQ}(E) = 0$ for $s > s_0$. It is obvious that $H^s_{\DQ}(E) \geq H^s(E)$ for any set $E$, so we certainly have $s_0 \geq \hausdim(E)$. The next lemma guarantees that $s_0 = \hausdim(E)$, under the same conditions on the sequence $\{ N_k \}$ as found in Theorem \ref{definingsequenceminkowski}.

\begin{lemma} \label{lemma51464}
	If \eqref{definingsequencegrowthrate} holds, then for any $\varepsilon > 0$, $H^s_{\DQ}(E) \lesssim_{s,\varepsilon} H^{s-\varepsilon}(E)$.
\end{lemma}
\begin{proof}
	Fix $\varepsilon > 0$ and $m$. Let $E \subset \bigcup Q_k$, where $l(Q_k) \leq l_m$ for each $k$. Then for each $k$, we can find $i_k$ such that $l_{i_k+1} \leq l(Q_k) \leq l_{i_k}$. Then $Q_k$ is covered by $O_d(1)$ elements of $\DQ_{i_k}^d$, and
	%
	\begin{equation} \label{equation824} H^s_{\DQ,m}(E) \lesssim_d \sum l_{i_k}^s \leq \sum (l_{i_k}/l_{i_k+1})^s l(Q_k)^s \leq \sum \left( l_{i_k}/l_{i_{k+1}} \right)^s l_{i_k}^\varepsilon l(Q_k)^{s - \varepsilon}. \end{equation}
	%
	By assumption,
	%
	\begin{equation} \label{equation992352}
		l_{i_k+1} = \frac{1}{N_1 \dots N_{i_k} N_{i_k+1}} \gtrsim_{s,\varepsilon} (N_1 \dots N_{i_k})^{1+ \varepsilon/s} = l_{i_k}^{1 + \varepsilon/s}.
	\end{equation}
	%
	Putting \eqref{equation824} and \eqref{equation992352} together, we conclude that $H^s_{\DQ,m}(E) \lesssim_{d,s,\varepsilon} \sum l(Q_k)^{s-\varepsilon}$. Since $\{ Q_k \}$ was an arbitrary cover of $E$, we conclude $H^s_{\DQ,m}(E) \lesssim H^{s-\varepsilon}(E)$, and since $m$ was arbitrary, that $H^s_{\DQ}(E) \lesssim H^{s-\varepsilon}(E)$.
\end{proof}

Finally, we consider computing whether we can establish that a measure is a Frostman measure dyadically.

\begin{theorem} \label{easyCoverTheorem}
	If \eqref{definingsequencegrowthrate} holds, and if $\mu$ is a Borel measure such that $\mu(Q) \lesssim l(Q)^s$ for each $Q \in \DQ_k^d$, then $\mu$ is a Frostman measure of dimension $s - \varepsilon$ for each $\varepsilon > 0$.
\end{theorem}
\begin{proof}
	Given a cube $Q$, find $k$ such that $l_{k+1} \leq l(Q) \leq l_k$. Then $Q$ is covered by $O_d(1)$ cubes in $\DQ^d_k$, which shows
	%
	\[ \mu(Q) \lesssim_d l_k^s = [(l_k/l)^s l^\varepsilon ] l^{s - \varepsilon} \leq [l_k^{s + \varepsilon} / l_{k+1}^s] l^{s - \varepsilon} = \left[ \frac{N_{k+1}^s}{(N_1 \dots N_k)^\varepsilon} \right] l^{s-\varepsilon} \lesssim_\varepsilon l^{s-\varepsilon}. \qedhere \]
\end{proof}	

Let's recognize the utility of this approach from the perspective of a dyadic construction. Suppose we have a sequence of nested sets $\{ E_k \}$, where $E_k$ is a $\DQ_k$ discretized subset of $[0,1]^d$, and for each $Q_0 \in \DQ_k(E_k)$, there is at least one cube $Q \in \DQ_{k+1}(E_{k+1})$ with $Q^* = Q_0$. Then we can set $E = \bigcap E_k$ as a `limit' of the discretizations $E_k$. We can associate with this construction a finite measure $\mu$ supported on $E$. It is defined by the mass distribution principle with respect to a function $w: \DQ^d \to [0,\infty)$. We set $w([0,1]^d) = 1$, and for each $Q \in \DQ_{k+1}(E_{k+1})$, set
%
\[ w(Q) = \frac{w(Q^*)}{\# \{ Q' \in \DQ_{k+1}(E_{k+1}) : (Q')^* = Q^* \}}. \]
%
The mass distribution principle then gives a Borel measure $\mu$, which we refer to as the \emph{canonical measure} associated with this construction. For this measure, it is often easy to show from a combinatorial argument that $w(Q) \lesssim l(Q)^s$ if $Q \in \DQ^d$, which together with \eqref{massdissupperbound} also implies $\mu(Q) \lesssim l(Q)^s$ for $Q \in \DQ^d$. This makes Theorem \ref{easyCoverTheorem} useful.

\begin{remark}
	The dyadic construction showing that Minkowski dimension cannot be measured only at hyperdyadic scales also shows that a bound on a measure $\mu$ on hyperdyadic cubes does not imply the correct bound at all scales. It is easy to show from \eqref{equation12623} that the canonical measure $\mu$ for this example satisfies, for each $k$, each $Q \in \DQ_k(E_k)$, and each $\varepsilon > 0$,
	%
	\[ \mu(Q) = \left( \#(\DQ_k(E_k)) \right)^{-1} \lesssim_\varepsilon l(Q)^{1-c-\varepsilon} \]
	%
	for all $Q \in \DQ_k(E_k)$, yet we know that for the set constructed in that example,
	%
	\[ \hausdim(E) \leq \lowminkdim(E) < 1 - c. \]
	%
	Frostman's lemma implies we cannot possibly have $\mu(Q) \lesssim_\varepsilon l(Q)^{1-c-\varepsilon}$ for all $\varepsilon > 0$ and \emph{all} cubes $Q$.
\end{remark}

%Our final method for interpolating requires extra knowledge of the dissection process, but enables us to choose the $l_k$ arbitrarily rapidly. The idea behind this is that there is an additional sequence of lengths $r_k$ with $l_k \leq r_k \leq l_{k-1}$. The difference between $r_k$ and $l_{k-1}$ is allowed to be arbitrary, but the decay rate between $l_k$ and $r_k$ is of polynomial-type, which enables us to use the covering methods of the previous section. In addition, we rely on a `uniform mass bound' between $r_k$ and $l_k$ to cover the remaining classes of intervals. Because we can take $r_k$ arbitrarily large relative to $l_k$, this renders any constants that occur in the construction to become immediately negligible. For two quantities $A$ and $B$, we will let $A \precsim_k B$ stand for an inequality with a hidden constant depending only on parameters with index smaller than $k$, i.e. $A \leq C(l_1, \dots, l_k, r_1,\dots,r_k) B$ for some constant $C(l_1, \dots, l_k, r_1, \dots, r_k)$ depending only on parameters with indices up to $k$.

\section{Beyond Hyperdyadics}

If we use a faster increasing sequence of branching factors than that satisfying \eqref{definingsequencegrowthrate}, we must exploit some extra property of our construction, which is not always present in general sets. Here, we rely on a \emph{uniform mass distribution} between scales. Given the uniformity assumption, the lengths can decrease as fast as desired. We utilize the multi-scale set of dyadic cubes $\DQ^d$ and $\DR^d$ introduced in Section \ref{sec:Dyadics}.

\begin{lemma} \label{uniformMassFrostman}
	Let $\mu$ be a measure supported on a set $E$. Suppose that
    %
    \begin{enumerate}
    	\item \label{discreteBound} For any $Q \in \DQ_k^d$, $\mu(Q) \lesssim l_k^s$.
    	\item \label{controlledScale} For each $R \in \DR_{k+1}^d$, $\#[\DQ_{k+1}^d(E(l_k) \cap R)] \lesssim 1$.
    	\item \label{uniformDist} For any $R \in \DR_{k+1}^d$ with parent cube $Q \in \DQ_k^d$, $\mu(R) \lesssim (1/M_{k+1})^d \cdot \mu(Q)$.
    \end{enumerate}
	%
	Then $\mu$ is a Frostman measure of dimension $s$.
\end{lemma}
\begin{proof}
	We establish the general bound $\mu(Q) \lesssim l(Q)^s$ for all cubes $Q$ by separating our analysis into two different cases:
	%
	\begin{itemize}
		\item Suppose there is $k$ with $r_{k+1} \leq l(Q) \leq l_k$. Then $\#(\DR_{k+1}^d(Q(r_{k+1}))) \lesssim (l/r_{k+1})^d$. Properties \ref{discreteBound} and \ref{uniformDist} imply each of these cubes has measure at most $O( (r_{k+1}/l_k)^d l_k^s)$, so we obtain that
	    %
    	\[ \mu(Q) \lesssim (l/r_{k+1})^d (r_{k+1}/l_k)^d l_k^s = l^d / l_k^{d-s} \lesssim l^s. \]

    \item Suppose there exists $k$ with $l_k \leq l \leq r_k$. Then $\#[\DR_k^d(Q(r_k))] \lesssim 1$. Combining this with Property \ref{uniformDist} gives $\#[\DQ_k^d(Q(r_k) \cap E(l_k))] \lesssim 1$. This and Property \ref{discreteBound} then shows
    %
    \[ \mu(Q) \lesssim l_k^s \leq l^s. \]
	\end{itemize}
	%
	We have addressed all cases, so $\mu$ is a Frostman measure of dimension $s$.
\end{proof}

This theorem is commonly used here when dealing with multi-scale dyadic fractal constructions, whose character is summarized in the following Theorem.

\begin{theorem} \label{TheConstructionTheorem}
	let $E = \bigcap E_k$, where $\{ E_k \}$ is a nested family of subsets of $\RR^d$, such that $E_k$ is $\DQ_k$ discretized for each $k$. Suppose that 
	%
	\begin{enumerate}
		\item \label{SingleSelection} For each $Q \in \DQ_k(E_k)$, there exists a set $\mathcal{R}_Q \subset \DR_{k+1}(Q)$ such that $\#(\mathcal{R}_Q) \geq (1/2) \cdot \#(\DR_{k+1}(Q))$, and
		%
		\[ \# \left( \DQ_{k+1}(R \cap E_{k+1}) \right) = \begin{cases} 1 & : R \in \mathcal{R}_Q, \\ 0 & : R \not \in \mathcal{R}_Q. \end{cases} \]

		\item \label{RapidDecrease} For any $\varepsilon > 0$, $N_1 \dots N_k \lesssim_\varepsilon N_{k+1}^\varepsilon$.

		\item \label{ChangeofScales} There is $0 < s \leq 1$ such that for any $\varepsilon > 0$, $N_{k+1} \lesssim_\varepsilon M_{k+1}^{(1 + \varepsilon)/s}$.
	\end{enumerate}
	%
	Then $E$ has Hausdorff dimension $sd$.
\end{theorem}

\begin{remark}
	Note that Property \ref{RapidDecrease} is essentially the opposite of \eqref{definingsequencegrowthrate}.
\end{remark}

\begin{proof}
	Consider the function $w: \DQ^d \to [0,\infty)$ defined with respect to the sequence $\{ E_k \}$, which generates the canonical measure $\mu$ supported on $E$ using the mass distribution principle. For each $R \in \DR_{k+1}(E_k)$ with parent cube $Q \in \DQ_k(E_k)$, Property \ref{SingleSelection} shows
	%
	\begin{equation} \label{equation6250234923} w(R) \leq (2/M_{k+1}^d) f(Q). \end{equation}
	%
	Properties \ref{RapidDecrease} and \ref{ChangeofScales} together imply that for each $\varepsilon > 0$,
	%
	\begin{equation} \label{equation363491043214} 1/M_{k+1} \lesssim_\varepsilon r_{k+1}^{1 - \varepsilon} \lesssim_\varepsilon l_{k+1}^{s(1  - 2 \varepsilon)}. \end{equation}
	%
	If $Q \in \DQ_{k+1}(E_{k+1})$ has parent cubes $R \in \DR_{k+1}(E_k)$ and $Q^* \in \DQ_k(E_k)$, then by \eqref{equation6250234923}, \eqref{equation363491043214}, and the fact that $w(Q^*) \leq 1$,
	%
	\begin{equation} \label{equation120492309562} w(Q) = w(R) \leq (2/M_{k+1}^d) w(Q^*) \leq (2/M_{k+1}^d) \lesssim_{\varepsilon} l_{k+1}^{ds(1 - 2\varepsilon)}. \end{equation}
	%
	If $Q$ is a cube with length $l_k$, then $\#(\DQ_k^d(Q(l_k))) = O_d(1)$, which combined with \eqref{massdisslowerbound}, shows that
	%
	\begin{equation} \label{equation69009230919} \mu(Q) \lesssim_\varepsilon l_{k+1}^{ds(1-2\varepsilon)}. \end{equation}
	%
	Property \ref{controlledScale} of Lemma \ref{uniformMassFrostman} is implied by Property \ref{SingleSelection}.  Equation \eqref{equation69009230919} is a form of Property \ref{discreteBound} in Lemma \ref{uniformMassFrostman}. Together with \eqref{massdisslowerbound}, \eqref{equation6250234923} implies that the canonical measure $\mu$ satisfies Property \ref{uniformDist} of Lemma \ref{uniformMassFrostman}. Thus all assumptions of Lemma \ref{uniformMassFrostman} are satisfied, and so we conclude $\mu$ is a Frostman measure of dimension $ds(1 - 2\varepsilon)$ for each $\varepsilon > 0$. Taking $\varepsilon \to 0$, and applying Frostman's lemma, we conclude that the Hausdorff dimension of the support of $\mu$, which is a subset of $E$, is greater than or equal to $ds$. For each $k$, and $\varepsilon > 0$,
	%
	\[ \#(\DQ_{k+1}(E_{k+1})) \leq \#(\DR_{k+1}(E_k)) \leq (1/M_{k+1})^d \lesssim_\varepsilon l_{k+1}^{ds - \varepsilon}. \]
	%
	Taking $k \to \infty$, and then $\varepsilon \to 0$, we conclude that
	%
	\[ \hausdim(E) \leq \lowminkdim(E) \leq ds. \]
	%
	Since we already know $\hausdim(E) \geq ds$, this completes the proof.
\end{proof}

%\begin{remark}
%    The condition $\mu_\beta(J) \lesssim_{N-1} (r_N/l_N) \mu_\beta(I)$ essentially means that the probability mass on a length $l_N$ interval $I$ is uniformly distributed over the length $r_N$ intervals it contains. This is what enables us to remove the discussion of the growth of the sequence $\beta$ over time from discussion.
%\end{remark}

%Since the construction is obtained as a limit of intervals, it is often possible to construct such a $\mu$ by the {\it mass distribution principle}. That is, we let $\mu$ denote the weak limit of the probability masses $\mu_n$, where $\mu_0$ is a uniform distribution over $\mu_0$, and $\mu_{n+1}$ is obtained from $\mu_n$ by distributing the mass $\mu_n(I)$ of each length $l_n$ interval $I$ contained in $X_n$ over the portion of $I$ that remains in $X_{n+1}$. The cumulative distribution functions of the $\mu_n$ uniformly converge, hence the $\mu_n$ converge weakly to some $\mu$, which satisfy $\mu(I) = \mu_n(I)$ for each interval $I$ as above. Because of this discreteness, it is most easy to establish a bound $\mu(I) \lesssim l_n^\alpha$ when $I \subset X_n$ is a length $l_n$ interval. Since any interval $I$ of length $l_n$ is contained within at least two such intervals (or is contained in other length $l_n$ intervals that $\mu$ assigns no mass to), we have the general bound $\mu(I) \lesssim l_n^\alpha$ for all intervals $I$ of length $l_n$. Hausdorff dimension is a local property of a set\footnote{If we define $\dim_{\mathbf{H}}(x) = \lim_{r \downarrow 0} \dim_{\mathbf{H}}(B_r(x) \cap X)$ then $\dim_{\mathbf{H}}(X) = \sup_{x \in X} \dim_{\mathbf{H}}(x)$.}, so it is natural to expect that we can obtain a general bound $\mu(I) \lesssim_\alpha|I|^\alpha$ given that one has established precisely the same estimate, but restricted to intervals $I$ with $|I| = l_N$. This section concerns itself with ways that we can establish this general bound, and thus prove that $\dim_{\mathbf{H}}(X) \geq \alpha$.

%\section{BLAH}

%The collection $\DQ^d$ forms a \emph{tree} under the partial ordering induced by inclusion, with a branching factor of $H$. We let $\DB^d$ denote the set of all branches of the tree $\DQ^d$. For each branch $\mathfrak{b} = \{ Q_k : k \geq 0 \}$, the set $\bigcap_{k \geq 0} Q_k$ contains a unique point, which induces a function $\pi: \DB^d \to \RR^d$. This function is obviously surjective, but unfortunately not injective. Nonetheless, for each $x \in \RR^d$, $\pi^{-1}(x)$ contains $O_d(1)$ points. This means that from the point of view of geometric measure theory, the spaces $\DB^d$ and $\RR^d$ are isomorphic\footnote{Formally, we can define a topology on $\DB^d$ as a subset of $\prod_{k \geq 0} \DQ_k^d$, and $\pi$ is continuous with respect to this topology. We can also define the Hausdorff measures $H^s$ on $\DB^d$ as limits of $H^s_m$, where
%
%\[ H^s_m(E) = \inf \left\{ \sum_{i = 1}^\infty l(Q_i)^s : Q_i \in \DQ_{k_i}^d, k_i \geq m, E \subset \bigcup \{ \mathfrak{b} \in \DB^d : \mathfrak{b}_k = Q \} \right\} \]
%
%Then for each value $s > 0$ the map $\pi$ is an isomorphism of $(\DB^d, H^s)$ and $(\RR^d, H^s)$.}. In particular, given any configuration $\C$ on $\RR^d$, we can define a configuration $\pi^{-1}(\C)$ on $\DB^d$ as
%
%\[ \pi^{-1}(\C) = \{ (\mathfrak{b_1}, \dots, \mathfrak{b}_n) : (\pi(\mathfrak{b_1}), \dots, \pi(\mathfrak{b_n})) \in \C \}. \]
%
%If we can find an $s$ dimensional set $E \subset \DB^d$ avoiding $\pi^{-1}(\C)$, then $\pi(E)$ avoids $\C$ and is $s$ dimensinoal. Conversely, if $E \subset \RR^d$ avoids $\C$ and is $s$ dimensional, then $\pi^{-1}(E)$ avoids $\pi^{-1}(\C)$ and is $s$ dimensional.

%The Dyadic model is useful, but if the lengths decrease too fast, the model fails to reflect the geometry of $\RR^n$ at all scales.

\begin{comment}

\section{Extras: Hyperdyadic Covers}

Nonetheless, it will be useful for us to know that we can `decompose' a set with a prescribed Hausdorff dimension hyperdyadically. We say a sequence of sets $\{ E_k \}$ is a \emph{strong cover} of a set $E$ if $E \subset \limsup E_k$, or equivalently, if every $x \in E$ lies in infinitely many of the sets $E_k$. In this section, we inclusively treat hyperdyadic cubes, i.e. we assume $l_k = 2^{-\lfloor (1 + \varepsilon)^k \rfloor}$ for some fixed $0 < \varepsilon \leq 1$.

%Fix two parameters $\delta > 0$ and $\varepsilon > 0$. Given two numbers $A = A_{\delta \varepsilon}$ and $B = B_{\delta \varepsilon}$, we say $A \lessapprox B$ if there exists constants $C_\varepsilon$, and $C$ such that $A \leq C_\varepsilon \delta^{-C\varepsilon} B$. We say $A \approx B$ if $A \lessapprox B$ and $B \lessapprox A$. We say a set $E$ is \emph{$\delta$ discretized} if it is a union of dyadic cubes with sidelength $\approx \delta$. We say a set $E$ is a \emph{$(\delta,\alpha)$ set} if it is $\delta$ discretized, and for any dyadic cube $I$ with $\delta \leq l(I) \leq 1$, $|E \cap I| \lessapprox \delta^{d-\alpha} l(I)^\alpha$. Thus $E$ is \emph{roughly} a $\delta$ thickening of an $\alpha$ dimensional set. A set $E$ is \emph{strongly covered} by a family of sets $\{ U_i \}$ if $E \subset \limsup_{i \to \infty} U_i$. We consider a fixed hyperdyadic sequence $l_k = 2^{- \lfloor (1 + \varepsilon)^k \rfloor}$.

%\begin{lemma}
%	If $C$ is sufficiently large, and for each $\varepsilon$, there is a $(\delta, \alpha - C \varepsilon)$ set $X_\delta$ for each hyperdyadic $\delta$ such that the $X_\delta$ strongly cover $X$, then $\dim(X) \leq \alpha$.
%\end{lemma}
%\begin{proof}
%	Let $X_\delta = \bigcup I_i$, where $\{ I_i \}$ are disjoint dyadic cubes such that $l(I_i) \approx \delta$, and with $|X_\delta| \lessapprox \delta^{d-\alpha + C\varepsilon}$. Then
	%
%	\[ |X_\delta(\delta/2)| \leq \sum (l(I_i) + \delta/2)^d \lessapprox \sum l(I_i)^d = |X_\delta| \lessapprox \delta^{d - \alpha + C\varepsilon}. \]
	%
%	A volumetric argument then guarantees that $N(X_\delta,\delta) \lessapprox \delta^{-\alpha + C\varepsilon}$, and so
	%
%	\[ H^\alpha_\infty(X_\delta) \leq N(X_\delta,\delta) \delta^\alpha \lessapprox \delta^{C\varepsilon}. \]
	%
%	Thus there is $C_\varepsilon$ and $C_0$ such that $H^\alpha_\delta(X_\delta) \leq C_\varepsilon \delta^{(C - C_0) \varepsilon}$. Since $C_0$ does not depend on $C$, if we set $C > C_0$, then
	%
%	\[ \sum_{i = 1}^\infty H^\alpha_\infty(X_\delta) < \infty, \]
	%
%	and so $H^\alpha_\infty(X) = 0$.
%\end{proof}

\begin{theorem}
	Suppose $E \subset [0,1]^d$ is a set with $\dim(E) \leq s$. Fix $\varepsilon > 0$, and write $l_k = 2^{-\lfloor (1 + \varepsilon)^k \rfloor}$. Then there exists a strong cover of $E$ by sets $\{ E_k \}$, where $E_k$ is a union of $O((1 + \varepsilon)^{2k} l_k^{-s})$ cubes in $\DQ_k^d$.
\end{theorem}
\begin{proof}
	For each hyperdyadic number $l_k$, we can find a collection of cubes $\{ Q_{k,i} \}$ covering $E$ with $l(Q_{k,i}) \leq l_k$ for all $i$, and
	%
	\begin{equation} \label{HausdorffBound5}
		\sum_{i = 1}^\infty l(Q_{k,i})^{s + C\varepsilon} \lesssim 1.
	\end{equation}
	%
	For each $k$ and $i$, find $j_{k,i}$ such that $l_{j_{k,i} + 1} \leq l(Q_{k,i}) \leq l_{j_{k,i}}$. Note $l_{j_{k,i} + 1} \lesssim l_{j_{k,i}}^{1 + \varepsilon}$, so
	%
	\begin{align*}
		\sum_{i = 1}^\infty l_{j_{k,i}}^{s + (C + s)\varepsilon} &= \sum_{i = 1}^\infty l(Q_{k,i})^{s + (C + s) \varepsilon} (l_{j_{k,i}} / l(Q_{k,i}))^{s + (C + s) \varepsilon}\\
		&\lesssim \sum_{i = 1}^\infty l(Q_{k,i})^{s + (C + s)\varepsilon} l_{j_{k,i}}^{-s \varepsilon} \lesssim \sum_{i = 1}^\infty l(Q_{k,i})^{s + C \varepsilon} \lesssim 1.
	\end{align*}
	%
	Thus, replacing $C$ with $C + s$, and replacing $Q_{k,i}$ with the $O_d(1)$ cubes in $\DQ_{j_{k,i}}(Q_{k,i})$, we may assume without loss of generality that all cubes in the decomposition corresponding to \eqref{HausdorffBound5} are hyperdyadic.

	For $k_2 \geq k_1$, we let
	%
	\[ Y_{k_1,k_2} = \bigcup \{ Q_{k_1,i} : l(Q_{k_1,i}) = l_{k_2}. \} \]
	%
	Note that $Y_{k_1,k_2}$ is the union of $O((1/l_{k_2})^{s + C\varepsilon})$ cubes in $\DQ_{k_2}$. We let $Z_{k_1,k_2}$ be the collection of hyperdyadic cubes covering $Y_{k_1,k_2}$ which minimize
	%
	\[ \sum \left\{ l(Q)^s : Q \in Z_{k_1,k_2} \right\} \]
	%
	and such that $l(Q) \geq l_{k_2}$ for each $Q$. Then clearly
	%
	\[ \sum_{Q \in Z_{k_1,k_2}} l(Q)^s \lesssim l_{k_2}^{- C\varepsilon}. \]
	%
	In particular, this means $l(Q) \lesssim l_{k_2}^{-C\varepsilon/s}$ for each $Q \in Z_{k_1,k_2}$. Moreover, for each hyperdyadic $Q_0$ with $l(Q_0) \geq l_{k_2}$,
	%
	\[ \sum_{Q \subset Q_0} l(Q)^s \leq l(Q_0)^s. \]
	%
	Now we define $E_k = \bigcup \left\{ \bigcup_{k_1,k_2} Z_{k_1,k_2} \cap \DQ_k \right\}$. Since $E_k$ only contains cubes from $Z_{k_1,k_2}$ where $k_1 \leq k_2$, and $l_k \lesssim l_{k_2}^{-\varepsilon/\alpha}$ TODO: THERE IS SOMETHING WRONG HERE THIS DOESN'T IMPLY $\log(1/l_k)^2$?. But this means that there are only $O(\log(1/l_k)^2) = O((1 + \varepsilon)^{2k})$ such choices of $(k_1,k_2)$. But this means that
	%
	\[ |E_k| = \sum l(Q)^d = l_k^{d - s} \sum l(Q)^s \lesssim (1 + \varepsilon)^{2k} l_k^{d-s}, \]
	%
	which implies that $E_k$ is the union of at most $O((1 + \varepsilon)^{2k} l_k^{-s})$ cubes in $\DQ_k$.
\end{proof}

\end{comment}