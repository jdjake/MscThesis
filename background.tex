%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Background}
\label{ch:Background}

\section{Configuration Avoidance}

We consider an ambient set $\AAA$. It's \emph{$n$-point configuration space} is
%
\[ \Config^n(\AAA) = \{ (a_1, \dots, a_n) \in \AAA^n: a_i \neq a_j\ \text{if $i \neq j$} \}. \]
%
An \emph{$n$ point configuration}, or \emph{$n$ point pattern}, is a subset of $\Config^n(\AAA)$. More generally, we define the general \emph{configuration space} of $\AAA$ as $\Config(\AAA) = \bigcup_{n = 1}^\infty \Config^n(\AAA)$, and a \emph{pattern}, or \emph{configuration}, on $\AAA$ as a subset of $\Config(\AAA)$.

Our main focus in this thesis is the \emph{pattern avoidance problem}. For a fixed configuration $\C$ on $\AAA$, we say a set $X \subset \AAA$ \emph{avoids} $\C$ if $\Config(X)$ is disjoint from $\C$. The pattern avoidance problem asks to find sets $X$ of maximal size avoiding a fixed configuration $\C$. Often $\C$ describes algebraic or geometric structure, and the pattern avoidance problem asks to find the maximal size of a set before it is guaranteed to have such structure.

\begin{example}[Isoceles Triangle Configuration]
	Let
	%
	\[ \C = \left\{ (x_1, x_2, x_3) \in \Config^3(\RR^2) : |x_1-x_2| = |x_1-x_3| \right\}. \]
	%
	Then $\C$ is a 3-point configuration, and a set $X \subset \RR^2$ avoids $\C$ if and only if it does not contain all three vertices of an isoceles triangle. %Notice that $|x_1 - x_2| = |x_1 - x_3|$ holds if and only if $|x_1 - x_2|^2 = |x_1 - x_3|^2$, which is an algebraic equation in the coordinates of $x_1,x_2$, and $x_3$. Thus $\C$ is an algebraic hypersurface of degree two in $\RR^6$.
\end{example}

\begin{example}[Linear Independence Configuration]
	Let $V$ be a vector space over a field $K$. We set
	%
	\[ \C = \bigcup_{n = 1}^\infty \{ (x_1, \dots, x_n) \in \C^n(V): \text{there is}\ a_1, \dots, a_n \in K\ \text{s.t.}\ a_1x_1 + \dots + a_nx_n = 0 \}. \]
	%
	A set $X \subset V$ avoids $\C$ if and only if $X$ is a linearly independent subset of $X$. Note that if $V$ is infinite dimensional, then $\C$ cannot be replaced by a $n$ point configuration for any $n$; arbitrarily large tuples must be considered. We will be interested in the case where $K = \QQ$, and $V = \RR$. Our interest here is to find analytically large linearly independant subsets of $V$.
\end{example}

%\begin{example}[General Position Configuration]
%	Suppose we wish to find a subset $X$ of $\RR^d$ such that for each positive integer $k \leq d$, and for each collection of $k+1$ distinct points $x_1, \dots, x_{k+1} \in X$, the points do not lie in a $k-1$ dimensional hyperplane. For each $k \leq d$, set
	%
%	\[ \C^{k+1} = \{ (x_0, x_1, \dots, x_k) \in \Config^{k+1}(\RR^d): x_1-x_0, \dots, x_k - x_0\ \text{are linearly dependant} \}. \]
	%
%	If we define $\C = \bigcup_{k = 2}^d \C^k$, then a set $X$ avoids $\C$ precisely when all finite collection of distinct points in $X$ lie in general position. Notice that
	%
%	\[ \C^{k+1} = \bigcup \left\{ \text{span}(y_1, \dots, y_k) \times \{ y \} : y = (y_1, \dots, y_k) \in \Config^k(\RR^d) \right\} \cap \Config^{k+1}(\RR^d). \]
	%
%	so each $\C^{k+1}$ is essentially a union of $k$ dimensional hyperplanes.
%\end{example}

Even though our problem formulation assumes configurations are formed by distinct sets of points, one can still formulate avoidance problems involving repeated points by a simple trick.

\begin{example}[Sum Set Configuration]
	Let $G$ be an abelian group, and fix $Y \subset G$. Set
	%
	\[ \C^1 = \{ g \in \Config^1(G): g + g \in Y \} \quad \text{and} \quad \C^2 = \{ (g_1,g_2) \in \Config^2(G): g_1 + g_2 \in Y \}. \]
	%
	Then define $\C = \C^1 \cup \C^2$. A set $X \subset G$ avoids $\C$ if and only if $(X + X) \cap Y = \emptyset$.
\end{example}

Depending on the structure of the ambient space $\AAA$ and the configuration $\C$, there are various ways of measuring the size of sets $X \subset \AAA$ for the purpose of the pattern avoidance problem:
%
\begin{itemize}
	\item If $\AAA$ is finite, we wish to find a set $X$ with large cardinality.
	\item If $\{ \AAA_n \}$ is an increasing family of finite sets with $\AAA = \bigcup_n \AAA_n$, we wish to find a set $X$ such that $X \cap \AAA_n$ has large cardinality asymptotically as $n \to \infty$.
	\item If $\AAA = \RR^d$, but $\C$ is a discrete configuration, then a satisfactory goal is to find a set $X$ with large Lebesgue measure avoiding $\C$.
\end{itemize}
%
In this thesis, inspired by results in these three settings, we establish methods for avoiding non-discrete configurations $\C$ in $\RR^d$. Here, Lebesgue measure completely fails to measure the size of pattern avoiding solutions, as the next theorem shows, under the often true assumption that $\C$ is \emph{translation invariant}, i.e. that if $(a_1, \dots, a_n) \in \C$ and $b \in \RR^d$, $(a_1 + b, \dots, a_n + b) \in \C$.

\begin{theorem}
	Let $\C$ be a $n$-point configuration on $\RR^d$. Suppose
	%
	\begin{enumerate}
		\item \label{translationinvariance} $\C$ is translation invariant.
		\item \label{nonDiscreteConfig} For any $\varepsilon > 0$, there is $(a_1, \dots, a_n) \in \C$ with $\diam \{ a_1, \dots, a_n \} \leq \varepsilon$.
	\end{enumerate}
	%
	Then no set with positive Lebesgue measure avoids $\C$.
\end{theorem}
\begin{proof}
	Let $X \subset \RR^d$ have positive Lebesgue measure. The Lebesgue density theorem shows that there exists a point $x \in X$ such that
	%
	\begin{equation} \label{densityApplication} \lim_{l(Q) \to 0} \frac{|X \cap Q|}{|Q|} = 1, \end{equation}
	%
	where $Q$ ranges over all cubes in $\RR^d$ with $x \in Q$, and $l(Q)$ denotes the sidelength of $Q$. Fix $\varepsilon > 0$, to be specified later, and choose $r$ small enough that $|X \cap Q| \geq (1 - \varepsilon) |Q|$ for any cube $Q$ with $x \in Q$ and $l(Q) \leq r$. Now let $Q_0$ denote a cube centered at $x$ with $l(Q_0) \leq r$. Applying Property \ref{nonDiscreteConfig}, we find $C = (a_1, \dots, a_n) \in \C$ such that
	%
	\begin{equation} \label{equation690346024} \diam \{ a_1, \dots, a_n \} \leq l(Q_0)/2. \end{equation}
	%
	For each $p \in Q_0$, let $C(p) = (a_1(p), \dots, a_n(p))$, where $a_i(p) = p + (a_i - a_1)$. Property \ref{translationinvariance} implies $C(p) \in \C$ for each $p \in \RR^d$. A union bound shows
	%
	\begin{equation} \label{equation548} \left| \{ p \in Q_0 : C(p) \not \in \C(X) \} \right| \leq \sum_{i = 1}^d \left| \{ p \in Q_0 : a_i(p) \not \in X \} \right|.
	\end{equation}
	%
	We have $a_i(p) \not \in X$ precisely when $p + (a_i - a_1) \not \in X$, so
	%
	\begin{equation} \label{equation1243462}
		|\{ p \in Q_0 : a_i(p) \not \in X \}| = |(Q_0 + (a_i - a_1)) \cap X^c|.
	\end{equation}
	%
	Note $Q_0 + (a_i - a_1)$ is a cube with the same sidelength as $Q_0$. Equation \eqref{equation690346024} implies $|a_i - a_1| \leq l(Q_0)/2$, so $x \in Q_0 + (a_i - a_1)$. Thus \eqref{densityApplication} shows
	%
	\begin{equation} \label{equation543} |Q_0 + (a_i - a_1)) \cap X^c| \leq \varepsilon |Q_0|. \end{equation}
	%
	Combining \eqref{equation548}, \eqref{equation1243462}, and \eqref{equation543}, we find
	%
	\[ \left| \{ p \in Q_0 : C(p) \not \in \C(X) \} \right| \leq \varepsilon d |Q_0|. \]
	%
	Provided $\varepsilon d < 1$, this means there is $p \in Q_0$ with $C(p) \in \C(X)$. But this means $X$ does not avoid $\C$.
\end{proof}

Since no set of positive Lebesgue measure can avoid non-discrete configurations, we cannot use the Lebesgue measure to quantify the size of pattern avoiding sets for many non-discrete configurations. Geometric measure theory provides us with a quantity which can distinguish between the size of sets of measure zero. This is the \emph{fractional dimension} of a set.

There are many variants of fractional dimension. Here we choose to use the Minkowski dimension and the Hausdorff dimension. They assign the same dimension to any smooth manifold with non-vanishing curvature, but vary over more singular sets. One major difference is that Minkowski dimension measures relative density at a single scale, whereas Hausdorff dimension measures relative density at countably many scales.
%The Fourier dimension is a refinement of the Hausdorff dimension which gives greater control on the set when viewed `in the frequency domain', and therefore gives additional structural information on sets.









\section{Minkowski Dimension}

We begin by discussing the Minkowski dimension, which is the simplest to define. Given $l > 0$, and a bounded set $E \subset \RR^d$, we let $N(l,E)$ denote the \emph{covering number} of $E$, i.e. the minimum number of sidelength $l$ cubes required to cover $E$. We define the \emph{lower} and \emph{upper} Minkowski dimension as
%
\[ \lowminkdim(E) = \liminf_{l \to 0} \frac{\log(N(l,E))}{\log(1/l)} \quad\text{and}\quad \upminkdim(E) = \limsup_{l \to 0} \frac{\log(N(l,E))}{\log(1/l)}. \]
%
If $\upminkdim(E) = \lowminkdim(E)$, then we refer to this common quantity as the \emph{Minkowski dimension} of $E$, denoted $\minkdim(E)$. Thus $\lowminkdim(E) < s$ if there exists a sequence of lengths $\{ l_k \}$ converging to zero with $N(l_k,E) \leq (1/l_k)^s$, and $\upminkdim(E) < s$ if $N(l,E) \leq (1/l)^s$ for \emph{all} sufficiently small lengths $l$.

\section{Hausdorff Dimension}

For $E \subset \RR^d$ and $\delta > 0$, we define the \emph{Hausdorff content}
%
\[ H_\delta^s(E) = \inf \left\{ \sum_{k = 1}^\infty l(Q_k)^s : E \subset \bigcup_{k = 1}^\infty Q_k, l(Q_k) \leq \delta \right\}. \]
%
The \emph{$s$-dimensional Hausdorff measure} of $E$ is
%
\[ H^s(E) = \lim_{\delta \to 0} H_\delta^s(E) = \sup_{\delta > 0} H^s_\delta(E). \]
%
It is easy to see $H^s$ is an exterior measure on $\RR^d$, and $H^s(E \cup F) = H^s(E) + H^s(F)$ if the Hausdorff distance $d(E,F)$ between $E$ and $F$ is positive. So $H^s$ is actually a metric exterior measure, and the Caratheodory extension theorem shows all Borel sets are measurable with respect to $H^s$. Sometimes, it is convenient to use the exterior measure
%
\[ H^s_\infty(E) = \inf \left\{ \sum_{k = 1}^\infty l(Q_k)^s : E \subset \bigcup_{k = 1}^\infty Q_k \right\}. \]
%
The majority of Borel sets which occur in practice fail to be measurable with respect to $H^s_\infty$, but the exterior measure $H^s_\infty$ has the useful property that $H^s_\infty(E) = 0$ if and only if $H^s(E) = 0$.

\begin{lemma} \label{HausdorffBoundary}
	Consider $t < s$, and $E \subset \RR^d$.
	%
	\begin{enumerate}
		\item[(i)] If $H^t(E) < \infty$, then $H^s(E) = 0$.
		\item[(ii)] If $H^s(E) \neq 0$, then $H^t(E) = \infty$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	Suppose that $H^t(E) = A < \infty$. Then for any $\delta > 0$, there is a cover of $E$ by a collection of intervals $\{ Q_k \}$, such that $l(Q_k) \leq \delta$ for each $k$, and
	%
	\[ \sum l(Q_k)^t \leq A < \infty. \]
	%
	But then
	%
	\[ H^s_\delta(E) \leq \sum l(Q_k)^s \leq \sum l(Q_k)^{s-t} l(Q_k)^t \leq \delta^{s-t} A. \]
	%
	As $\delta \to 0$, we conclude $H^s(E) = 0$, proving \emph{(i)}. And \emph{(ii)} is just the contrapositive of (i), and therefore immediately follows.
\end{proof}

\begin{corollary} \label{corollaryhausdorffzero}
	If $s > d$, $H^s = 0$.
\end{corollary}
\begin{proof}
	The measure $H^d$ is just the Lebesgue measure on $\RR^d$, so
	%
	\[ H^d[-N,N]^d = (2N)^d. \]
	%
	If $s > d$, Lemma \ref{HausdorffBoundary} shows $H^s[-N,N]^d = 0$. By countable additivity, taking $N \to \infty$ shows $H^s(\RR^d) = 0$. Since $H^s$ is a positive measure, $H^s(E) = 0$ for all $E$.
\end{proof}

Given any Borel set $E$, Corollary \ref{corollaryhausdorffzero}, combined with Lemma \ref{HausdorffBoundary}, implies there is a unique value $s_0 \in [0,d]$ such that $H^s(E) = 0$ for $s > s_0$, and $H^s(E) = \infty$ for $0 \leq s < s_0$. We refer to $s_0$ as the \emph{Hausdorff dimension} of $E$, denoted $\hausdim(E)$.

\begin{theorem}
	For any bounded set $E$, $\hausdim(E) \leq \lowminkdim(E) \leq \upminkdim(E)$.
\end{theorem}
\begin{proof}
	Given $l > 0$, we have a simple bound $H^s_l(E) \leq N(l,E) \cdot l^s$. If $\lowminkdim(E) < s$, then there exists a sequence $\{ l_k \}$ with $l_k \to 0$, and $N(l_k,E) \leq (1/l_k)^s$. Thus we conclude that
	%
	\[ H^s(E) = \lim_{k \to \infty} H^s_{l_k}(E) \leq \lim_{k \to \infty} N(l_k,E) \cdot l_k^s \leq 1, \]
	%
	Thus $\hausdim(E) \leq s$. Taking infima over all $s$, we find $\hausdim(E) \leq \lowminkdim(E)$.
\end{proof}

\begin{remark}
	If $\hausdim(E) < d$, then $|E| = H^d(E) = 0$. Thus any set with fractional dimension less than $d$ must have measure zero. This means we can use the dimension as a way of distinguishing between sets of measure zero, which is precisely what we need to study configuration avoidance problem for non-discrete configurations.
\end{remark}

The fact that Hausdorff dimension is defined over multiple scales simultaneously makes it more stable under analytical operations. In particular, for any family of at most countably many sets $\{ E_k \}$,
%
\[ \hausdim \left\{ \bigcup E_k \right\} = \sup \left\{ \hausdim(E_k) \right\}. \]
%
This need not be true for the Minkowski dimension; a single point has Minkowski dimension zero, but the rational numbers, which are a countable union of points, have Minkowski dimension one. An easy way to make Minkowski dimension countably stable is to define the \emph{modified Minkowski dimensions}
%
\begin{align*}
	\lmbdim(E) &= \inf \left\{ s : E \subset \bigcup_{i = 1}^\infty E_i, \lowminkdim(E_i) \leq s \right\}
\end{align*}
%
and
%
\begin{align*}
	\umbdim(E) &= \inf \left\{ s : E \subset \bigcup_{i = 1}^\infty E_i, \upminkdim(E_i) \leq s \right\}.
\end{align*}
%
This notion of dimension, in a disguised form, appears in Chapter BLAH.







\section{Dyadic Scales}

It is now useful to introduce the dyadic notation we utilize throughout this thesis. At the cost of losing topological perspective about $\RR^d$, applying dyadic techniques often allows us to elegantly discretize certain problems in Euclidean space.

Fix an integer $N$. The classic family of dyadic cubes with \emph{branching factor} $N$ is given by setting, for each integer $k \geq 0$,
%
\[ \DD_k^d = \left\{ \prod_{i = 1}^d \left[ \frac{n_i}{N^k}, \frac{n_i + 1}{N^k} \right] : n \in \ZZ^d \right\}, \]
%
and then setting $\DD = \bigcup_{k \geq 0} \DD_k^d$. Elements of $\DD$ are known as \emph{dyadic cubes}, and elements of $\DD_k^d$ are known as \emph{dyadic cubes of generation $k$}. The most important properties of the dyadic cubes is that for each $k$, $\DD_k^d$ is a cover of $\RR^d$ by cubes of sidelength $1/N^k$, and for any two cubes $Q,R \in \DD$, either their interiors are disjoint, or one cube is nested in the other.
%
\begin{itemize}
	\item For each cube $Q \in \DD_{k+1}^d$, there is a unique cube $R \in \DD_k^d$ such that $Q \subset R$. We refer to $R$ as the \emph{parent} of $Q$, and $Q$ as a \emph{child} of $R$. Each cube in $\DD$ has exactly $N^d$ children. For $Q \in \DD_{k+1}^d$, we let $Q^* \in \DD_k^d$ denote it's parent.

	\item We say a set $E \subset \RR^d$ is \emph{$\DD_k$ discretized} if it is a union of cubes in $\DD_k^d$. If $E$ is $\DD_k$ discretized, we define
	%
	\[ \DD_k(E) = \{ Q \in \DQ_k^d : Q \subset E \}. \]
	%
	Then $E = \bigcup \DD_k(E)$.

	\item Given $k \geq 0$, and $E \subset \RR^d$, we let
	%
	\[ E(1/N^k) = \bigcup \{ Q \in \DD_k^d : Q \cap E \neq \emptyset \}. \]
	%
	Then $E(1/N^k)$ is the smallest $\DD_k$ discretized set containing $E$ in it's interior. Our choice of notation invites thinking of $E(1/N^k)$ as a discretized version of the classic $1/N^k$ thickening
	%
	\[ \{ x \in \RR^d : d(x,E) < 1/N^k \}. \]
	%
	We have no need for the standard thickening in this thesis, so there is no notational conflict.
\end{itemize}
%
Since any cube is covered by at most $O_d(1)$ cubes in $\DD$ of comparable sidelength, from the perspective of geometric measure theory, working with dyadic cubes is normally equivalent to working with the class of all cubes.

Our main purpose with working with dyadic cubes is to construct \emph{fractal-type sets}. By this, we mean defining sets $X$ as the intersection of a nested family of sets $\{ X_k \}$, where each $X_k$ is $\DD_k$ discretized, and each succesive set $X_{k+1}$ is obtained from $X_k$ by application of a simple procedure applied recursively. Such a construction satisfies Property (i), (ii), and (v) of Falconer's definition of a fractal, justifying the name.

\begin{example}
	A classic fractal-type set is the Cantor set $C$. We form $C$ from the family of dyadic cubes with branching factor $M = 3$. We initially set $C_0 = [0,1]$. Then, given the $\DD_k$ discretized set $C_k$, we consider each $I \in \DD_k^1(C_k)$, and let $\DD_{k+1}^1(I) = \{ I_1, I_2, I_3 \}$, where $I_1, I_2, I_3$ are listed in order. We set
	%
	\[ C_{k+1} = \bigcup \{ I_1 \cup I_3 : I \in \DD_k^1(C_k) \}. \]
	%
	Then $C = \bigcap_{k \geq 0} C_k$ is the Cantor set.
\end{example}

Unfortunately, a \emph{constant} branching factor is not sufficient to describe the types of recursive procedures we discuss in this thesis. This motivates a more general iterated family of cubes. Instead of a single branching factor $N$, we fix a sequence of positive integers $\{ N_k : k \geq 1 \}$, with $N_k \geq 2$ for all $k$, which give the branching factor at each stage of the dyadic cubes we define.
%
\begin{itemize}
	\item For each $k \geq 0$, we define 
	%
	\[ \DQ_k^d = \left\{ \prod_{i = 1}^d \left[ \frac{m_i}{N_1 \dots N_k}, \frac{m_i + 1}{N_1 \dots N_k} \right] : m \in \ZZ^d \right\}. \]
	%
	These are the \emph{dyadic cubes of generation $k$}. We let $\DQ^d = \bigcup_{k \geq 0} \DQ_k^d$. Note that any two cubes $\DQ^d$ are either nested within one another, or disjoint from one another.

	\item We set $l_k = (N_1 \dots N_k)^{-1}$. Then $l_k$ is the sidelength of the cubes in $\DQ_k^d$.

	\item Given $Q \in \DQ_{k+1}^d$, we let $Q^* \in \DQ_k^d$ denote the \emph{parent cube} of $Q$, i.e. the unique dyadic cube of generation $k$ such that $Q \subset Q^*$.

	\item We say a set $E \subset \RR^d$ is \emph{$\DQ_k$ discretized} if it is a union of cubes in $\DQ_k^d$. In this case, we let
	%
	\[ \DQ_k(E) = \{ Q \in \DQ_k^d: Q \subset E \} \]
	%
	denote the family of cubes whose union is $E$.

	\item For $E \subset \RR^d$ and $k \geq 0$, we let $E(l_k) = \{ Q \in \DQ_k^d : Q \cap E = \emptyset \}$.
\end{itemize}
%
%The most common class of dyadic cubes in analysis is obtained by setting $N_k = 2$ for each $k$. We reserve a special notation for this class of dyadic cubes; the class of all such cubes is denoted by $\DD^d$, and the generation $k$ cubes by $\DD^d_k$. The fact that the sequence $\{ N_k \}$ is constant makes these cubes more easy to analyze. But in our methods, it is necessary for the sequence $\{ N_k \}$ to become unbounded as $k \to \infty$. This is why we have to introduce the more general family of dyadic cubes introduced above.
%
Sometimes, our recursive constructions need a family of `intermediary' cubes that lie between the scales $\DQ_k^d$ and $\DQ_{k+1}^d$. In this case, we consider a supplementary sequence $\{ M_k : k \geq 1 \}$ with $M_k \divides N_k$ for each $k$.
%
\begin{itemize}
	\item For $k \geq 1$, we define
	%
	\[ \DR_k^d = \left\{ \prod_{i = 1}^d \left[ \frac{m_i}{N_1 \dots N_{k-1} M_k} , \frac{m_i + 1}{N_1 \dots N_{k-1} M_k} \right] : m \in \mathbf{Z}^d \right\}. \]

	\item We set $r_k = (N_1 \dots N_{k-1} M_k)^{-1}$. Then $r_k$ is the sidelength of a cube in $\DR_k^d$.

	\item The notions of being $\DR_k^d$ discretized, the collection of cubes $\DR_k^d(E)$, and the sets $E(r_k)$, are defined as should be expected.
\end{itemize}
%
The cubes in $\DR_k^d$ are coarser than those in $\DQ_k^d$, but finer than those in $\DQ_{k-1}^d$.

\begin{remark}
	We note that there is some notational conflict between the cubes $\DD^d$ and the cubes $\DQ^d$, but since we never use both families simultaneously in a single argument, it should be clear which notation we are using.
\end{remark}

%For the purposes of discretization, and to simplify notation, it is very useful to identify those cubes in $\DQ_k^d$ which are subsets of $[0,1]^d$ with the set
%
%\[ \Sigma_k^d = [N_1]^d \times \dots \times [N_k]^d. \]
%
%Given $j \in \Sigma_m^d$, we let $Q_j \in \DQ_m^d$ denote the cube with left-hand corner $a = \sum_{k = 1}^m j_kl_k$. Thus subcubes of a cube corresponding to an index $j \in \Sigma_k^d$ correspond to indices obtained by appending additional integers onto $j$. In the case of intermediary scales, we abuse notation, writing $[N_k] = [K_k] \times [M_k]$, we have
%
%\[ \Sigma_k^d = \big([K_1] \times [M_1] \big)^d \times \dots \times \big([K_k] \times [M_k] \big)^d, \]
%
%where $n \in [N_k]$ is equal to $(k,m) \in [K_k] \times [M_k]$, where $k M_k + m = n$.

%One very useful property of the cubes in $\DQ^d$ is that cubes are either nested within one another, or \emph{almost disjoint} from one another, in the sense that only their boundaries intersect. Thus we can think of $\DQ^d$ as a forest under the partial ordering of inclusion, with the roots corresponding to the elements of $\DQ_0^d$. Each cube $Q \in \DQ^d_k$ has $N_{k+1}^d$ children. For each cube $Q \in \DQ_{k+1}^d$, we will let $Q^* \in \DQ_k^d$ denote it's parent, i.e. the unique cube in $\DQ_k^d$ with $Q \subset Q^*$. Similarily, given an index $I = (I_0, \dots, I_{k+1}) \in \Sigma_{k+1}$, we let $I^* = (I_0, \dots, I_k) \in \Sigma_k$, so that $Q_I \subset Q_{I^*}$.

%We often construct configuration avoiding sets as limits of dyadic discretizations. It is most convenient to describe this construction in terms of a sequence of sets $\{ S_k \}$ with $S_k \subset \Sigma_k^d$ for each $k$, and $(S_{k+1})^* \subset S_k$ for each $k$. We refer to such a sequence as a \emph{constructing sequence}. We can define $E_k = \bigcup \{ Q_j : j \in S_k \}$. Then $E_{k+1} \subset E_k$ for each $k$, and we can form a set $\bigcap E_k$, which is the final, non discretized limit of the sequence of discretizations.

%We can also give the spaces $\Sigma_k^d$ and $\Sigma^d$ a metric space structure, by defining, for $I \neq J$, $d(I,J) = l_k$, where $k$ is the smallest index such that $I_k \neq J_k$. Aside from the fact that some points in $\RR^d$ are duplicated in $\Sigma^d$, the main difference between the two spaces is that the balls in $\Sigma^d$ are discretized to the scales $\{ l_k \}$. From the point of view of geometric measure theory, the first point is neglible, but we shall find that discretization does matter. The degree to which the geometry of $\Sigma^d$ models the geometry of $\RR^d$ from the perspective of geometric measure theory is a key topic in this thesis. We shall find that the rate at which the lengths $l_k$ tend to zero will be a key factor in this relationship.

\section{Frostman Measures}

%\begin{example}
%	Let $s = 0$. Then $H_\delta^0(E)$ is the number of $\delta$ balls it takes to cover $E$, which tends to $\infty$ as $\delta \to 0$ unless $E$ is finite, and in the finite case, $H_\delta^0(E) \to \# E$. Thus $H^0$ is just the counting measure.
%\end{example}

%\begin{example}
%	Let $s = d$. If $E$ has Lebesgue measure zero, then for any $\varepsilon > 0$, there exists a sequence of balls $\{ B(x_k,r_k) \}$ covering $E$ with
	%
%	\[ \sum_{k = 1}^\infty r_k^d < \varepsilon^d. \]
	%
%	Then we know $r_k < \varepsilon$, so $H^s_\varepsilon(E) < \varepsilon^d$. Letting $\varepsilon \to 0$, we conclude $H^d(E) = 0$. Thus $H^d$ is absolutely continuous with respect to the Lebesgue measure. The measure $H^d$ is translation invariant, so $H^d$ is actually a constant multiple of the Lebesgue measure.
%\end{example}

It is often easy to upper bound Hausdorff dimension, but non-trivial to \emph{lower bound} the Hausdorff dimension of a given set. A key technique to finding a lower bound is \emph{Frostman's lemma}, which says that a set has large Hausdorff dimension if and only if it supports a probability measure which obeys a certain decay law on small sets. We say a Borel probability measure $\mu$ is a \emph{Frostman measure} of dimension $s$ if it is non-zero, compactly supported, and there exists $C > 0$ such that for any cube $Q$, $\mu(Q) \leq C \cdot l(Q)^s$. The proof of Frostman's lemma will utilize a technique often useful, known as the \emph{mass distribution principle}. Such a principle was stated in BLAH.

\begin{lemma}
	For each $k \geq 0$, let $\mathcal{E}_k$ be a finite collection of non-empty, compact, disjoint subsets of $\RR^d$, such that for each $A \in \mathcal{E}_{k+1}$, there is a unique $A^* \in \mathcal{E}_k$ such that $A \subset A^*$, and for any $A^* \in \mathcal{E}_k$, there is at least one $A \in \mathcal{E}_{k+1}$ with $A \subset A^*$. Let $E_k = \bigcup \mathcal{E}_k$, and let $E_\infty = \bigcap E_k$. Let $\mu: \bigcup_{k \geq 0} \mathcal{E}_k \to [0,\infty)$ be a function such that for any $i$, and for any $A \in \mathcal{E}_i$,
	%
	\begin{equation} \label{equation124069350740597} \mu(A) = \sum \{ \mu(B) : B \in \mathcal{E}_{i+1}, B \subset A \}. \end{equation}
	%
	Then $\mu$ extends to a finite Borel measure on $\RR^d$ supported on $E_\infty$.
\end{lemma}
\begin{proof}
	Let $\mathcal{E} = \bigcup_{k \geq 0} \mathcal{E}_k \cup \mathcal{P}(\RR^d - E_k)$. Then $\mathcal{E}$ is a \emph{semi-ring} of sets:
	%
	\begin{itemize}
		\item \emph{$\mathcal{E}$ is closed under intersections}: Let $A, B \in \mathcal{E}$. Then without loss of generality, swapping $A$ and $B$ if necessary, there exists $i \leq j$ such that $A \in \mathcal{E}_i$ or $A \subset \RR^d - E_i$, and $B \in \mathcal{E}_j$ or $B \subset \RR^d - E_j$.

		If $A \in \mathcal{E}_i$, and $B \in \mathcal{E}_j$, then either $A \cap B = \emptyset$, or $B \subset A$, and $A \cap B = B$. In either case, $A \cap B \in \mathcal{E}$.

		If $A \subset \RR^d - E_i$, then $A \cap B \subset A \subset \RR^d - E_i$, so $A \cap B \in \mathcal{E}$. Similarily, if $B \subset \RR^d - E_j$, then $A \cap B \subset \RR^d - E_j$, so $A \cap B \in \mathcal{E}$.

		This addresses all cases.

		\item \emph{$\mathcal{E}$ is closed under relative complements}: Let $A,B \in \mathcal{E}$. Then there exists $i,j$ such that $A \in \mathcal{E}_i$ or $A \subset \RR^d - E_i$, and $B \in \mathcal{E}_j$ or $B \subset \RR^d - E_j$.

		Suppose $A \in \mathcal{E}_i$ and $B \in \mathcal{E}_j$. If $i \geq j$, then either $A \cap B = \emptyset$, or $A \subset B$. In either case, $A - B = \emptyset \in \mathcal{E}$. If $i \leq j$, then either $A \cap B = \emptyset$, or $B \subset A$. In the latter case,
		%
		\[ A - B = \left( \bigcup \{ C : C \in \mathcal{E}_j, C \neq B, C \subset A \} \right) \cup \{ A - E_j \}. \]
		%
		This gives $A - B$ as a disjoint union of elements of $\mathcal{E}$.

		Suppose $A \in \mathcal{E}_i$, and $B \subset \RR^d - E_j$. If $i \geq j$, then $A \subset E_i \subset E_j$, so $A - B = A$. If $i \leq j$, then
		%
		\[ A - B = (A \cap E_j) \cup (A \cap (\RR^d - B)). \]
		%
		The former set can be written as $\bigcup \{ A' \in \mathcal{E}_j : A' \subset A \}$, and the latter set is a subset of $\RR^d - E_j$. This gives $A - B$ as a disjoint union of elements of $\mathcal{E}$.

		If $A \subset \RR^d - E_i$, then $A - B \subset \RR^d - E_i$, so $A - B \in \mathcal{E}$.

		This addresses all cases.
	\end{itemize}
	%
	The function $\mu$ extends to a function on $\mathcal{E}$ by setting $\mu(E) = 0$ if $E \subset \RR^d - E_k$ for some $k$. This does not conflict with our previous definition, since if $A \in \mathcal{E}_i$, then $A \cap E_j \neq \emptyset$ for all $j \geq 0$. We claim that $\mu$ is then a \emph{pre-measure} on the semi-ring:
	%
	\begin{itemize}
		\item It is certainly true that $\mu(\emptyset) = 0$.

		\item Let $A \in \mathcal{E}$, and suppose $A = \bigcup_i A_i$, where $\{ A_i \}$ is an at most countable subcollection of disjoint sets from $\mathcal{E}$. We fix $k$ such that $A \in \mathcal{E}_k$, or $A \subset \RR^d - E_k$, and for each $i$, fix $k_i$ such that $A_i \in \mathcal{E}_{k_i}$, or $A \subset \RR^d - E_{k_i}$.

		If $A \in \RR^d - E_k$ for some $k$, then $A_i \in \RR^d - E_k$ for each $i$, and thus $\mu(A_i) = 0$ for all $i$. Since $\mu(A) = 0$, this means $\mu(A) = \sum \mu(A_i)$.

		Suppose $A \in \mathcal{E}_k$, and let $A_\infty = A \cap E_\infty$. If $B \in \mathcal{E}_k$ for any $k$, then $B \cap A_\infty$ is \emph{relatively open} in $A_\infty$ because the sets in $\mathcal{E}_k$ cover $A_\infty$ and are separated. Note that $A_\infty \cap (\RR^d - E_k) = \emptyset$ for all $k$. Thus the family of sets $\{ A_i : A_i \in \mathcal{E}_{k_i} \}$ is a relatively open cover of $A_\infty$. Since $A_\infty$ is compact, it must have a finite subcover. But applying compactness, $A_i \cap A_\infty \neq \emptyset$ for all $i$ with $A_i \in \mathcal{E}_{k_i}$, so we conclude the set $\{ A_i : A_i \in \mathcal{E}_{k_i} \}$ is finite.

		Since the family of $A_i$ with $A_i \in \mathcal{E}_{k_i}$ is finite, we can repeatedly apply \eqref{equation124069350740597} so that, without loss of generality, we may assume there is a common integer $N$ such that $A_i \in \mathcal{E}_N$ for all $i$ with $\mu(A_i) > 0$. To prove that $\mu(A) = \sum \mu(A_i)$, it now suffices to show that for each $B \in \mathcal{E}_N$ with $B \subset A$, $B = A_i$ for some $i$. But this is obvious, since $\{ A_i : A_i \in \mathcal{E}_N \}$ covers $A_\infty$, and every such $B$ satisfies $B \cap A_\infty \neq \emptyset$.
	\end{itemize}
	%
	The Caratheodory extension theorem guarantees that $\mu$ extends to a measure on the $\sigma$ algebra generated by $\mathcal{E}$, denoted $\sigma(\mathcal{E})$. We claim this $\sigma$ algebra contains all Borel sets. Let $F$ be a closed set. Then
	%
	\[ F \cap E_\infty = \bigcap_k \left[ \bigcup \{ A : A \in \mathcal{E}_k, A \cap F \neq \emptyset \} \right] = \bigcap_k \left[ G_k \right]. \]
	%
	Each of the sets $G_k$ is a finite union of elements in $\mathcal{E}_k$, hence $G_k \in \sigma(\mathcal{E})$, and so $F \cap E_\infty = \bigcap_k G_k \in \sigma(\mathcal{E})$. We also find
	%
	\[ F \cap E_\infty^c = \bigcup_k F \cap (\RR^d - E_k) = \bigcup_k G_k'. \]
	%
	Since $G_k' \in \mathcal{E}$ for all $k$, we conclude $F \cap E_\infty^c \in \sigma(\mathcal{E})$. Thus
	%
	\[ F = (F \cap E_\infty) \cup (F \cap E_\infty^c) \in \sigma(\mathcal{E}). \]
	%
	Since $F$ was an arbitrary closed set, this implies all Borel sets are measurable with respect to $\sigma(\mathcal{E})$.
\end{proof}

An alternative approach, leading to a more general theorem, is given by employing weak convergence.

\begin{lemma} \label{weakstarcompleteness}
	A Cauchy sequence of non-negative Borel measures on $\RR^d$ is convergent with respect to the weak $*$ topology.
\end{lemma}
\begin{proof}
	Let $\{ \mu_i \}$ be a Cauchy sequence of non-negative, regular Borel measures. This means that for each $f \in C_c(\RR^d)$, the sequence of numbers
	%
	\[ \left\{ \int f d\mu_i \right\} \]
	%
	is Cauchy. Fix a compact set $K$. then we can find a function $\varphi \in C_c(\RR^d)$ such that $\mathbf{I}_K \leq \varphi$. This means that
	%
	\[ \mu_i(K) = \int \mathbf{I}_K d\mu_i \leq \int \varphi d\mu_i. \]
	%
	Since $\{ \int \varphi d\mu_i \}$ is Cauchy, it is uniformly bounded in $i$. In particular, $\mu_i(K)$ is uniformly bounded in $i$. Thus the measures $\mu_i|_K$ are uniformly finite, and we can apply the Banach Alaoglu theorem to find a regular Borel measure $\mu^K$ such that $\mu_i|_K \to \mu^K$ weakly. Note that if $f \in C_c(\RR^d)$ is supported on $K_1 \cap K_2$ for two compact sets $K_1$ and $K_2$, then
	%
	\[ \int f d\mu^{K_1} = \lim_{i \to \infty} \int_{K_1} f d\mu_i = \lim_{i \to \infty} \int_{K_2} f d \mu_i = \int f d\mu^{K_2}. \]
	%
	Thus we can define a measure $\mu$ such that
	%
	\[ \int f d\mu = \lim_{K \to \infty} \int f d\mu^K. \]
	%
	For any $f \in C_c(\RR^d)$ supported on a compact set $K$,
	%
	\[ \int f d\mu = \int f d\mu^K = \lim_{i \to \infty} \int_K f d\mu_i = \lim_{i \to \infty} \int f d\mu_i. \]
	%
	Since $f$ was arbitrary, $\mu_i \to \mu$ weakly.
\end{proof}

\begin{lemma}[Mass Distribution Principle] \label{massdistributionprinciplelem}
	Let $f: \DQ^d \to [0,\infty)$ be a function such that for any $Q_0 \in \DQ^d$,
	%
	\begin{equation} \label{equation73234091} \sum_{Q^* = Q_0} f(Q) = f(Q_0), \end{equation}
	%
	Then there exists a regular Borel measure $\mu$ supported on
	%
	\[ \bigcap_{k = 1}^\infty \left[ \bigcup \{ Q \in \DQ_k^d : f(Q) > 0 \} \right] \]
	%
	such that for each $Q \in \DQ^d$,
	%
	\begin{equation} \label{massdissupperbound} \mu(Q) \geq f(Q), \end{equation}
	%
	and for any set $E$ and $k \geq 0$,
	%
	\begin{equation} \label{massdisslowerbound} \mu(E) \leq \sum f(Q), \end{equation}
	%
	where $Q$ ranges over all cubes in $\DQ^d_k(E(l_k))$.
\end{lemma}
\begin{proof}
	For each $i$, let $\mu_i$ be a regular Borel measure such that for each $j \leq i$, and $Q \in \DQ_j^d$, $\mu_i(Q) = f(Q)$. One such choice is given, for each $f \in C_c(\RR^d)$, by the equation
	%
	\[ \int f d\mu_i = \sum_{Q \in \DQ_i^d} \frac{f(Q)}{|Q|} \int_Q f\; dx. \]
	%
	We claim that $\{ \mu_i \}$ is a Cauchy sequence in the space of all regular Borel measures on $\RR^d$, viewing the space as a locally convex space under the weak topology. Fix $\varphi \in C_c(\RR^d)$, and choose some $N$ such that $\varphi$ is supported on $[-N,N]^d$. Set $Q_0 = [-N,N]^d$. Since $\varphi$ is compactly supported, $\varphi$ is \emph{uniformly continuous}, so for each $\varepsilon > 0$, if $i$ is suitably large, there is a sequence of values $\{ a_Q : Q \in \DQ_i^d(Q_0) \}$ such that if $x \in Q$, $|\varphi(x) - a_Q| \leq \varepsilon$. But this means that
	%
	\[ \sum (a_Q - \varepsilon) \mathbf{I}_Q \leq \varphi \leq \sum (a_Q + \varepsilon) \mathbf{I}_Q, \]
	%
	where $Q$ ranges over cubes in $\DQ_i^d(Q_0)$. Thus for any $j \geq i$,
	%
	\[ \int \varphi\; d\mu_j\leq \sum (a_Q + \varepsilon) \mu_j(Q) = \sum (a_Q + \varepsilon) f(Q) \]
	%
	and
	%
	\[ \int \varphi\; d\mu_j \geq \sum (a_Q - \varepsilon) \mu_j(Q) = \sum (a_Q - \varepsilon) f(Q). \]
	%
	In particular, if $j,j' \geq i$,
	%
	\[ \left| \int \varphi d\mu_j - \int \varphi d\mu_{j'} \right| \leq 2 \varepsilon \sum_{Q \in \DQ_i(Q_0)} f(Q) = 2\varepsilon \sum_{Q \in \DQ_0(Q_0)} f(Q). \]
	%
	Since $\varepsilon$ and $\varphi$ were arbitrary, this shows $\{ \mu_i \}$ is Cauchy.

	Applying Lemma \ref{weakstarcompleteness}, there exists a regular Borel measure $\mu$ such that $\mu_i \to \mu$ weakly. For any $Q \in \DQ^d$, since $Q$ is a closed set,
	%
	\[ \mu(Q) \geq \limsup_{i \to \infty} \mu_i(Q) = f(Q). \]
	%
	Conversely, if $E$ is an arbitrary set, then $E \subset E(l_i)^\circ$ for any $i$, so
	%
	\[ \mu(E) \leq \liminf_{i \to \infty} \mu_i(E(l_i)^\circ) \leq \liminf_{i \to \infty} \mu_i(E(l_i)) = \sum f(Q), \]
	%
	where $Q$ ranges over the cubes in $\DQ_i^d(E(l_k))$.
\end{proof}

%\begin{lemma}
%	let $\mu^+$ be a function from $\B$ to $[0,\infty)$ such that for any $I \in \B(1/M^k,\RR^d)$,
	%
%	\[ \sum \left\{ \mu^+(J) :J \in \B(1/M^{k+1},I) \right\} \leq \mu^+(I) \]
	%
%	Assume there exists $c > 0$ such that for all $k$,
	%
%	\[ \sum \left\{ \mu^+(I) : I \in \B(1/M^k,I) \right\} \geq c \]
	%
%	and
	%
%	\[ \sum \left\{ \mu^+(I) : I \in \B(1,I) \right\} < \infty \]	
	%
%	Then there exists a non-zero Borel measure $\mu$ such that $\mu(I) \leq \mu^+(I)$ for $I \in \B$.
%\end{lemma}
%\begin{proof}
%	As in the last lemma, define the operators $E_k$ and the measures $\mu_k$. By weak compactness, a subsequence of these measures converge weakly to some measure $\mu$, and $E_k(\mu) = \lim E_k(\mu_{j_k}) \leq \mu_k$. The measure $\mu$ is nonzero, since $\| \mu_{j_k} \| \geq c$ for each $k$, and so $\| \mu \| \geq c$.
%\end{proof}

\begin{lemma}[Frostman's Lemma]
	If $E$ is a Borel set, $H^s(E) > 0$ if and only if there exists an $s$ dimensional Frostman measure supported on $E$.
\end{lemma}
\begin{proof}
	Suppose that $\mu$ is $s$ dimensional and supported on $E$. If $H^s(F) = 0$, then for each $\varepsilon > 0$ there is a sequence of cubes $\{ Q_k \}$ with $\sum_{k = 1}^\infty l(Q_k)^s \leq \varepsilon$. But then
	%
	\[ \mu(F) \leq \sum_{k = 1}^\infty \mu(Q_k) \lesssim \sum_{k = 1}^\infty l(Q_k)^s \leq \varepsilon. \]
	%
	Taking $\varepsilon \to 0$, we conclude $\mu(F) = 0$. Thus $\mu$ is absolutely continuous with respect to $H^s$. Since $\mu(E) > 0$, this means that $H^s(E) > 0$.

	To prove the converse, we will suppose for simplicity that $E$ is compact. We work dyadically, with the classical family of dyadic cubes $\DD$.  By translating, we may assume that $H^s(E \cap [0,1]^d) > 0$, and so without loss of generality we may assume $E \subset [0,1]^d$. For each $Q \in \DD_k^d$, define $f^+(Q) = H^s_\infty(E \cap Q)$. Then $f^+(Q) \leq 1/2^{ks}$, and $f^+$ is subadditive. We try and define a function $f$ to which we can apply Lemma \ref{massdistributionprinciplelem}. We initially define $f$ by setting $f([0,1]^d) = f^+([0,1]^d)$. Given $Q \in \DD_k^d$, we enumerate it's children as $Q_1, \dots, Q_M \in \DD_{k+1}^d$. We then consider any values $A_1, \dots, A_M \geq 0$ such that
	%
  	\begin{equation} \label{equation3424209034}
  		A_1 + \dots + A_M = f(Q),
  	\end{equation}
  	%
  	and for each $k$,
  	%
  	\begin{equation} \label{equation12039123012}
  		A_k \leq f^+(Q_k).
  	\end{equation}
	%
	This is feasible to do because $f^+(Q_1) + \dots + f^+(Q_M) \geq f^+(Q)$. We then define $f(Q_k) = A_k$ for each $k$. Equation \eqref{equation3424209034} implies the recursive constraint is satisfied, so $f$ is a well defined function. Furthermore, \eqref{equation3424209034} implies \eqref{equation73234091} of Lemma \ref{massdistributionprinciplelem}, and so the mass distribution principle implies that there exists a measure $\mu$ supported on $E$, satisfying \eqref{massdisslowerbound} and \eqref{massdissupperbound}. In particular, \eqref{massdisslowerbound} implies $\mu$ is non-zero. For each $Q \in \DD_k^d$, $\#[\DD_k^d(Q(l_k))] = 3^d = O_d(1)$, so we can apply \eqref{massdissupperbound} to conclude
	%
	\[ \mu(Q) \lesssim_d \max f(Q') \leq 1/2^{ks} = l(Q)^s. \]
	%
	where $Q'$ ranges over the cubes in $\DD_k^d(Q(l_k))$. Given any cube $Q$, we find $k$ with $1/2^{k-1} \leq l(Q) \leq 1/2^k$. Then $Q$ is covered by $O_d(1)$ dyadic cubes in $\DD_k^d$, and so $\mu(Q) \lesssim l(Q)^s$. Thus $\mu$ is a Frostman measure of dimension $s$.
\end{proof}

Frostman's lemma implies that to study the Hausdorff dimension of the set, it suffices to understand the class of measures which can be supported on that set. The Fourier dimension of a set also studies this perspective, by slightly refining the measure bound required by the Frostman dimension in frequency space.











\begin{comment}

\section{Fourier Dimension}

The applicability of Fourier analysis to the analysis of dimension begins by converting the measure bound required on the Frostman dimension onto a condition on the Fourier transform of the measure. For a Borel measure $\mu$, we define the \emph{$s$ energy} of $\mu$ as
%
\[ I_s(\mu) = \int \int \frac{d\mu(x) d\mu(y)}{|x - y|^s}. \]
%
A simple rearrangement shows that for each $y$,
%
\[ \int \int \frac{d\mu(x) d\mu(y)}{|x - y|^s} = s \int_0^\infty \frac{\mu(B(x,r))}{r^{s+1}}\; dr, \]
%
where $B(x,r)$ is the open ball of radius $r$ about the point $x$. This enables us to relate the Frostman bound with energy integrals.

\begin{theorem}
	For any set $E$,
	%
	\[ \hausdim(E) = \sup \{ s : \text{there is $\mu$ supported on $E$ with $I_s(\mu) < \infty$} \}. \]
\end{theorem}
\begin{proof}
	For each $x \in \RR^d$ and $r > 0$, let $B(x,r)$ denote the open ball of radius $r$ centered at $x$. We note $\mu$ is an $s$ dimensional Frostman measure if and only if $\mu(B(x,r)) \lesssim r^s$, since every dyadic cube with sidelength $r$ is contained in $O_d(1)$ balls of radius $r$, and every ball of radius $r$ is contained in $O_d(1)$ dyadic cubes with sidelength $r$. Thus if $\mu$ is a Frostman measure with dimension less than $s$, then $I_s(\mu) < \infty$. Conversely, if $I_s(\mu) < \infty$, then for $\mu$ almost every $y$,
	%
	\[ \int \frac{d\mu(x)}{|x - y|^s} < \infty \]
	%
	In particular, there is $M < \infty$, and $E_0$ with $\mu(E_0) > 0$ such that for any $y \in E_0$,
	%
	\[ \int \frac{d\mu(x)}{|x - y|^s} \leq M. \]
	%
	If we let $\nu(E) = \mu(E \cap E_0)$, then for any $y \in \RR^d$, if $\nu(B(y,r)) > 0$, there is $y_0 \in E \cap B(y,r)$, so $B(y,r) \subset B(y_0,2r)$, and this implies
	%
	\[ \nu(B(y,r)) \leq \nu(B(y_0,2r)) \leq \int_{B(y_0,2r)} d\nu(x) \leq 2^s r^s \int_{B(y_0,2r)} \frac{d\nu(x)}{|x - y|^s} \leq (2^s M) r^s. \]
	%
	Thus $\nu$ is a Frostman measure of dimension $s$ supported on $E$.
\end{proof}

\begin{lemma}
	There exists a constant $C(d,s)$ such that
	%
	\[ I_s(\mu) = C(d,s) \int k_{d-s}(\xi) |\widehat{\mu}(\xi)|^2\; d\xi. \]
\end{lemma}
\begin{proof}
	We can convert the energy integral into a condition on the Fourier transform. If we define the \emph{Riesz kernels} $k_s(x) = 1/|x|^s$, for $0 < s < d$, then
	%
	\[ I_s(\mu) = \int (k_s * \mu) d\mu. \]
	%
	We use the fact that the Fourier transform of $k_s$ is equal to $C(d,s) k_{d-s}$ for some constant $C(d,s)$. Naively applying the multiplication formula for the Fourier transform, we find
	%
	\begin{align*}
		\int (k_s * \mu)(x) d\mu(x) &= \int \widehat{k_s * \mu}(\xi) \widehat{\mu}(\xi)\; dx\\
		&= \int \widehat{k_s}(\xi) |\widehat{\mu}(\xi)|^2\; d\xi\\
		&= C(d,s) \int k_{d-s}(\xi) |\widehat{\mu}(\xi)|^2\; d\xi.
	\end{align*}
	%
	This is not a rigorous argument, because the kernels $k_s$ and the measure $\mu$ do not lie in $L^1(\RR^d)$. Nonetheless, the equation can be interpreted in a distribution sense. In particular, if $d\mu = fdx$, then the argument is rigorous, and approximating measures $\mu$ be Schwartz functions establishes the argument. We leave the technical argument to other sources, e.g. BLAH.
\end{proof}

Thus the application of energy integrals translates the problem of finding a Frostman measure bound to frequency space. In particular, if $\mu$ is a Frostman measure of dimension $s$, then
%
\[ \int \frac{|\widehat{\mu}(\xi)|^2}{|\xi|^{d-s}}\; d\xi < \infty. \]
%
A weak type bound implies that we should have
%
\begin{equation} \label{equation89041094242} |\widehat{\mu}(\xi)|^2 \lesssim |\xi|^{-s/2} \end{equation}
%
for \emph{most} values $\xi$. Thus we obtain a stronger condition if we require that \eqref{equation89041094242} holds for \emph{all} values $\xi$. We say a measure $\mu$ is a measure with \emph{Fourier dimension} $s$ if there exists a constant $C$ such that for all $\xi$,
%
\[ |\widehat{\mu}(\xi)| \leq C \cdot |\xi|^{-s/2}. \]
%
If this is true, then $I_t(\mu) < \infty$ for all $t < s$, so $\mu$ has Frostman dimension $t$ for all $t < s$. Thus if we define the \emph{Fourier dimension} of a set $E$ as
%
\[ \fordim(E) = \sup \left\{ s : \begin{array}{c} \text{there is $\mu$ supported on $E$ with}\\ \text{Fourier dimension $s$} \end{array} \right\}, \]
%
then $\fordim(E) \leq \hausdim(E)$. A set $E$ is \emph{Salem} if $\fordim(E) = \hausdim(E)$. Most classical, self-similar fractals (for instance, the classical Cantor set) have Fourier dimension zero, and are therefore not Salem. Nonetheless, it is a general principle that most \emph{random} families of sets are almost surely Salem. As of now, except in very particular cases, the only way to find large Salem sets is to incorporate randomness into their construction. Using randomness, in Chapter BLAH we are able to find Salem sets with large Fourier dimension.

Later on, we will use two important principles to calculate the Fourier transforms of measures supported $\DQ_k$ discretized sets. The first property is an instance of the Heisenberg uncertainty principle, which says that the Fourier transform of a function $f$ supported on a sidelength $r$ intervals has fast decay outside of a sidelength $1/r$ interval. The second is an instance of the Poisson summation formula, which says that the Fourier transform of a measure $\mu$ supported on $[0,1]^d$ can be read off from it's Fourier series $\{ \widehat{\mu}(k) : k \in \ZZ^d \}$.

\begin{theorem}
	Suppose $\mu$ is supported on $[0,1)^d$.
\end{theorem}
\begin{proof}
	Consider the distribution $\Lambda = \sum_{n \in \mathbf{Z}} \delta_n$, where $\delta_n$ is the Dirac delta function at $n$. Then the Poisson summation formula says that the Fourier transform of $\Lambda$ is itself. If $I = \mathbf{I}_{x \in [0,1)^d}$, then
	%
	\[ |\widehat{I}(\xi)| = \prod_{i = 1}^d \left| \frac{1 - e^{-2 \pi i \xi_i}}{2\pi \xi_i} \right| \lesssim \prod_{i = 1}^d \frac{1}{1 + |\xi_i|} \]
	%
	We have $\mu = I (\Lambda * \mu)$, so
	%
	\begin{align*}
		|\widehat{\mu}(\xi)| &= \left| \left[ \widehat{I} * (\Lambda \widehat{\mu}) \right](\xi) \right| = \left| \sum_{n \in \mathbf{Z}} \widehat{\mu}(n)(\widehat{I} * \delta_n)(\xi) \right| = \left| \sum_{n \in \mathbf{Z}} \widehat{\mu}(n) \widehat{I}(n - \xi) \right|\\
		&\lesssim \sum_{|n - \xi| \leq 1} |\widehat{\mu}(n)| + \sum_{|n - \xi| \geq 1} \frac{|\widehat{\mu}(n)|}{|\xi_1 - n_1| \dots |\xi_d - n_d|}.
	\end{align*}
	%
	\begin{align*}
		\sum_{n \in \ZZ^d} [1 + |n|]^{-s/2} \prod_{i = 1}^d \frac{1}{1 + |\xi_i - n_i|} &\lesssim \int_{\RR^d} [1 + |x|]^{-s/2} \prod_{i = 1}^d \frac{1}{1 + |\xi_i - x_i|} dx\\
		&= \int_{\RR^d} [1 + |x + \xi|]^{-s/2} \prod_{i = 1}^d \frac{1}{1 + |x_i|}.
	\end{align*}
	% [1 + |x|] \geq |x_1| ... |x_d| 
	%
	Now suppose $|\widehat{\mu}(n)| \lesssim |n|^{-s/2}$. If $|\xi| \geq 10$, and $|n - \xi| \leq 1$, then $n^{-s/2} \leq |\xi|^{-s/2}$. Since there are $O(1)$ values $n \in \mathbf{Z}^d$ with $|n - \xi| \leq 1$, this implies that
	%
	\[ \sum_{|n - \xi| \leq 1} |\widehat{\mu}(n)| \lesssim |\xi|^{-s/2}. \]
	%
	On the other hand, since there are $O(1)$ values $n \in \mathbf{Z}$ with $|n| \leq 1$, we find
	%
	\[ \sum_{\substack{|n| \leq 1\\|n - \xi| \geq 1}} \frac{|\widehat{\mu}(n)|}{|\xi_1 - n_1| \dots |\xi_d - n_d|} \lesssim \frac{1}{|\xi_1 - n_1| \dots |\xi_d - n_d|} \]

	and $|\xi| \geq 10$, we perform a dyadic decomposition, writing
	%
	\begin{align*}
		|\widehat{\mu}(\xi)| &\lesssim \sum_{|n - \xi| \leq 1} [1 + |n|]^{-s/2} + \sum_{k = 1}^\infty \sum_{2^{k-1} \leq |n - \xi| \leq 2^k} \frac{[1 + |n|]^{-s/2}}{2^k}.
	\end{align*}
	%
	There are $O(1)$ integers $n$ with $|n - \xi| \leq 1$, and if $|n - \xi| \leq 1$, then $[1 + |n|]^{-s/2} \lesssim |\xi|^{-s/2}$. This shows
	%
	\[ \sum_{|n - \xi| \leq 1} |n|^{-s/2} \lesssim |\xi|^{-s/2}. \]
	%
	For each $k$, there are $O(2^{dk})$ integers $n$ with $2^{k-1} \leq |n - \xi| \leq 2^k$, and for each such $n$, $[1 + |n|]^{-s/2} \lesssim [|\xi| - 2^k]^{-s/2}$
\end{proof}

\end{comment}






\section{Dyadic Fractional Dimension}

We wish to establish results about fractional dimension `dyadically', working with the family of cubes $\DQ^d$ specified in terms of a sequence $\{ N_k : k \geq 1 \}$. We begin with Minkowski dimension. For each $m$, let $N_{\DQ}(m,E)$ denote the minimal number of cubes in $\DQ_m^d$ required to cover $E$. This is often easy to calculate, up to a multiplicative constant, by greedily selecting cubes which intersect $E$.

\begin{lemma} \label{comparableCovers}
	For any set $E$,
	%
	\[ N_{\DQ}(m,E) \approx_d \# \{ Q \in \DQ_m^d : Q \cap E \neq \emptyset \} \approx_d N(l_m,E). \]
\end{lemma}
\begin{proof}
	Let $\mathcal{E} = \{ Q \in \DQ_m^d : Q \cap E \neq \emptyset \}$. Then $N(l_m,E) \leq N_{\DQ}(m,E) \leq \#(E)$. Conversely, let $\{ Q_k \}$ be a minimal cover of $E$ by cubes. Then each cube $Q_k$ intersects at most $3^d$ cubes in $\DQ_k^d$, so $\#(\mathcal{E}) \leq 3^d \cdot N(l_m,E) \leq 3^d \cdot N_{\DQ}(m,E)$.
\end{proof}

Thus it is natural to ask whether it is true that for any set $E$,
%
\begin{equation} \label{definingSequence}
	\begin{aligned}
		\lowminkdim(E) &= \liminf_{k \to \infty} \frac{\log[N_{\DQ}(k,E)]}{\log[1/l_k]}\\
		\text{and}\\
		\upminkdim(E) &= \limsup_{k \to \infty} \frac{\log[N_{\DQ}(k,E)]}{\log[1/l_k]}.
	\end{aligned}
\end{equation}
%
The answer depends on the choice of $\{ N_k \}$. In particular, we find that a sufficient condition is that
%
\begin{equation} \label{definingsequencegrowthrate}
	N_{k+1} \lesssim_\varepsilon (N_1 \dots N_k)^\varepsilon \quad \text{for any $\varepsilon > 0$}.
\end{equation}
%
We will see that this condition allows us to work dyadically in many scenarios when it comes to fractal dimension.

%Subsets of $\Sigma^d$ can also be assigned a Minkowski dimension. We define
%
%\[ \lowminkdim(E) = \liminf_{k \to \infty} \frac{\log(\#(\sigma_k^d(E)))}{\log(1/l_k)}\quad\text{and}\quad\upminkdim(E) = \limsup_{k \to \infty} \frac{\log(\#(\sigma_k^d(E)))}{\log(1/l_k)}. \]
%
%This makes sense, because $\Sigma^d$ only really has `balls' of radius $\{ l_k \}$, for each $k$, and \emph{any} cover of $E$ by balls of radius $l_k$ contains $\sigma_k^d(E)$. In order 
%we have $N(E,l_k) = \# (\Sigma_k^d(E))$, since \emph{any} cover of $E$ by balls of radius $l_k$

\begin{lemma} \label{definingsequenceminkowski}
	If \eqref{definingsequencegrowthrate} holds, then \eqref{definingSequence} holds.
\end{lemma}
\begin{proof}
	Fix a length $l$, and find $k$ with $l_{k+1} \leq l \leq l_k$. Applying Lemma \ref{comparableCovers} shows
	%
	\[ N(l,E) \leq N(l_{k+1},E) \lesssim_d N_{\DQ}(k+1,E) \]
	%
	and
	%
	\[ N(l,E) \geq N(l_k,E) \gtrsim_d N_{\DQ}(k,E). \]
	%
	Thus
	%
	\[ \frac{\log[N(l,E)]}{\log[1/l]} \leq \left[ \frac{\log(1/l_{k+1})}{\log(1/l_k)} \right] \frac{\log[N_{\DQ}(k+1,E)]}{\log[1/l_{k+1}]} + O_d(1/k) \]
	%
	and
	%
	\[ \frac{\log[N(l,E)]}{\log[1/l]} \geq \left[ \frac{\log(1/l_k)}{\log(1/l_{k+1})} \right] \frac{\log[N_{\DQ}(k,E)]}{\log[1/l_k]} + O_d(1/k). \]
	%
	Thus, provided that
	%
	\begin{equation} \label{equivalenceofscales}
		\frac{\log(1/l_{k+1})}{\log(1/l_k)} \to 1,
	\end{equation}
	%
	the conclusion of the theorem is true. But \eqref{equivalenceofscales} is equivalent to the condition that
	%
	\[ \frac{\log(N_{k+1})}{\log(N_1) + \dots + \log(N_k)} \to 0, \]
	%
	and this is equivalent to \eqref{definingsequencegrowthrate}.
\end{proof}

Any constant branching factor satisfies \ref{definingsequencegrowthrate} for the Minkowski dimension. In particular, we can work fairly freely with the classical dyadic cubes without any problems occuring. But more importantly for our work, we can let the sequence $\{ N_k \}$ increase rapidly.

\begin{lemma} \label{rapidBranching}
	If $N_k = 2^{\lfloor 2^{k \psi(k)} \rfloor}$, where $\psi(k)$ is any decreasing sequence of positive numbers tending to zero, such that $\psi(k) \gtrsim \log(k)/k$, then \eqref{definingsequencegrowthrate} holds.
\end{lemma}
\begin{proof}
	We note that $\log(N_k) = 2^{k \psi(k)} + O(1)$. Thus
	%
	\begin{align*}
		\frac{\log(N_{k+1})}{\log(N_1) + \dots + \log(N_k)} &= \frac{2^{(k+1) \psi(k+1)} + O(1)}{2^{\psi(1)} + 2^{2 \psi(2)} + \dots + 2^{k \psi(k)} + O(k)}\\
		&\lesssim \frac{2^{(k+1) \psi(k+1)}}{2^{\psi(k)} + 2^{2 \psi(k)} + \dots + 2^{k \psi(k)}}\\
		&\lesssim \frac{2^{(k+1) \psi(k+1)}}{2^{(k+1) \psi(k)}} ( 2^{\psi(k)} - 1 )\\
		&\leq (2^{\psi(k)} - 1) \to 0.
	\end{align*}
	%
	This is equivalent to the fact that $N_{k+1} \lesssim_\varepsilon (N_1 \dots N_k)^\varepsilon$ for any $\varepsilon > 0$.
\end{proof}
%
We refer to any sequence $\{ l_k \}$ constructed by $\{ N_k \}$ satisfying the conditions of Lemma \ref{rapidBranching} as a \emph{subhyperdyadic} sequence. If a sequence is generated by a sequence $\{ N_k = 2^{\lfloor 2^{ck} \rfloor} \}$, for some fixed $c > 0$, the values $\{ l_k \}$ are referred to as \emph{hyperdyadic}. The next (counter) example shows that hyperdyadic sequences are essentially the `boundary' for sequences that can be used to measure the Minkowski dimension.

\begin{example}
	We consider a multi-scale dyadic construction, utilizing the two families $\DQ^d$ and $\DR^d$. Fix $0 \leq c < 1$, and define $N_k = 2^{\lfloor 2^{ck} \rfloor}$, and $M_k = 2^{\lfloor c 2^{ck} \rfloor}$. Then $M_k \divides N_k$ for each $k$. We recursively define a nested family of sets $\{ E_k \}$, with each $E_k$ a $\DQ_k^d$ discretized set, and set $E = \bigcap E_k$. We define $E_0 = [0,1]$. Then, given $E_k$, we divide each sidelength $l_k$ dyadic interval in $E_k$ into $M_{k+1}$ intervals, and then keep the first sidelength $l_k/M_{k+1}$ interval from this set, which is formed from $N_{k+1}/M_{k+1}$ sidelength $l_{k+1}$ dyadic intervals. Thus $\#(\DQ_0(E_0)) = 1$, and
	%
	\[ \#(\DQ_{k+1}(E_{k+1})) = (N_{k+1}/M_{k+1}) \#(\DQ_k(E_k)) \]
	%
	so
	%
	\begin{equation} \label{equation12623} \#(\DQ_k(E_k)) = \frac{N_1 \dots N_k}{M_1 \dots M_k} \end{equation}
	%
	Noting that $\log(N_i) = 2^{ci} + O(1)$, and $\log(M_i) = c2^{ci} + O(1)$, we conclude that
	%
	\begin{align*}
		\frac{\log \#(\DQ_k(E_k))}{\log(1/l_k)} &= \frac{(1-c)(2^c + \dots + 2^{ck}) + O(k)}{(2^c + \dots + 2^{ck}) + O(k)} = 1-c + O\left(\frac{k}{2^{ck}} \right) \to 1-c.
	\end{align*}
	%
	On the other hand, if $r_{k+1} = l_k/M_{k+1}$, then for each $k$,
	%
	\[ \#(\DR_{k+1}^d(E_k)) = \#(\DQ_k(E_k)) = \frac{N_1 \dots N_k}{M_1 \dots M_k}, \]
	%
	and so
	%
	\begin{align*}
		\frac{\log \#(\DR_{k+1}^d(E_k))}{\log(1/r_{k+1})} &= \frac{(1-c)(2^c + \dots + 2^{ck}) + O(k)}{(2^c + \dots + 2^{ck}) + c2^{c(k+1)} + O(k)} \\
		&= \frac{\left( \frac{(1-c) 2^c}{2^c - 1} \right) 2^{ck} + O(k)}{ \left( \frac{2^c}{2^c - 1} + c2^c \right) 2^{ck} + O(k)}\\
		&= \frac{1-c}{1 - c + c2^c} + O \left( \frac{k}{2^{ck}} \right) \to \frac{1 - c}{1 - c + c2^c} < 1 - c.
	\end{align*}
	%
%
%	Fix $0 \leq c < 1$. Let $\{ M_k \}$ be a sequence of integers such that $M_k \divides N_k$ for each $k$. We recursively define a sequence of sets $\{ E_k \}$, with $E_k$ a union of length $l_k$ intervals
%
%	Construct a subset of $\RR$ as follows. Let $N_k = K_kM_k$, where $N_k$, $K_k$, and $M_k$ are parameters to be specified later. Define $E_0 = [0,1]$. Given $E_k$, define $E_{k+1}$ by dividing each sidelength $l_k$ dyadic interval in $E_k$ into $K_{k+1}$ intervals, and then keeping only the first interval. Then $\#(\DQ_{k+1}^d(E_{k+1})) = M_k \cdot \#(\DQ_k^d(E_k))$, and since $\#(\DQ_0^d(E_0)) = 1$, $\#(\DQ_k^d(E_k)) = M_1 \dots M_k$. Thus
%	\begin{align*}
%		\frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} &\sim \frac{\log \left[ \#(\DQ_k^d(E_k)) \right]}{\log(1/l_k)}\\
%		&= \frac{\log(M_1) + \dots + \log(M_k)}{\log(N_1) + \dots + \log(N_k)}\\
%		&= 1 - \frac{\log(K_1) + \dots + \log(K_k)}{\log(N_1) + \dots + \log(N_k)}.
%	\end{align*}
	%
%	On the other hand, if $r_k = l_k/K_{k+1}$, $N(r_k,E) \sim_d \#(S_k) = M_1 \dots M_k$, so
	%
%	\begin{align*}
%		\frac{\log \left[ N(r_k,E) \right]}{\log(1/r_k)} &\sim \frac{\log \left[ \#(\DQ_k^d(E_k)) \right]}{\log(1/r_k)}\\
%		&= \frac{\log(M_1) + \dots + \log(M_k)}{\log(N_1) + \dots + \log(N_k) + \log(K_{k+1})}\\
%		&= 1 - \frac{\log(K_1) + \dots + \log(K_{k+1})}{\log(N_1) + \dots + \log(N_k) + \log(K_{k+1})}.
%	\end{align*}
	%
%	Set $N_k = 2^{\lfloor 2^{ck} \rfloor}$, and $K_k = 2^{\lfloor c 2^{ck} \rfloor}$. Then
	%
%	\[ \log(K_1) + \dots + \log(K_k) = O(k) + c \sum_{i = 1}^k 2^{ck} = O(k) + c \frac{2^{c(k+1)} - 2^c}{2^c - 1} \]
	%
%	and
	%
%	\[ \log(N_1) + \dots + \log(N_k) = O(k) + \sum_{i = 1}^k 2^{ck} = O(k) + \frac{2^{c(k+1)} - 2^c}{2^c - 1}. \]
	%
%	Thus
	%
%	\[ \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} \to 1 - c \quad \text{and} \quad \frac{\log \left[ N(r_k,E) \right]}{\log(1/l_k)} \to \frac{1 - c}{1 - c + c2^c}. \]
	In particular,
	%
	\[ \lowminkdim(E) \neq \liminf_{k \to \infty} \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)}, \] % = \liminf_{k \to \infty} \frac{\log[N_{\DQ}(k,E)]}{\log(1/l_k)}, \]
	%
	so measurements at hyperdyadic scales fail to establish general results about the Minkowski dimension.

%	\[ \lim_{k \to \infty} \frac{\log(K_1) + \dots + \log(K_k)}{2^{c(k+1)} - 2^c} \neq \lim_{k \to \infty} \frac{\log(K_1) + \dots + \log(K_{k+1})}{2^{c(k+1)} - 2^c} \frac{1}{1 + \log(K_{k+1}) (2^c - 1)/(2^{c(k+1)} - 2^c)} \]

%	First, assume $N_k/N_{k-1} \in \mathbf{Z}$ for each $k$, and for convenience, set $N_0 = 1$. Define $S_0 = \{ 0 \}$, and then given $S_k$, recursively define
	%
%	\[ S_{k+1} = \{ (j,1), \dots, (j,N_{k+1}/N_k) : j \in S_k \} \]
	%
%	We then set $E = \pi(\lim S_k)$. If we let $E_k = \bigcup \{ Q_j : j \in S_k \}$, then $E_{k+1}$ can be constructed by dividing each sidelength $l_k$ dyadic interval in $E_k$ into $N_{k+1}$ intervals, and selecting the initial $N_{k+1}/N_k$ intervals, which have total length $1/(N_1 \dots N_k^2)$. Then $\#(S_{k+1}) = (N_{k+1}/N_k) \#(S_k)$, and since $\#(S_0) = 1$, $\#(S_k) = N_k$. Thus
	%
%	\[ \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} \sim_d \frac{\log \left[ \# (S_k) \right]}{\log(1/l_k)} = \frac{\log(N_k)}{\log(N_1) + \dots + \log(N_k)}. \]
	%
%	On the other hand, if $r_k = 1/(N_1 \dots N_k^2) = l_k/N_k$, then $N(l,E) = \#(S_k) = N_k$, so
	%
%	\[ \frac{\log \left[ N(r_k,E) \right]}{\log(1/r_k)} \sim_d \frac{\log \left[ \#(S_k) \right]}{\log(1/r_k)} = \frac{\log(N_k)}{\log(N_1) + \dots + 2\log(N_k)}. \]
%	In any case to which Lemma \ref{definingsequenceminkowski} applies, both of these estimates converge to zero as $k \to \infty$, so that $E$ has Minkowski dimension zero. On the other hand, if $N_k = 2^{\lfloor \psi(k) 2^k \rfloor}$ where $\psi(k)$ is an increasing sequence tending to $\infty$, then
	%
%	\begin{align*}
%		\frac{2^{(k-1) \psi(k-1)}}{2^{\psi(1)} + 2^{2 \psi(2)} + \dots + 2^{(k-1) \psi(k-1)}} &\geq \frac{\left(2^{(k-1) \psi(k-1)} \right) \left( 2^{\psi(k-1)} - 1 \right)}{2^{k \psi(k-1)} - 2^{\psi(k-1)}} \sim 1.
%	\end{align*}
	%
%	Thus
	%
%	\[ \lim_{k \to \infty} \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} = 1. \]
	%
%	On the other hand,
	%
%	\[ \frac{\log \left[ N(r_k, E) \right]}{\log(1/r_k)} = \frac{\log(N_k)}{\log(N_1) + \dots + 2\log(N_k)} \leq 1/2. \]
	%
%	Thus we cannot possibly have
	%
%	\[ \lowminkdim(E) = \liminf_{k \to \infty} \frac{\log \left( N(l_k,E) \right)}{\log(1/l_k)}, \]
	%
	%
%	A simple calculation shows this result even fails if $N_k = 2^{\lfloor 2^{ck} \rfloor}$, where $c > 1$.
\end{example}

%In particular, we can define the Minkowski dimensions of $E \subset \Sigma$ as
%
%\[ \lowminkdim(E) = \liminf_{k \to \infty} \frac{\log(\#(\Sigma_k^d(E)))}{\log(1/l_k)}\quad\text{and}\quad\upminkdim(E) = \limsup_{k \to \infty} \frac{\log(\#(\Sigma_k^d(E)))}{\log(1/l_k)}. \]
%
%Similarily, the Hausdorff measures $H^s$ are obtained by setting
%
% TODO: Fix this
%\[ H^s(E) = \left\{ \sum_m l_{k_m} : Q_m \in \Sigma_{k_m}^d\ \text{for each $k$}, \text{For any} \right\} \]
%
%and define the Hausdorff dimension correspondingly. A natural question is whether $\dim(\pi(E)) = \dim(E)$ for the various fractal dimensions we consider in this thesis. This is addressed in the next section.

We now move on to calculating Hausdorff dimension dyadically. The natural quantity to consider is the measure defined for any $E$ as $H^s_{\DQ}(E) = \lim_{m \to \infty} H^s_{\DQ,m}(E)$, where
%
\[ H^s_{\DQ,m}(E) = \inf \left\{ \sum_k l(Q_k)^s : E \subset \bigcup_k^\infty Q_k,\ Q_k \in \bigcup_{i \geq m} \DQ_i^d\ \text{for each $k$} \right\}. \]
%
A similar argument to the standard Hausdorff measures shows there is a unique $s_0$ such that $H^s_{\DQ}(E) = \infty$ for $s < s_0$, and $H^s_{\DQ}(E) = 0$ for $s > s_0$. It is obvious that $H^s_{\DQ}(E) \geq H^s(E)$ for any set $E$, so we certainly have $s_0 \geq \hausdim(E)$. The next lemma guarantees that $s_0 = \hausdim(E)$, under the same conditions on the sequence $\{ N_k \}$ as found in Lemma \ref{definingsequenceminkowski}.

\begin{lemma} \label{lemma51464}
	If \eqref{definingsequencegrowthrate} holds, then for any $\varepsilon > 0$, $H^s_{\DQ}(E) \lesssim_{s,\varepsilon} H^{s-\varepsilon}(E)$.
\end{lemma}
\begin{proof}
	Fix $\varepsilon > 0$ and $m$. Let $E \subset \bigcup Q_k$, where $l(Q_k) \leq l_m$ for each $k$. Then for each $k$, we can find $i_k$ such that $l_{i_k+1} \leq l(Q_k) \leq l_{i_k}$. Then $Q_k$ is covered by $O_d(1)$ elements of $\DQ_{i_k}^d$, and
	%
	\begin{equation} \label{equation824} H^s_{\DQ,m}(E) \lesssim_d \sum l_{i_k}^s \leq \sum (l_{i_k}/l_{i_k+1})^s l(Q_k)^s \leq \sum \left( l_{i_k}/l_{i_{k+1}} \right)^s l_{i_k}^\varepsilon l(Q_k)^{s - \varepsilon}. \end{equation}
	%
	By assumption,
	%
	\begin{equation} \label{equation992352}
		l_{i_k+1} = \frac{1}{N_1 \dots N_{i_k} N_{i_k+1}} \gtrsim_{s,\varepsilon} (N_1 \dots N_{i_k})^{1+ \varepsilon/s} = l_{i_k}^{1 + \varepsilon/s}.
	\end{equation}
	%
	Putting \eqref{equation824} and \eqref{equation992352} together, we conclude that $H^s_{\DQ,m}(E) \lesssim_{d,s,\varepsilon} \sum l(Q_k)^{s-\varepsilon}$. Since $\{ Q_k \}$ was an arbitrary cover of $E$, we conclude $H^s_{\DQ,m}(E) \lesssim H^{s-\varepsilon}(E)$, and since $m$ was arbitrary, that $H^s_{\DQ}(E) \lesssim H^{s-\varepsilon}(E)$.
\end{proof}

Finally, we consider computing whether we can establish that a measure is a Frostman measure dyadically.

\begin{theorem} \label{easyCoverTheorem}
	If \eqref{definingsequencegrowthrate} holds, and if $\mu$ is a Borel measure such that $\mu(Q) \lesssim l(Q)^s$ for each $Q \in \DQ_k^d$, then $\mu$ is a Frostman measure of dimension $s - \varepsilon$ for each $\varepsilon > 0$.
\end{theorem}
\begin{proof}
	Given a cube $Q$, find $k$ such that $l_{k+1} \leq l(Q) \leq l_k$. Then $Q$ is covered by $O_d(1)$ cubes in $\DQ^d_k$, which shows
	%
	\[ \mu(Q) \lesssim_d l_k^s = [(l_k/l)^s l^\varepsilon ] l^{s - \varepsilon} \leq [l_k^{s + \varepsilon} / l_{k+1}^s] l^{s - \varepsilon} = \left[ \frac{N_{k+1}^s}{(N_1 \dots N_k)^\varepsilon} \right] l^{s-\varepsilon} \lesssim_\varepsilon l^{s-\varepsilon}. \qedhere \]
\end{proof}	

\begin{remark}
	The dyadic construction showing that Minkowski dimension cannot be measured only at hyperdyadic scales also shows that a bound on a measure $\mu$ on hyperdyadic cubes does not imply the correct bound at all scales. It is easy to show from \eqref{equation12623} that the canonical measure $\mu$ for this example satisfies $\mu(Q) \lesssim l(Q)^{1-c}$ for all $Q \in \DQ_k(E_k)$, yet we know that for the set constructed in that example,
	%
	\[ \hausdim(E) \leq \lowminkdim(E) < 1 - c. \]
	%
	Frostman's lemma implies we cannot possibly have $\mu(Q) \lesssim_\varepsilon l(Q)^{1-c-\varepsilon}$ for all $\varepsilon > 0$ and \emph{all} cubes $Q$.
\end{remark}

Let's recognize the utility of this approach from the perspective of a dyadic construction. Suppose we have a sequence of nested sets $\{ E_k \}$, where $E_k$ is a $\DQ_k$ discretized subset of $[0,1]^d$, and for each $Q_0 \in \DQ_k(E_k)$, there is at least one cube $Q \in \DQ_{k+1}(E_{k+1})$ with $Q^* = Q_0$. Then we can set $E = \bigcap E_k$ as a `limit' of the discretizations $E_k$. We can associate with this construction a finite measure $\mu$. It is defined by setting $f([0,1]^d) = 1$, and setting, for each $Q \in \DQ_{k+1}(E_{k+1})$,
%
\[ f(Q) = \frac{f(Q^*)}{\# \{ Q' \in \DQ_{k+1}(E_{k+1}) : (Q')^* = Q^* \}}. \]
%
The mass distribution principle shows that there exists a Borel measure $\mu$, which we refer to as the \emph{canonical measure} associated with this construction. For this measure, it is often easy to show from a combinatorial argument that $f(Q) \lesssim l(Q)^s$ if $Q \in \DQ^d$, which leads to bounds on the measure $\mu$. This makes Theorem \ref{easyCoverTheorem} useful.

%Our final method for interpolating requires extra knowledge of the dissection process, but enables us to choose the $l_k$ arbitrarily rapidly. The idea behind this is that there is an additional sequence of lengths $r_k$ with $l_k \leq r_k \leq l_{k-1}$. The difference between $r_k$ and $l_{k-1}$ is allowed to be arbitrary, but the decay rate between $l_k$ and $r_k$ is of polynomial-type, which enables us to use the covering methods of the previous section. In addition, we rely on a `uniform mass bound' between $r_k$ and $l_k$ to cover the remaining classes of intervals. Because we can take $r_k$ arbitrarily large relative to $l_k$, this renders any constants that occur in the construction to become immediately negligible. For two quantities $A$ and $B$, we will let $A \precsim_k B$ stand for an inequality with a hidden constant depending only on parameters with index smaller than $k$, i.e. $A \leq C(l_1, \dots, l_k, r_1,\dots,r_k) B$ for some constant $C(l_1, \dots, l_k, r_1, \dots, r_k)$ depending only on parameters with indices up to $k$.

\section{Beyond Hyperdyadics}

If we are to use a faster increasing sequence of branching factors than the last section guarantees, we therefore must exploit some extra property of our construction, which is not always present in general sets. Here, we rely on a \emph{uniform mass distribution} between scales. Given the uniformity assumption, the lengths can decrease as fast as desired. We utilize a multi-scale set of dyadic cubes.

\begin{lemma} \label{uniformMassFrostman}
	Let $\mu$ be a measure supported on a set $E$. Suppose that
    %
    \begin{enumerate}
    	\item \label{discreteBound} For any $Q \in \DQ_k^d$, $\mu(Q) \lesssim l_k^s$.
    	\item \label{controlledScale} For each $Q \in \DR_k^d$, $\#[\DQ_k^d(E(l_k) \cap Q)] \lesssim 1$.
    	\item \label{uniformDist} For any $Q \in \DR_{k+1}^d$ with parent cube $Q^* \in \DQ_k^d$, $\mu(Q) \lesssim (r_{k+1}/l_k)^d \mu(Q^*)$.
    \end{enumerate}
	%
	Then $\mu$ is a Frostman measure of dimension $s$.
\end{lemma}
\begin{proof}
	We establish the general bound $\mu(Q) \lesssim l(Q)^s$ for all cubes $Q$ by separating into two different cases:
	%
	\begin{itemize}
		\item Suppose there is $k$ with $r_{k+1} \leq l(Q) \leq l_k$. Then $\#(\DR_{k+1}^d(Q(r_{k+1}))) \lesssim (l/r_{k+1})^d$. Properties \ref{discreteBound} and \ref{uniformDist} imply each of these cubes has measure at most $O( (r_{k+1}/l_k)^d l_k^s)$, so we obtain that
	    %
    	\[ \mu(Q) \lesssim (l/r_{k+1})^d (r_{k+1}/l_k)^d l_k^s = l^d / l_k^{d-s} \lesssim l^s. \]

    \item Suppose there exists $k$ with $l_k \leq l \leq r_k$. Then $\#[\DR_k^d(Q(r_k))] \lesssim 1$. Combining this with Property \ref{uniformDist} gives $\#[\DQ_k^d(Q(r_k) \cap E(l_k))] \lesssim 1$. This and Property \ref{discreteBound} then shows
    %
    \[ \mu(Q) \lesssim l_k^s \leq l^s. \]
	\end{itemize}
	%
	This addresses all cases, so $\mu$ is a Frostman measure of dimension $s$.
\end{proof}

TODO: ADDRESS OTHER FRACTIONAL DIMENSION CASES?

%\begin{remark}
%    The condition $\mu_\beta(J) \lesssim_{N-1} (r_N/l_N) \mu_\beta(I)$ essentially means that the probability mass on a length $l_N$ interval $I$ is uniformly distributed over the length $r_N$ intervals it contains. This is what enables us to remove the discussion of the growth of the sequence $\beta$ over time from discussion.
%\end{remark}

%Since the construction is obtained as a limit of intervals, it is often possible to construct such a $\mu$ by the {\it mass distribution principle}. That is, we let $\mu$ denote the weak limit of the probability masses $\mu_n$, where $\mu_0$ is a uniform distribution over $\mu_0$, and $\mu_{n+1}$ is obtained from $\mu_n$ by distributing the mass $\mu_n(I)$ of each length $l_n$ interval $I$ contained in $X_n$ over the portion of $I$ that remains in $X_{n+1}$. The cumulative distribution functions of the $\mu_n$ uniformly converge, hence the $\mu_n$ converge weakly to some $\mu$, which satisfy $\mu(I) = \mu_n(I)$ for each interval $I$ as above. Because of this discreteness, it is most easy to establish a bound $\mu(I) \lesssim l_n^\alpha$ when $I \subset X_n$ is a length $l_n$ interval. Since any interval $I$ of length $l_n$ is contained within at least two such intervals (or is contained in other length $l_n$ intervals that $\mu$ assigns no mass to), we have the general bound $\mu(I) \lesssim l_n^\alpha$ for all intervals $I$ of length $l_n$. Hausdorff dimension is a local property of a set\footnote{If we define $\dim_{\mathbf{H}}(x) = \lim_{r \downarrow 0} \dim_{\mathbf{H}}(B_r(x) \cap X)$ then $\dim_{\mathbf{H}}(X) = \sup_{x \in X} \dim_{\mathbf{H}}(x)$.}, so it is natural to expect that we can obtain a general bound $\mu(I) \lesssim_\alpha|I|^\alpha$ given that one has established precisely the same estimate, but restricted to intervals $I$ with $|I| = l_N$. This section concerns itself with ways that we can establish this general bound, and thus prove that $\dim_{\mathbf{H}}(X) \geq \alpha$.

%\section{BLAH}

%The collection $\DQ^d$ forms a \emph{tree} under the partial ordering induced by inclusion, with a branching factor of $H$. We let $\DB^d$ denote the set of all branches of the tree $\DQ^d$. For each branch $\mathfrak{b} = \{ Q_k : k \geq 0 \}$, the set $\bigcap_{k \geq 0} Q_k$ contains a unique point, which induces a function $\pi: \DB^d \to \RR^d$. This function is obviously surjective, but unfortunately not injective. Nonetheless, for each $x \in \RR^d$, $\pi^{-1}(x)$ contains $O_d(1)$ points. This means that from the point of view of geometric measure theory, the spaces $\DB^d$ and $\RR^d$ are isomorphic\footnote{Formally, we can define a topology on $\DB^d$ as a subset of $\prod_{k \geq 0} \DQ_k^d$, and $\pi$ is continuous with respect to this topology. We can also define the Hausdorff measures $H^s$ on $\DB^d$ as limits of $H^s_m$, where
%
%\[ H^s_m(E) = \inf \left\{ \sum_{i = 1}^\infty l(Q_i)^s : Q_i \in \DQ_{k_i}^d, k_i \geq m, E \subset \bigcup \{ \mathfrak{b} \in \DB^d : \mathfrak{b}_k = Q \} \right\} \]
%
%Then for each value $s > 0$ the map $\pi$ is an isomorphism of $(\DB^d, H^s)$ and $(\RR^d, H^s)$.}. In particular, given any configuration $\C$ on $\RR^d$, we can define a configuration $\pi^{-1}(\C)$ on $\DB^d$ as
%
%\[ \pi^{-1}(\C) = \{ (\mathfrak{b_1}, \dots, \mathfrak{b}_n) : (\pi(\mathfrak{b_1}), \dots, \pi(\mathfrak{b_n})) \in \C \}. \]
%
%If we can find an $s$ dimensional set $E \subset \DB^d$ avoiding $\pi^{-1}(\C)$, then $\pi(E)$ avoids $\C$ and is $s$ dimensinoal. Conversely, if $E \subset \RR^d$ avoids $\C$ and is $s$ dimensional, then $\pi^{-1}(E)$ avoids $\pi^{-1}(\C)$ and is $s$ dimensional.

%The Dyadic model is useful, but if the lengths decrease too fast, the model fails to reflect the geometry of $\RR^n$ at all scales.

\begin{comment}

\section{Extras: Hyperdyadic Covers}

Nonetheless, it will be useful for us to know that we can `decompose' a set with a prescribed Hausdorff dimension hyperdyadically. We say a sequence of sets $\{ E_k \}$ is a \emph{strong cover} of a set $E$ if $E \subset \limsup E_k$, or equivalently, if every $x \in E$ lies in infinitely many of the sets $E_k$. In this section, we inclusively treat hyperdyadic cubes, i.e. we assume $l_k = 2^{-\lfloor (1 + \varepsilon)^k \rfloor}$ for some fixed $0 < \varepsilon \leq 1$.

%Fix two parameters $\delta > 0$ and $\varepsilon > 0$. Given two numbers $A = A_{\delta \varepsilon}$ and $B = B_{\delta \varepsilon}$, we say $A \lessapprox B$ if there exists constants $C_\varepsilon$, and $C$ such that $A \leq C_\varepsilon \delta^{-C\varepsilon} B$. We say $A \approx B$ if $A \lessapprox B$ and $B \lessapprox A$. We say a set $E$ is \emph{$\delta$ discretized} if it is a union of dyadic cubes with sidelength $\approx \delta$. We say a set $E$ is a \emph{$(\delta,\alpha)$ set} if it is $\delta$ discretized, and for any dyadic cube $I$ with $\delta \leq l(I) \leq 1$, $|E \cap I| \lessapprox \delta^{d-\alpha} l(I)^\alpha$. Thus $E$ is \emph{roughly} a $\delta$ thickening of an $\alpha$ dimensional set. A set $E$ is \emph{strongly covered} by a family of sets $\{ U_i \}$ if $E \subset \limsup_{i \to \infty} U_i$. We consider a fixed hyperdyadic sequence $l_k = 2^{- \lfloor (1 + \varepsilon)^k \rfloor}$.

%\begin{lemma}
%	If $C$ is sufficiently large, and for each $\varepsilon$, there is a $(\delta, \alpha - C \varepsilon)$ set $X_\delta$ for each hyperdyadic $\delta$ such that the $X_\delta$ strongly cover $X$, then $\dim(X) \leq \alpha$.
%\end{lemma}
%\begin{proof}
%	Let $X_\delta = \bigcup I_i$, where $\{ I_i \}$ are disjoint dyadic cubes such that $l(I_i) \approx \delta$, and with $|X_\delta| \lessapprox \delta^{d-\alpha + C\varepsilon}$. Then
	%
%	\[ |X_\delta(\delta/2)| \leq \sum (l(I_i) + \delta/2)^d \lessapprox \sum l(I_i)^d = |X_\delta| \lessapprox \delta^{d - \alpha + C\varepsilon}. \]
	%
%	A volumetric argument then guarantees that $N(X_\delta,\delta) \lessapprox \delta^{-\alpha + C\varepsilon}$, and so
	%
%	\[ H^\alpha_\infty(X_\delta) \leq N(X_\delta,\delta) \delta^\alpha \lessapprox \delta^{C\varepsilon}. \]
	%
%	Thus there is $C_\varepsilon$ and $C_0$ such that $H^\alpha_\delta(X_\delta) \leq C_\varepsilon \delta^{(C - C_0) \varepsilon}$. Since $C_0$ does not depend on $C$, if we set $C > C_0$, then
	%
%	\[ \sum_{i = 1}^\infty H^\alpha_\infty(X_\delta) < \infty, \]
	%
%	and so $H^\alpha_\infty(X) = 0$.
%\end{proof}

\begin{theorem}
	Suppose $E \subset [0,1]^d$ is a set with $\dim(E) \leq s$. Fix $\varepsilon > 0$, and write $l_k = 2^{-\lfloor (1 + \varepsilon)^k \rfloor}$. Then there exists a strong cover of $E$ by sets $\{ E_k \}$, where $E_k$ is a union of $O((1 + \varepsilon)^{2k} l_k^{-s})$ cubes in $\DQ_k^d$.
\end{theorem}
\begin{proof}
	For each hyperdyadic number $l_k$, we can find a collection of cubes $\{ Q_{k,i} \}$ covering $E$ with $l(Q_{k,i}) \leq l_k$ for all $i$, and
	%
	\begin{equation} \label{HausdorffBound5}
		\sum_{i = 1}^\infty l(Q_{k,i})^{s + C\varepsilon} \lesssim 1.
	\end{equation}
	%
	For each $k$ and $i$, find $j_{k,i}$ such that $l_{j_{k,i} + 1} \leq l(Q_{k,i}) \leq l_{j_{k,i}}$. Note $l_{j_{k,i} + 1} \lesssim l_{j_{k,i}}^{1 + \varepsilon}$, so
	%
	\begin{align*}
		\sum_{i = 1}^\infty l_{j_{k,i}}^{s + (C + s)\varepsilon} &= \sum_{i = 1}^\infty l(Q_{k,i})^{s + (C + s) \varepsilon} (l_{j_{k,i}} / l(Q_{k,i}))^{s + (C + s) \varepsilon}\\
		&\lesssim \sum_{i = 1}^\infty l(Q_{k,i})^{s + (C + s)\varepsilon} l_{j_{k,i}}^{-s \varepsilon} \lesssim \sum_{i = 1}^\infty l(Q_{k,i})^{s + C \varepsilon} \lesssim 1.
	\end{align*}
	%
	Thus, replacing $C$ with $C + s$, and replacing $Q_{k,i}$ with the $O_d(1)$ cubes in $\DQ_{j_{k,i}}(Q_{k,i})$, we may assume without loss of generality that all cubes in the decomposition corresponding to \eqref{HausdorffBound5} are hyperdyadic.

	For $k_2 \geq k_1$, we let
	%
	\[ Y_{k_1,k_2} = \bigcup \{ Q_{k_1,i} : l(Q_{k_1,i}) = l_{k_2}. \} \]
	%
	Note that $Y_{k_1,k_2}$ is the union of $O((1/l_{k_2})^{s + C\varepsilon})$ cubes in $\DQ_{k_2}$. We let $Z_{k_1,k_2}$ be the collection of hyperdyadic cubes covering $Y_{k_1,k_2}$ which minimize
	%
	\[ \sum \left\{ l(Q)^s : Q \in Z_{k_1,k_2} \right\} \]
	%
	and such that $l(Q) \geq l_{k_2}$ for each $Q$. Then clearly
	%
	\[ \sum_{Q \in Z_{k_1,k_2}} l(Q)^s \lesssim l_{k_2}^{- C\varepsilon}. \]
	%
	In particular, this means $l(Q) \lesssim l_{k_2}^{-C\varepsilon/s}$ for each $Q \in Z_{k_1,k_2}$. Moreover, for each hyperdyadic $Q_0$ with $l(Q_0) \geq l_{k_2}$,
	%
	\[ \sum_{Q \subset Q_0} l(Q)^s \leq l(Q_0)^s. \]
	%
	Now we define $E_k = \bigcup \left\{ \bigcup_{k_1,k_2} Z_{k_1,k_2} \cap \DQ_k \right\}$. Since $E_k$ only contains cubes from $Z_{k_1,k_2}$ where $k_1 \leq k_2$, and $l_k \lesssim l_{k_2}^{-\varepsilon/\alpha}$ TODO: THERE IS SOMETHING WRONG HERE THIS DOESN'T IMPLY $\log(1/l_k)^2$?. But this means that there are only $O(\log(1/l_k)^2) = O((1 + \varepsilon)^{2k})$ such choices of $(k_1,k_2)$. But this means that
	%
	\[ |E_k| = \sum l(Q)^d = l_k^{d - s} \sum l(Q)^s \lesssim (1 + \varepsilon)^{2k} l_k^{d-s}, \]
	%
	which implies that $E_k$ is the union of at most $O((1 + \varepsilon)^{2k} l_k^{-s})$ cubes in $\DQ_k$.
\end{proof}

\end{comment}