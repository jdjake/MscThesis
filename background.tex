%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Background}
\label{ch:Background}

\section{Configuration Avoidance}

We consider an ambient set $\AAA$. It's \emph{$n$-point configuration space} is
%
\[ \Config^n(\AAA) = \{ (a_1, \dots, a_n) \in \AAA^n: a_i \neq a_j\ \text{if $i \neq j$} \}. \]
%
An \emph{$n$ point configuration}, or \emph{$n$ point pattern}, is a subset of $\Config^n(\AAA)$. More generally, we define the general \emph{configuration space} of $\AAA$ as $\Config(\AAA) = \bigcup_{n = 1}^\infty \Config^n(\AAA)$, and a \emph{pattern}, or \emph{configuration}, on $\AAA$ is a subset of $\Config(\AAA)$.

Our main focus in this thesis is the \emph{pattern avoidance problem}. For a fixed configuration $\C$ on $\AAA$, we say a set $X \subset \AAA$ \emph{avoids} $\C$ if $\Config(X)$ is disjoint from $\C$. The pattern avoidance problem asks to find sets $X$ of maximal size avoiding a fixed configuration $\C$. The set $\C$ often describes the presence of algebraic or geometric structure, and so we are trying to find large sets avoiding structure.

\begin{example}[Isoceles Triangle Configuration]
	Let
	%
	\[ \C = \left\{ (x_1, x_2, x_3) \in \Config^3(\RR^2) : |x_1-x_2| = |x_1-x_3| \right\}. \]
	%
	Then $\C$ is a 3-point configuration, and a set $X \subset \RR^2$ avoids $\C$ if and only if it does not contain all three vertices of an isoceles triangle. %Notice that $|x_1 - x_2| = |x_1 - x_3|$ holds if and only if $|x_1 - x_2|^2 = |x_1 - x_3|^2$, which is an algebraic equation in the coordinates of $x_1,x_2$, and $x_3$. Thus $\C$ is an algebraic hypersurface of degree two in $\RR^6$.
\end{example}

\begin{example}[Linear Independence Configuration]
	Let $V$ be a vector space over a field $K$. We set
	%
	\[ \C = \bigcup_{n = 1}^\infty \{ (x_1, \dots, x_n) \in \C^n(V): \text{for any}\ a_1, \dots, a_n \in K,\ a_1x_1 + \dots + a_nx_n \neq 0 \}. \]
	%
	A subset $X \subset V$ avoids $\C$ if and only if $X$ is a linearly independent subset of $X$. Note that if $V$ is infinite dimensional, then $\C$ cannot be replaced by a $n$ point configuration for any $n$; arbitrarily large tuples must be considered. We will be interested in the case where $K = \QQ$, and $V = \RR$. Our interest here is to find analytically large linearly independant subsets of $V$.
\end{example}

%\begin{example}[General Position Configuration]
%	Suppose we wish to find a subset $X$ of $\RR^d$ such that for each positive integer $k \leq d$, and for each collection of $k+1$ distinct points $x_1, \dots, x_{k+1} \in X$, the points do not lie in a $k-1$ dimensional hyperplane. For each $k \leq d$, set
	%
%	\[ \C^{k+1} = \{ (x_0, x_1, \dots, x_k) \in \Config^{k+1}(\RR^d): x_1-x_0, \dots, x_k - x_0\ \text{are linearly dependant} \}. \]
	%
%	If we define $\C = \bigcup_{k = 2}^d \C^k$, then a set $X$ avoids $\C$ precisely when all finite collection of distinct points in $X$ lie in general position. Notice that
	%
%	\[ \C^{k+1} = \bigcup \left\{ \text{span}(y_1, \dots, y_k) \times \{ y \} : y = (y_1, \dots, y_k) \in \Config^k(\RR^d) \right\} \cap \Config^{k+1}(\RR^d). \]
	%
%	so each $\C^{k+1}$ is essentially a union of $k$ dimensional hyperplanes.
%\end{example}

Even though our problem formulation assumes configurations are formed by distinct sets of points, one can still formulate avoidance problems involving repeated points by a simple trick.

\begin{example}[Sum Set Configuration]
	Let $G$ be an abelian group, and fix $Y \subset G$. Set
	%
	\[ \C^1 = \{ g \in \Config^1(G): g + g \in Y \} \quad \text{and} \quad \C^2 = \{ (g_1,g_2) \in \Config^2(G): g_1 + g_2 \in Y \}. \]
	%
	Then set $\C = \C^1 \cup \C^2$. A set $X \subset G$ avoids $\C$ if and only if $(X + X) \cap Y = \emptyset$.
\end{example}

Depending on the structure of the ambient space $\AAA$ and the configuration $\C$, there are various ways of measuring the size of sets $X \subset \AAA$ for the purpose of the pattern avoidance problem:
%
\begin{itemize}
	\item If $\AAA$ is finite, we wish to find a set $X$ with large cardinality.
	\item If $\{ \AAA_n \}$ is an increasing family of finite sets with $\AAA = \lim \AAA_n$, we wish to find a set $X$ such that $X \cap \AAA_n$ has large cardinality asymptotically in $n$.
	\item If $\AAA = \RR^d$, but $\C$ is a discrete configuration, then a satisfactory goal is to find a set $X$ with large Lebesgue measure avoiding $\C$.
\end{itemize}
%
In this thesis, inspired by results in these three settings, we establish methods for avoiding non-discrete configurations $\C$ in $\RR^d$. Here, Lebesgue measure completely fails to measure the size of pattern avoiding solutions, as the next theorem shows, under the often true assumption that $\C$ is \emph{translation invariant}, i.e. that if $(a_1, \dots, a_n) \in \C$ and $b \in \RR^d$, $(a_1 + b, \dots, a_n + b) \in \C$.

\begin{theorem}
	Let $\C$ be a $n$-point configuration on $\RR^d$. Suppose
	%
	\begin{enumerate}
		\item \label{translationinvariance} $\C$ is translation invariant.
		\item \label{nonDiscreteConfig} For any $\varepsilon > 0$, there is $(a_1, \dots, a_n) \in \C$ with $\diam \{ a_1, \dots, a_n \} \leq \varepsilon$.
	\end{enumerate}
	%
	Then no set with positive Lebesgue measure avoids $\C$.
\end{theorem}
\begin{proof}
	Let $X \subset \RR^d$ have positive Lebesgue measure. The Lebesgue density theorem shows that there exists a point $x \in X$ such that
	%
	\begin{equation} \label{densityApplication} \lim_{l(Q) \to 0} \frac{|X \cap Q|}{|Q|} = 1, \end{equation}
	%
	where $Q$ ranges over all cubes in $\RR^d$ with $x \in Q$, and $l(Q)$ denotes the sidelength of $Q$. Fix $\varepsilon > 0$, to be specified later, and choose $r$ small enough that $|X \cap Q| \geq (1 - \varepsilon) |Q|$ for any cube $Q$ with $x \in Q$ and $l(Q) \leq r$. Now let $Q_0$ denote a cube centered at $x$ with $l(Q_0) \leq r$. Applying Property \ref{nonDiscreteConfig}, we find $C = (a_1, \dots, a_n) \in \C$ such that
	%
	\begin{equation} \label{equation690346024} \diam \{ a_1, \dots, a_n \} \leq l(Q_0)/2. \end{equation}
	%
	For each $p \in Q_0$, let $C(p) = (a_1(p), \dots, a_n(p))$, where $a_i(p) = p + (a_i - a_1)$. Property \ref{translationinvariance} implies $C(p) \in \C$ for each $p \in \RR^d$. A union bound shows
	%
	\begin{equation} \label{equation548} \left| \{ p \in Q_0 : C(p) \not \in \C(X) \} \right| \leq \sum_{i = 1}^d \left| \{ p \in Q_0 : a_i(p) \not \in X \} \right|.
	\end{equation}
	%
	We have $a_i(p) \not \in X$ precisely when $p + (a_i - a_1) \not \in X$, so
	%
	\begin{equation} \label{equation1243462}
		|\{ p \in Q_0 : a_i(p) \not \in X \}| = |(Q_0 + (a_i - a_1)) \cap X^c|.
	\end{equation}
	%
	Note $Q_0 + (a_i - a_1)$ is a cube with the same sidelength as $Q_0$. Equation \eqref{equation690346024} implies $|a_i - a_1| \leq l(Q_0)/2$, so $x \in Q_0 + (a_i - a_1)$. Thus \eqref{densityApplication} shows
	%
	\begin{equation} \label{equation543} |Q_0 + (a_i - a_1)) \cap X^c| \leq \varepsilon |Q_0|. \end{equation}
	%
	Combining \eqref{equation548}, \eqref{equation1243462}, and \eqref{equation543}, we find
	%
	\[ \left| \{ p \in Q_0 : C(p) \not \in \C(X) \} \right| \leq \varepsilon d |Q_0|. \]
	%
	Provided $\varepsilon d < 1$, this means there is $p \in Q_0$ with $C(p) \in \C(X)$.
\end{proof}

Since no set of positive Lebesgue measure can avoid non-discrete configurations, we cannot use the Lebesgue measure to quantify the size of pattern avoiding sets. Fortunately, there is a quantity which can distinguish between the size of sets of measure zero. This is the \emph{fractional dimension} of a set.

There are many variants of fractional dimension. Here we choose to use the Minkowski dimension, the Hausdorff dimension, and the Fourier dimension. They assign the same dimension to any smooth manifold (though Fourier dimension may differ if the manifold has nonvanishing curvature), but vary over more singular sets. One major difference is that Minkowski dimension measures relative density at a single scale, whereas Hausdorff dimension measures relative density at countably many scales. The Fourier dimension is a refinement of the Hausdorff dimension which gives greater control on the set in the frequency domain, and therefore gives additional structural information on sets.









\section{Minkowski Dimension}

We begin by discussing the Minkowski dimension, which is the simplest to define. Given $l > 0$, and a bounded set $E \subset \RR^d$, we let $N(l,E)$ denote the \emph{covering number} of $E$, the minimum number of sidelength $l$ cubes required to cover $E$. We define the \emph{lower} and \emph{upper} Minkowski dimension as
%
\[ \lowminkdim(E) = \liminf_{l \to 0} \frac{\log(N(l,E))}{\log(1/l)} \quad\text{and}\quad \upminkdim(E) = \limsup_{l \to 0} \frac{\log(N(l,E))}{\log(1/l)}. \]
%
If $\upminkdim(E) = \lowminkdim(E)$, then we refer to this common quantity as the \emph{Minkowski dimension} of $E$, denoted $\minkdim(E)$. Thus $\lowminkdim(E) < s$ if there exists a sequence of lengths $\{ l_k \}$ converging to zero with $N(l_k,E) \leq (1/l_k)^s$, and $\upminkdim(E) < s$ if $N(l,E) \leq (1/l)^s$ for \emph{all} sufficiently small lengths $l$.

\section{Hausdorff Dimension}

For $E \subset \RR^d$ and $\delta > 0$, we define the \emph{Hausdorff content}
%
\[ H_\delta^s(E) = \inf \left\{ \sum_{k = 1}^\infty l(Q_k)^s : E \subset \bigcup_{k = 1}^\infty Q_k, l(Q_k) \leq \delta \right\}. \]
%
The \emph{$s$-dimensional Hausdorff measure} of $E$ is
%
\[ H^s(E) = \lim_{\delta \to 0} H_\delta^s(E). \]
%
It is easy to see $H^s$ is an exterior measure on $\RR^d$, and $H^s(E \cup F) = H^s(E) + H^s(F)$ if the Hausdorff distance $d(E,F)$ between $E$ and $F$ is positive. So $H^s$ is actually a metric exterior measure, and the Caratheodory extension theorem shows all Borel sets are measurable with respect to $H^s$.

\begin{lemma} \label{HausdorffBoundary}
	Consider $t < s$, and $E \subset \RR^d$.
	%
	\begin{enumerate}
		\item[(i)] If $H^t(E) < \infty$, then $H^s(E) = 0$.
		\item[(ii)] If $H^s(E) \neq 0$, then $H^t(E) = \infty$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	Suppose that $H^t(E) = A < \infty$. Then for any $\delta > 0$, there is a cover of $E$ by a collection of intervals $\{ Q_k \}$, such that $l(Q_k) \leq \delta$ for each $k$, and
	%
	\[ \sum l(Q_k)^t \leq A < \infty. \]
	%
	But then
	%
	\[ H^s_\delta(E) \leq \sum l(Q_k)^s \leq \sum l(Q_k)^{s-t} l(Q_k)^t \leq \delta^{s-t} A. \]
	%
	As $\delta \to 0$, we conclude $H^s(E) = 0$, proving \emph{(i)}. And \emph{(ii)} is just the contrapositive of (i), and therefore immediately follows.
\end{proof}

\begin{corollary} \label{corollaryhausdorffzero}
	If $s > d$, $H^s = 0$.
\end{corollary}
\begin{proof}
	The measure $H^d$ is just the Lebesgue measure on $\RR^d$, so
	%
	\[ H^d[-N,N]^d = (2N)^d. \]
	%
	If $s > d$, Lemma \ref{HausdorffBoundary} shows $H^s[-N,N]^d = 0$. By countable additivity, taking $N \to \infty$ shows $H^s(\RR^d) = 0$. Since $H^s$ is a positive measure, $H^s(E) = 0$ for all $E$.
\end{proof}

Given any Borel set $E$, Corollary \ref{corollaryhausdorffzero}, combined with Lemma \ref{HausdorffBoundary}, implies there is a unique value $s_0 \in [0,d]$ such that $H^s(E) = 0$ for $s > s_0$, and $H^s(E) = \infty$ for $0 \leq s < s_0$. We refer to $s_0$ as the \emph{Hausdorff dimension} of $E$, denoted $\hausdim(E)$.

\begin{theorem}
	For any bounded set $E$, $\hausdim(E) \leq \lowminkdim(E) \leq \upminkdim(E)$.
\end{theorem}
\begin{proof}
	Given $l > 0$, we have a simple bound $H^s_l(E) \leq N(l,E) \cdot l^s$. If $\lowminkdim(E) < s$, then there exists a sequence $\{ l_k \}$ with $l_k \to 0$, and $N(l_k,E) \leq (1/l_k)^s$. Thus we conclude that
	%
	\[ H^s(E) = \lim_{k \to \infty} H^s_{l_k}(E) \leq \lim_{k \to \infty} N(l_k,E) \cdot l_k^s \leq 1, \]
	%
	Thus $\hausdim(E) \leq s$. Taking infima over all $s$, we find $\hausdim(E) \leq \lowminkdim(E)$.
\end{proof}

\begin{remark}
	If $\hausdim(E) < d$, then $|E| = H^d(E) = 0$. Thus any set with fractional dimension less than $d$ must have measure zero. Thus we can use the dimension as a way of distinguishing between sets of measure zero, which is precisely what we need to study configuration avoidance problem for non-discrete configurations.
\end{remark}

The fact that Hausdorff dimension is defined over simultaneously multiple scales makes it more stable under analytical operations. In particular,
%
\[ \hausdim \left\{ \bigcup E_k \right\} = \sup \left\{ \hausdim(E_k). \right\} \]
%
This need not be true for the Minkowski dimension; a single point has Minkowski dimension zero, but the rational numbers, which are a countable union of points, have Minkowski dimension one. An easy way to make Minkowski dimension countably stable is to define the \emph{modified Minkowski dimensions}
%
\begin{align*}
	\lmbdim(E) &= \inf \left\{ s : E \subset \bigcup_{i = 1}^\infty E_i, \lowminkdim(E_i) \leq s \right\}
\end{align*}
%
and
%
\begin{align*}
	\umbdim(E) &= \inf \left\{ s : E \subset \bigcup_{i = 1}^\infty E_i, \upminkdim(E_i) \leq s \right\}.
\end{align*}
%
This notion of dimension, in a disguised form, appears in Chapter BLAH.







\section{Dyadic Scales}

It is now useful to introduce the dyadic notation we utilize throughout this thesis. At the cost of losing topological perspective about $\RR^d$, applying dyadic techniques often allows us to elegantly discretize certain problems in Euclidean space. We introduce fractional dimension through a dyadic framework, and all our constructions will be done dyadically. This section introduces some notation we will use throughout the remainder of the thesis. We fix a sequence of positive integers $\{ N_k : k \geq 1 \}$, which we view as parameters to be modified in each argument.
%
\begin{itemize}
	\item For each $k \geq 0$, we define 
	%
	\[ \DQ_k^d = \left\{ \prod_{k = 1}^d \left[ \frac{m_k}{N_1 \dots N_k}, \frac{m_k + 1}{N_1 \dots N_k} \right) : m \in \ZZ^d \right\}. \]
	%
	These are the \emph{dyadic cubes of generation $k$}. We let $\DQ^d = \bigcup_{k \geq 0} \DQ_k^d$. Note that any two cubes $\DQ^d$ are either nested within one another, or disjoint from one another.

	\item We set
	%
	\[ l_k = \frac{1}{N_1 \dots N_k}. \]
	%
	Then $l_k$ is the sidelength of the cubes in $\DQ_k^d$.

	\item Given $Q \in \DQ_{k+1}^d$, we let $Q^* \in \DQ_k^d$ denote the \emph{parent cube} of $Q$, i.e. the unique dyadic cube of generation $k$ such that $Q \subset Q^*$.

	\item We say a set $E \subset \RR^d$ is \emph{$\DQ_k^d$ discretized} if it is a union of cubes in $\DQ_k^d$. In this case, we let
	%
	\[ \DQ_k(E) = \{ Q \in \DQ_k^d: Q \subset E \} \]
	%
	denote the family of cubes whose union is $E$.
\end{itemize}
%
It is most common to set $N_k = 2$ for all $k$, which gives the standard families of dyadic cubes. But in our methods, it is necessary to allow more general sequences $\{ N_k \}$ which are not necessarily bounded.

%The most common class of dyadic cubes in analysis is obtained by setting $N_k = 2$ for each $k$. We reserve a special notation for this class of dyadic cubes; the class of all such cubes is denoted by $\DD^d$, and the generation $k$ cubes by $\DD^d_k$. The fact that the sequence $\{ N_k \}$ is constant makes these cubes more easy to analyze. But in our methods, it is necessary for the sequence $\{ N_k \}$ to become unbounded as $k \to \infty$. This is why we have to introduce the more general family of dyadic cubes introduced above.

Sometimes, we need to rely on certain `intermediary' cubes that lie between the scales $\DQ_k^d$ and $\DQ_{k+1}^d$. In this case, we consider a supplementary sequence $\{ M_k : k \geq 1 \}$ with $M_k \divides N_k$ for each $k$.
%
\begin{itemize}
	\item For $k \geq 1$, we define
	%
	\[ \DR_k^d = \left\{ \prod_{k = 1}^d \left[ \frac{m_k}{N_1 \dots N_{k-1} M_k} , \frac{m_k + 1}{N_1 \dots N_{k-1} M_k} \right) : m \in \mathbf{Z}^d \right\}. \]

	\item We set
	%
	\[ r_k = \frac{1}{N_1 \dots N_{k-1} M_k} \]
	%
	to be the sidelength of a cube in $\DR_k^d$.

	\item For a set $E \subset \RR^d$, the notions of being $\DR_k^d$ discretized, and the collection of cubes $\DR_k^d(E)$, are defined as should be expected.
\end{itemize}
%
Thus the cubes in $\DR_k^d$ are coarser than those in $\DQ_k^d$, but finer than those in $\DQ_{k-1}^d$.

%For the purposes of discretization, and to simplify notation, it is very useful to identify those cubes in $\DQ_k^d$ which are subsets of $[0,1]^d$ with the set
%
%\[ \Sigma_k^d = [N_1]^d \times \dots \times [N_k]^d. \]
%
%Given $j \in \Sigma_m^d$, we let $Q_j \in \DQ_m^d$ denote the cube with left-hand corner $a = \sum_{k = 1}^m j_kl_k$. Thus subcubes of a cube corresponding to an index $j \in \Sigma_k^d$ correspond to indices obtained by appending additional integers onto $j$. In the case of intermediary scales, we abuse notation, writing $[N_k] = [K_k] \times [M_k]$, we have
%
%\[ \Sigma_k^d = \big([K_1] \times [M_1] \big)^d \times \dots \times \big([K_k] \times [M_k] \big)^d, \]
%
%where $n \in [N_k]$ is equal to $(k,m) \in [K_k] \times [M_k]$, where $k M_k + m = n$.

%One very useful property of the cubes in $\DQ^d$ is that cubes are either nested within one another, or \emph{almost disjoint} from one another, in the sense that only their boundaries intersect. Thus we can think of $\DQ^d$ as a forest under the partial ordering of inclusion, with the roots corresponding to the elements of $\DQ_0^d$. Each cube $Q \in \DQ^d_k$ has $N_{k+1}^d$ children. For each cube $Q \in \DQ_{k+1}^d$, we will let $Q^* \in \DQ_k^d$ denote it's parent, i.e. the unique cube in $\DQ_k^d$ with $Q \subset Q^*$. Similarily, given an index $I = (I_0, \dots, I_{k+1}) \in \Sigma_{k+1}$, we let $I^* = (I_0, \dots, I_k) \in \Sigma_k$, so that $Q_I \subset Q_{I^*}$.

%We often construct configuration avoiding sets as limits of dyadic discretizations. It is most convenient to describe this construction in terms of a sequence of sets $\{ S_k \}$ with $S_k \subset \Sigma_k^d$ for each $k$, and $(S_{k+1})^* \subset S_k$ for each $k$. We refer to such a sequence as a \emph{constructing sequence}. We can define $E_k = \bigcup \{ Q_j : j \in S_k \}$. Then $E_{k+1} \subset E_k$ for each $k$, and we can form a set $\bigcap E_k$, which is the final, non discretized limit of the sequence of discretizations.

%We can also give the spaces $\Sigma_k^d$ and $\Sigma^d$ a metric space structure, by defining, for $I \neq J$, $d(I,J) = l_k$, where $k$ is the smallest index such that $I_k \neq J_k$. Aside from the fact that some points in $\RR^d$ are duplicated in $\Sigma^d$, the main difference between the two spaces is that the balls in $\Sigma^d$ are discretized to the scales $\{ l_k \}$. From the point of view of geometric measure theory, the first point is neglible, but we shall find that discretization does matter. The degree to which the geometry of $\Sigma^d$ models the geometry of $\RR^d$ from the perspective of geometric measure theory is a key topic in this thesis. We shall find that the rate at which the lengths $l_k$ tend to zero will be a key factor in this relationship.

\section{Frostman Measures}

%\begin{example}
%	Let $s = 0$. Then $H_\delta^0(E)$ is the number of $\delta$ balls it takes to cover $E$, which tends to $\infty$ as $\delta \to 0$ unless $E$ is finite, and in the finite case, $H_\delta^0(E) \to \# E$. Thus $H^0$ is just the counting measure.
%\end{example}

%\begin{example}
%	Let $s = d$. If $E$ has Lebesgue measure zero, then for any $\varepsilon > 0$, there exists a sequence of balls $\{ B(x_k,r_k) \}$ covering $E$ with
	%
%	\[ \sum_{k = 1}^\infty r_k^d < \varepsilon^d. \]
	%
%	Then we know $r_k < \varepsilon$, so $H^s_\varepsilon(E) < \varepsilon^d$. Letting $\varepsilon \to 0$, we conclude $H^d(E) = 0$. Thus $H^d$ is absolutely continuous with respect to the Lebesgue measure. The measure $H^d$ is translation invariant, so $H^d$ is actually a constant multiple of the Lebesgue measure.
%\end{example}

It is often easy to upper bound Hausdorff dimension, but non-trivial to \emph{lower bound} the Hausdorff dimension of a given set. A key technique to finding a lower bound is \emph{Frostman's lemma}, which says that a set has large Hausdorff dimension if and only if it supports a probability measure which obeys a certain decay law on small sets. We say a Borel measure $\mu$ is a \emph{Frostman measure} of dimension $s$ if it is non-zero, compactly supported, and for any cube $Q$, $\mu(Q) \lesssim l(Q)^s$. The proof of Frostman's lemma will utilize a technique often useful, known as the \emph{mass distribution principle}.

\begin{lemma}[Mass Distribution Principle] \label{massdistributionprinciplelem}
	Let $\mu: \DQ^d \to [0,\infty)$ be a function such that for any $k$, and for any $Q_0 \in \DQ^d_k$,
	%
	\begin{equation} \label{equation73234091} \sum \left\{ \mu(Q) : Q \in \DQ^d_{k+1}, Q^* = Q_0 \right\} = \mu(Q_0). \end{equation}
	%
	Then $\mu$ extends uniquely to a regular Borel measure on $\RR^d$.
\end{lemma}
\begin{proof}
	We begin by defining a sequence of regular Borel measures $\{ \mu_k \}$ by setting, for each $f \in C_c(\RR^d)$,
	%
	\[ \int f d\mu_k = \sum_{Q \in \DQ_k^d} \frac{\mu(Q)}{|Q|} \int_Q f(x)\; dx. \]
	%
	Similarily, for each regular Borel measure $\nu$, and for each $k$, define a a regular Borel measure $E_k(\nu)$ by the formula
	%
	\[ \int f(x) dE_k(\nu) = \sum_{Q \in \DQ_k^d} \frac{\nu(Q)}{|Q|} \int_Q f(x)\; dx. \]
	%
	Equation \eqref{equation73234091} says that for each $i \leq j$, $E_i(\mu_j) = \mu_i$.

	If $\nu_i \to \nu$ weakly, then $\nu_i(Q) \to \nu(Q)$ for each fixed $Q \in \DQ_k^d$. If $f \in C_c(\RR^d)$, then the support of $f$ intersects only finitely many cubes in $\DQ_k^d$, and this implies
	%
	\[ \int f(x) dE_k(\nu_i) = \sum \nu_i(Q) \int_Q f\; dx \to \sum \nu(Q) \int_Q f\; dx = \int f dE_k(\nu). \]
	%
	Thus the operators $\{ E_k \}$ are continuous with respect to the weak topology.

	Now fix an interval $Q \in \DQ_0^d$. The measures $\{ \mu_k|_Q \}$, restricted to $Q$, all have total mass $\mu(Q) < \infty$. Thus the Banach-Alaoglu theorem implies that is a subsequence $\mu_{k_i}|_Q$ converging weakly on $Q$ to some measure $\mu_Q$. By continuity,
	%
	\[ E_j(\mu_Q) = \lim_{i \to \infty} E_j(\mu_{k_i}|_Q) = \lim_{i \to \infty} E_j(\mu_{k_i})|_Q = \mu_j|_Q. \]
	%
	This means precisely that $\mu_Q$ is the extension of $\mu$ to a Borel measure on $Q$. If we define, for any Borel set $E$,
	%
	\[ \mu(E) = \sum_{Q \in \DQ_0^d} \mu_Q (E \cap Q), \]
	%
	then this is a well defined extension of $\mu$ to a regular Borel measure. The uniqueness of the extension is guaranteed, because the intervals in $\DQ^d$ generate the entire Borel sigma algebra.
\end{proof}

%\begin{lemma}
%	let $\mu^+$ be a function from $\B$ to $[0,\infty)$ such that for any $I \in \B(1/M^k,\RR^d)$,
	%
%	\[ \sum \left\{ \mu^+(J) :J \in \B(1/M^{k+1},I) \right\} \leq \mu^+(I) \]
	%
%	Assume there exists $c > 0$ such that for all $k$,
	%
%	\[ \sum \left\{ \mu^+(I) : I \in \B(1/M^k,I) \right\} \geq c \]
	%
%	and
	%
%	\[ \sum \left\{ \mu^+(I) : I \in \B(1,I) \right\} < \infty \]	
	%
%	Then there exists a non-zero Borel measure $\mu$ such that $\mu(I) \leq \mu^+(I)$ for $I \in \B$.
%\end{lemma}
%\begin{proof}
%	As in the last lemma, define the operators $E_k$ and the measures $\mu_k$. By weak compactness, a subsequence of these measures converge weakly to some measure $\mu$, and $E_k(\mu) = \lim E_k(\mu_{j_k}) \leq \mu_k$. The measure $\mu$ is nonzero, since $\| \mu_{j_k} \| \geq c$ for each $k$, and so $\| \mu \| \geq c$.
%\end{proof}

\begin{lemma}[Frostman's Lemma]
	If $E$ is Borel, $H^s(E) > 0$ if and only if there exists an $s$ dimensional Frostman measure supported on $E$.
\end{lemma}
\begin{proof}
	Suppose that $\mu$ is $s$ dimensional and supported on $E$. If $H^s(F) = 0$, then for each $\varepsilon > 0$ there is a sequence of cubes $\{ Q_k \}$ with $\sum_{k = 1}^\infty l(Q_k)^s \leq \varepsilon$. But then
	%
	\[ \mu(F) \leq \sum_{k = 1}^\infty \mu(Q_k) \lesssim \sum_{k = 1}^\infty l(Q_k)^s \leq \varepsilon. \]
	%
	Taking $\varepsilon \to 0$, we conclude $\mu(F) = 0$. Thus $\mu$ is absolutely continuous with respect to $H^s$. Since $\mu(E) > 0$, this means that $H^s(E) > 0$.

	Conversely, suppose $H^s(E) > 0$. We work dyadically, with the classical family of dyadic cubes, i.e. with the sequence $\{ N_k = 2 : k \geq 1 \}$.  By translating, we may assume that $H^s(E \cap [0,1]^d) > 0$, and so without loss of generality we may assume $E \subset [0,1]^d$. For each $Q \in \DQ_k^d$, define $\mu^+(Q) = H^s_1(E \cap Q)$. Then $\mu^+(Q) \leq 1/2^{ks}$, and $\mu^+$ is subadditive. We use it to recursively define a Frostman measure $\mu$, such that $\mu(Q) \leq \mu^+(Q)$ for each $Q \in \DQ_k^d$. We initially define $\mu$ by setting $\mu([0,1]^d) = \mu^+([0,1]^d)$. Given $Q \in \DQ_k^d$, we enumerate it's children as $Q_1, \dots, Q_M \in \DQ_{k+1}^d$. We then consider any values $A_1, \dots, A_M \geq 0$ such that
	%
  	\begin{equation} \label{equation3424209034}
  		A_1 + \dots + A_M = \mu(Q),
  	\end{equation}
  	%
  	and for each $k$,
  	%
  	\begin{equation} \label{equation12039123012}
  		A_k \leq \mu^+(Q_k).
  	\end{equation}
	%
	This is feasible to do because $\mu^+(Q_1) + \dots + \mu^+(Q_M) \geq \mu^+(Q)$. We then define $\mu(Q_k) = A_k$ for each $k$. Equation \eqref{equation3424209034} implies the recursive constraint is satisfied, so $\mu$ is a well defined function. Equation \eqref{equation12039123012} implies \eqref{equation73234091} of Lemma \ref{massdistributionprinciplelem}, and so the mass distribution principle implies $\mu$ extends to a Borel measure which satisfies $\mu(Q) \leq \mu^+(Q) \leq 1/2^{ks}$ for each $Q \in \DQ_k^d$. Given any cube $Q$, we find $k$ with $1/2^{k-1} \leq l(Q) \leq 1/2^k$. Then $Q$ is covered by $O_d(1)$ dyadic cubes in $\DQ_k^d$, and so $\mu(Q) \lesssim l(Q)^s$ for any cube $Q$. And this means that we have shown directly that $\mu$ is a Frostman measure of dimension $s$.
\end{proof}

Frostman's lemma implies that to study the Hausdorff dimension of the set, it suffices to understand the class of measures which can be supported on that set. The Fourier dimension of a set also studies this perspective, by slightly refining the measure bound required by the Frostman dimension of a measure in frequency space.



\section{Fourier Dimension}

The applicability of Fourier analysis to the analysis of dimension begins by converting the measure bound required on the Frostman dimension onto a condition on the Fourier transform of the measure. For a Borel measure $\mu$, we define the \emph{$s$ energy} of $\mu$ as
%
\[ I_s(\mu) = \int \int \frac{d\mu(x) d\mu(y)}{|x - y|^s}. \]
%
A simple rearrangement shows that for each $y$,
%
\[ \int \int \frac{d\mu(x) d\mu(y)}{|x - y|^s} = s \int_0^\infty \frac{\mu(B(x,r))}{r^{s+1}}\; dr, \]
%
where $B(x,r)$ is the open ball of radius $r$ about the point $x$. This enables us to relate the Frostman bound with energy integrals.

\begin{theorem}
	For any set $E$,
	%
	\[ \hausdim(E) = \sup \{ s : \text{there is $\mu$ supported on $E$ with $I_s(\mu) < \infty$} \}. \]
\end{theorem}
\begin{proof}
	For each $x \in \RR^d$ and $r > 0$, let $B(x,r)$ denote the open ball of radius $r$ centered at $x$. We note $\mu$ is an $s$ dimensional Frostman measure if and only if $\mu(B(x,r)) \lesssim r^s$, since every dyadic cube with sidelength $r$ is contained in $O_d(1)$ balls of radius $r$, and every ball of radius $r$ is contained in $O_d(1)$ dyadic cubes with sidelength $r$. Thus if $\mu$ is a Frostman measure with dimension less than $s$, then $I_s(\mu) < \infty$. Conversely, if $I_s(\mu) < \infty$, then for $\mu$ almost every $y$,
	%
	\[ \int \frac{d\mu(x)}{|x - y|^s} < \infty \]
	%
	In particular, there is $M < \infty$, and $E_0$ with $\mu(E_0) > 0$ such that for any $y \in E_0$,
	%
	\[ \int \frac{d\mu(x)}{|x - y|^s} \leq M. \]
	%
	If we let $\nu(E) = \mu(E \cap E_0)$, then for any $y \in \RR^d$, if $\nu(B(y,r)) > 0$, there is $y_0 \in E \cap B(y,r)$, so $B(y,r) \subset B(y_0,2r)$, and this implies
	%
	\[ \nu(B(y,r)) \leq \nu(B(y_0,2r)) \leq \int_{B(y_0,2r)} d\nu(x) \leq 2^s r^s \int_{B(y_0,2r)} \frac{d\nu(x)}{|x - y|^s} \leq (2^s M) r^s. \]
	%
	Thus $\nu$ is a Frostman measure of dimension $s$ supported on $E$.
\end{proof}

\begin{lemma}
	There exists a constant $C(d,s)$ such that
	%
	\[ I_s(\mu) = C(d,s) \int k_{d-s}(\xi) |\widehat{\mu}(\xi)|^2\; d\xi. \]
\end{lemma}
\begin{proof}
	We can convert the energy integral into a condition on the Fourier transform. If we define the \emph{Riesz kernels} $k_s(x) = 1/|x|^s$, for $0 < s < d$, then
	%
	\[ I_s(\mu) = \int (k_s * \mu) d\mu. \]
	%
	Naively applying the multiplication formula for the Fourier transform, we find
	%
	\begin{align*}
		\int (k_s * \mu)(x) d\mu(x) &= \int \widehat{k_s * \mu}(\xi) \overline{\widehat{\mu}(\xi)}\; dx\\
		&= \int \widehat{k_s}(\xi) |\widehat{\mu}(\xi)|^2\; dx\\
		&= C(d,s) \int k_{d-s}(\xi) |\widehat{\mu}(\xi)|^2\; dx.
	\end{align*}
	%
	where we have used the fact that the Fourier transform of $k_s$ is equal to $C(d,s) k_{d-s}$ for some constant $C(d,s)$. This is not a rigorous argument, because the kernels $k_s$ and the measure $\mu$ do not lie in $L^1(\RR^d)$. But one can interpret this idea in a distributional sense, and therefore obtain the formula by a technical argument involving approximations to the identity, which we leave out of this thesis. A formal proof can be found in BLAH.
\end{proof}

Thus the application of energy integrals translates the problem of finding a Frostman measure bound to frequency space. In particular, if $\mu$ is a Frostman measure of dimension $s$, then
%
\[ \int \frac{|\widehat{\mu}(\xi)|^2}{|\xi|^{d-s}}\; d\xi < \infty. \]
%
A weak type bound implies that we should have
%
\begin{equation} \label{equation89041094242} |\widehat{\mu}(\xi)|^2 \lesssim |\xi|^{s/2} \end{equation}
%
for \emph{most} values $\xi$. Thus we obtain a stronger condition if we require that \eqref{equation89041094242} holds for \emph{all} values $\xi$. In particular, we say a measure $\mu$ is a measure with \emph{Fourier dimension} $s$ if $\eqref{equation89041094242}$ holds for \emph{all} values $\xi$. If this is true, then $I_t(\mu) < \infty$ for all $t < s$. Thus if we define the \emph{Fourier dimension} of a set $E$ as
%
\[ \fordim(E) = \sup \left\{ s : \begin{array}{c} \text{there is $\mu$ supported on $E$ with}\\ \text{$|\widehat{\mu}(\xi)| \lesssim |\xi|^{s/2}$ for all $\xi \in \RR^d$} \end{array} \right\}, \]
%
then $\fordim(E) \leq \hausdim(E)$.

We say a set $E$ is \emph{Salem} if $\fordim(E) = \hausdim(E)$. Most classical, self-similar fractals (for instance, the classical Cantor set) have Fourier dimension zero, and are therefore not Salem. Nonetheless, it is a general principle that most \emph{random} families of sets are almost surely Salem. As of now, except in very particular cases, the only way to find sets with large Fourier dimension is to input randomness into their construction. Using randomness, in Chapter BLAH we are able to find Salem sets with large Fourier dimension.







\section{Dyadic Fractional Dimension}

We wish to establish results about fractional dimension `dyadically'. We begin with Minkowski dimension. For each $m$, let $N_{\DQ}(m,E)$ denote the minimal number of cubes in $\DQ_m^d$ required to cover $E$. This is often easy to calculate, up to a multiplicative constant, by greedily selecting cubes which intersect $E$.

\begin{lemma} \label{comparableCovers}
	For any set $E$,
	%
	\[ N_{\DQ}(m,E) \sim_d \# \{ Q \in \DQ_m^d : Q \cap E \neq \emptyset \} \sim_d N(l_m,E). \]
\end{lemma}
\begin{proof}
	Let $\mathcal{E} = \{ Q \in \DQ_m^d : Q \cap E \neq \emptyset \}$. Then $\mathcal{E}$ is certainly a cover of $E$ by dyadic cubes, which shows $N_{\DQ}(m,E) \leq \#(E)$. Conversely, let $\{ Q_k \}$ be a minimal cover of $E$. Then $Q_k \cap E \neq \emptyset$ for each $m$, so $\{ Q_k \} \subset \mathcal{E}$. But if $Q \in \mathcal{E}$, then it intersects a cube in $\{ Q_k \}$, and since each cube $Q_k$ intersects at most $2^d$ other cubes in $\DQ_k^d$, we conclude that $\#(\mathcal{E}) \leq (2^d + 1) N_{\DQ}(k,E)$. The bound $N(l_m,E) \leq N_{\DQ}(m,E)$ is obvious, whereas for each $Q$ with $l(Q) = l_m$, $Q$ is covered by $2^d + 1$ cubes in $\DQ_m^d$, so $N_{\DQ}(m,E) \leq (2^d + 1) N(l_m,E)$.
\end{proof}

Thus it is natural to ask whether it is true that for any set $E$,
%
\begin{equation} \label{definingSequence}
	\begin{aligned}
		\lowminkdim(E) &= \liminf_{k \to \infty} \frac{\log[N_{\DQ}(k,E)]}{\log[1/l_k]}\\
		\text{and}\\
		\upminkdim(E) &= \limsup_{k \to \infty} \frac{\log[N_{\DQ}(k,E)]}{\log[1/l_k]}.
	\end{aligned}
\end{equation}
%
The answer depends on the choice of $\{ N_k \}$. In particular, we find that a sufficient condition is that
%
\begin{equation} \label{definingsequencegrowthrate}
	N_{k+1} \lesssim_\varepsilon (N_1 \dots N_k)^\varepsilon \quad \text{for any $\varepsilon > 0$}.
\end{equation}

%Subsets of $\Sigma^d$ can also be assigned a Minkowski dimension. We define
%
%\[ \lowminkdim(E) = \liminf_{k \to \infty} \frac{\log(\#(\sigma_k^d(E)))}{\log(1/l_k)}\quad\text{and}\quad\upminkdim(E) = \limsup_{k \to \infty} \frac{\log(\#(\sigma_k^d(E)))}{\log(1/l_k)}. \]
%
%This makes sense, because $\Sigma^d$ only really has `balls' of radius $\{ l_k \}$, for each $k$, and \emph{any} cover of $E$ by balls of radius $l_k$ contains $\sigma_k^d(E)$. In order 
%we have $N(E,l_k) = \# (\Sigma_k^d(E))$, since \emph{any} cover of $E$ by balls of radius $l_k$

\begin{lemma} \label{definingsequenceminkowski}
	If \eqref{definingsequencegrowthrate} holds, then \eqref{definingSequence} holds.
\end{lemma}
\begin{proof}
	Fix a length $l$, and find $k$ with $l_{k+1} \leq l \leq l_k$. Applying Lemma \ref{comparableCovers} shows
	%
	\[ N(l,E) \leq N(l_{k+1},E) \lesssim_d N_{\DQ}(k+1,E) \]
	%
	and
	%
	\[ N(l,E) \geq N(l_k,E) \gtrsim_d N_{\DQ}(k,E). \]
	%
	Thus
	%
	\[ \frac{\log[N(l,E)]}{\log[1/l]} \leq \left[ \frac{\log(1/l_{k+1})}{\log(1/l_k)} \right] \frac{\log[N_{\DQ}(k+1,E)]}{\log[1/l_{k+1}]} + O_d(1/k) \]
	%
	and
	%
	\[ \frac{\log[N(l,E)]}{\log[1/l]} \geq \left[ \frac{\log(1/l_k)}{\log(1/l_{k+1})} \right] \frac{\log[N_{\DQ}(k,E)]}{\log[1/l_k]} + O_d(1/k). \]
	%
	Thus, provided that
	%
	\begin{equation} \label{equivalenceofscales}
		\frac{\log(1/l_{k+1})}{\log(1/l_k)} \to 1,
	\end{equation}
	%
	the conclusion of the theorem is true. But \eqref{equivalenceofscales} is equivalent to the condition that
	%
	\[ \frac{\log(N_{k+1})}{\log(N_1) + \dots + \log(N_k)} \to 0, \]
	%
	and this is equivalent to \eqref{definingsequencegrowthrate}.
\end{proof}

Any constant branching factor satisfies the hypothesis of Lemma \ref{definingsequenceminkowski} for the Minkowski dimension. In particular, we can construct sets over classical dyadic cubes without any problems occuring. But more importantly for our work, we can let the sequence $\{ N_k \}$ increase rapidly.

\begin{lemma} \label{rapidBranching}
	If $N_k = 2^{\lfloor 2^{k \psi(k)} \rfloor}$, where $\psi(k)$ is any decreasing sequence of positive numbers tending to zero, but for which $k \psi(k) \to \infty$, then \eqref{definingsequencegrowthrate} holds.
\end{lemma}
\begin{proof}
	We note that $\log(N_k) = 2^{k \psi(k)} + O(1)$. Thus
	%
	\begin{align*}
		\frac{\log(N_{k+1})}{\log(N_1) + \dots + \log(N_k)} &= \frac{2^{(k+1) \psi(k+1)} + O(1)}{2^{\psi(1)} + 2^{2 \psi(2)} + \dots + 2^{k \psi(k)} + O(k)}\\
		&\lesssim \frac{2^{(k+1) \psi(k+1)}}{2^{\psi(k)} + 2^{2 \psi(k)} + \dots 2^{k \psi(k-1)}}\\
		&\lesssim \frac{2^{(k+1) \psi(k+1)}}{2^{(k+1) \psi(k)}} ( 2^{\psi(k)} - 1 ) = 2^{\psi(k)} - 1 \to 0.
	\end{align*}
	%
	This is equivalent to the fact that $N_{k+1} \lesssim_\varepsilon (N_1 \dots N_k)^\varepsilon$ for any $\varepsilon > 0$.
\end{proof}
%
We refer to any sequence $\{ l_k \}$ constructed by $\{ N_k \}$ satisfying the conditions of Lemma \ref{rapidBranching} as a \emph{subhyperdyadic} sequence. If a sequence is generated by a sequence $\{ N_k = 2^{\lfloor 2^{ck} \rfloor} \}$, for some fixed $c > 0$, the lengths are referred to as \emph{hyperdyadic}. The next (counter) example shows that hyperdyadic sequences are essentially the `boundary' for sequences that can be used to measure the Minkowski dimension.

\begin{example}
	We consider a multi-scale dyadic construction. Fix $0 \leq c < 1$, and define $N_k = 2^{\lfloor 2^{ck} \rfloor}$, and $M_k = 2^{\lfloor c 2^{ck} \rfloor}$. Then $M_k \divides N_k$ for each $k$. We recursively define a nested family of sets $\{ E_k \}$, with each $E_k$ a $\DQ_k^d$ discretized set, and set $E = \bigcap E_k$. We define $E_0 = [0,1]$. Then, given $E_k$, we divide each sidelength $l_k$ dyadic interval in $E_k$ into $M_{k+1}$ intervals, and then keep the first sidelength $l_k/M_{k+1}$ interval from this set, which is formed from $N_{k+1}/M_{k+1}$ sidelength $l_{k+1}$ dyadic intervals. Thus $\#(\DQ_0(E_0)) = 1$, and
	%
	\[ \#(\DQ_{k+1}(E_{k+1})) = (N_{k+1}/M_{k+1}) \#(\DQ_k(E_k)) \]
	%
	so
	%
	\begin{equation} \label{equation12623} \#(\DQ_k(E_k)) = \frac{N_1 \dots N_k}{M_1 \dots M_k} \end{equation}
	%
	Noting that $\log(N_i) = 2^{ci} + O(1)$, and $\log(M_i) = c2^{ci} + O(1)$, we conclude that
	%
	\begin{align*}
		\frac{\log \#(\DQ_k(E_k))}{\log(1/l_k)} &= \frac{(1-c)(2^c + \dots + 2^{ck}) + O(k)}{(2^c + \dots + 2^{ck}) + O(k)} = 1-c + O\left(\frac{k}{2^{ck}} \right) \to 1-c.
	\end{align*}
	%
	On the other hand, if $r_{k+1} = l_k/M_{k+1}$, then for each $k$,
	%
	\[ \#(\DR_{k+1}^d(E_k)) = \#(\DQ_k(E_k)) = \frac{N_1 \dots N_k}{M_1 \dots M_k}, \]
	%
	and so
	%
	\begin{align*}
		\frac{\log \#(\DR_{k+1}^d(E_k))}{\log(1/r_{k+1})} &= \frac{(1-c)(2^c + \dots + 2^{ck}) + O(k)}{(2^c + \dots + 2^{ck}) + c2^{c(k+1)} + O(k)} \\
		&= \frac{\left( \frac{(1-c) 2^c}{2^c - 1} \right) 2^{ck} + O(k)}{ \left( \frac{2^c}{2^c - 1} + c2^c \right) 2^{ck} + O(k)}\\
		&= \frac{1-c}{1 - c + c2^c} + O \left( \frac{k}{2^{ck}} \right) \to \frac{1 - c}{1 - c + c2^c} < 1 - c.
	\end{align*}
	%
%
%	Fix $0 \leq c < 1$. Let $\{ M_k \}$ be a sequence of integers such that $M_k \divides N_k$ for each $k$. We recursively define a sequence of sets $\{ E_k \}$, with $E_k$ a union of length $l_k$ intervals
%
%	Construct a subset of $\RR$ as follows. Let $N_k = K_kM_k$, where $N_k$, $K_k$, and $M_k$ are parameters to be specified later. Define $E_0 = [0,1]$. Given $E_k$, define $E_{k+1}$ by dividing each sidelength $l_k$ dyadic interval in $E_k$ into $K_{k+1}$ intervals, and then keeping only the first interval. Then $\#(\DQ_{k+1}^d(E_{k+1})) = M_k \cdot \#(\DQ_k^d(E_k))$, and since $\#(\DQ_0^d(E_0)) = 1$, $\#(\DQ_k^d(E_k)) = M_1 \dots M_k$. Thus
%	\begin{align*}
%		\frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} &\sim \frac{\log \left[ \#(\DQ_k^d(E_k)) \right]}{\log(1/l_k)}\\
%		&= \frac{\log(M_1) + \dots + \log(M_k)}{\log(N_1) + \dots + \log(N_k)}\\
%		&= 1 - \frac{\log(K_1) + \dots + \log(K_k)}{\log(N_1) + \dots + \log(N_k)}.
%	\end{align*}
	%
%	On the other hand, if $r_k = l_k/K_{k+1}$, $N(r_k,E) \sim_d \#(S_k) = M_1 \dots M_k$, so
	%
%	\begin{align*}
%		\frac{\log \left[ N(r_k,E) \right]}{\log(1/r_k)} &\sim \frac{\log \left[ \#(\DQ_k^d(E_k)) \right]}{\log(1/r_k)}\\
%		&= \frac{\log(M_1) + \dots + \log(M_k)}{\log(N_1) + \dots + \log(N_k) + \log(K_{k+1})}\\
%		&= 1 - \frac{\log(K_1) + \dots + \log(K_{k+1})}{\log(N_1) + \dots + \log(N_k) + \log(K_{k+1})}.
%	\end{align*}
	%
%	Set $N_k = 2^{\lfloor 2^{ck} \rfloor}$, and $K_k = 2^{\lfloor c 2^{ck} \rfloor}$. Then
	%
%	\[ \log(K_1) + \dots + \log(K_k) = O(k) + c \sum_{i = 1}^k 2^{ck} = O(k) + c \frac{2^{c(k+1)} - 2^c}{2^c - 1} \]
	%
%	and
	%
%	\[ \log(N_1) + \dots + \log(N_k) = O(k) + \sum_{i = 1}^k 2^{ck} = O(k) + \frac{2^{c(k+1)} - 2^c}{2^c - 1}. \]
	%
%	Thus
	%
%	\[ \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} \to 1 - c \quad \text{and} \quad \frac{\log \left[ N(r_k,E) \right]}{\log(1/l_k)} \to \frac{1 - c}{1 - c + c2^c}. \]
	In particular,
	%
	\[ \lowminkdim(E) \neq \liminf_{k \to \infty} \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} = \liminf_{k \to \infty} \frac{\log[N_{\DQ}(k,E)]}{\log(1/l_k)}, \]
	%
	so measurements at hyperdyadic scales fail to establish general results about the Minkowski dimension.

%	\[ \lim_{k \to \infty} \frac{\log(K_1) + \dots + \log(K_k)}{2^{c(k+1)} - 2^c} \neq \lim_{k \to \infty} \frac{\log(K_1) + \dots + \log(K_{k+1})}{2^{c(k+1)} - 2^c} \frac{1}{1 + \log(K_{k+1}) (2^c - 1)/(2^{c(k+1)} - 2^c)} \]

%	First, assume $N_k/N_{k-1} \in \mathbf{Z}$ for each $k$, and for convenience, set $N_0 = 1$. Define $S_0 = \{ 0 \}$, and then given $S_k$, recursively define
	%
%	\[ S_{k+1} = \{ (j,1), \dots, (j,N_{k+1}/N_k) : j \in S_k \} \]
	%
%	We then set $E = \pi(\lim S_k)$. If we let $E_k = \bigcup \{ Q_j : j \in S_k \}$, then $E_{k+1}$ can be constructed by dividing each sidelength $l_k$ dyadic interval in $E_k$ into $N_{k+1}$ intervals, and selecting the initial $N_{k+1}/N_k$ intervals, which have total length $1/(N_1 \dots N_k^2)$. Then $\#(S_{k+1}) = (N_{k+1}/N_k) \#(S_k)$, and since $\#(S_0) = 1$, $\#(S_k) = N_k$. Thus
	%
%	\[ \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} \sim_d \frac{\log \left[ \# (S_k) \right]}{\log(1/l_k)} = \frac{\log(N_k)}{\log(N_1) + \dots + \log(N_k)}. \]
	%
%	On the other hand, if $r_k = 1/(N_1 \dots N_k^2) = l_k/N_k$, then $N(l,E) = \#(S_k) = N_k$, so
	%
%	\[ \frac{\log \left[ N(r_k,E) \right]}{\log(1/r_k)} \sim_d \frac{\log \left[ \#(S_k) \right]}{\log(1/r_k)} = \frac{\log(N_k)}{\log(N_1) + \dots + 2\log(N_k)}. \]
%	In any case to which Lemma \ref{definingsequenceminkowski} applies, both of these estimates converge to zero as $k \to \infty$, so that $E$ has Minkowski dimension zero. On the other hand, if $N_k = 2^{\lfloor \psi(k) 2^k \rfloor}$ where $\psi(k)$ is an increasing sequence tending to $\infty$, then
	%
%	\begin{align*}
%		\frac{2^{(k-1) \psi(k-1)}}{2^{\psi(1)} + 2^{2 \psi(2)} + \dots + 2^{(k-1) \psi(k-1)}} &\geq \frac{\left(2^{(k-1) \psi(k-1)} \right) \left( 2^{\psi(k-1)} - 1 \right)}{2^{k \psi(k-1)} - 2^{\psi(k-1)}} \sim 1.
%	\end{align*}
	%
%	Thus
	%
%	\[ \lim_{k \to \infty} \frac{\log \left[ N(l_k,E) \right]}{\log(1/l_k)} = 1. \]
	%
%	On the other hand,
	%
%	\[ \frac{\log \left[ N(r_k, E) \right]}{\log(1/r_k)} = \frac{\log(N_k)}{\log(N_1) + \dots + 2\log(N_k)} \leq 1/2. \]
	%
%	Thus we cannot possibly have
	%
%	\[ \lowminkdim(E) = \liminf_{k \to \infty} \frac{\log \left( N(l_k,E) \right)}{\log(1/l_k)}, \]
	%
	%
%	A simple calculation shows this result even fails if $N_k = 2^{\lfloor 2^{ck} \rfloor}$, where $c > 1$.
\end{example}

%In particular, we can define the Minkowski dimensions of $E \subset \Sigma$ as
%
%\[ \lowminkdim(E) = \liminf_{k \to \infty} \frac{\log(\#(\Sigma_k^d(E)))}{\log(1/l_k)}\quad\text{and}\quad\upminkdim(E) = \limsup_{k \to \infty} \frac{\log(\#(\Sigma_k^d(E)))}{\log(1/l_k)}. \]
%
%Similarily, the Hausdorff measures $H^s$ are obtained by setting
%
% TODO: Fix this
%\[ H^s(E) = \left\{ \sum_m l_{k_m} : Q_m \in \Sigma_{k_m}^d\ \text{for each $k$}, \text{For any} \right\} \]
%
%and define the Hausdorff dimension correspondingly. A natural question is whether $\dim(\pi(E)) = \dim(E)$ for the various fractal dimensions we consider in this thesis. This is addressed in the next section.

We now move on to calculating Hausdorff dimension dyadically. The natural quantity to consider is the measure defined for any $E$ as $H^s_{\DQ}(E) = \lim H^s_{\DQ,m}(E)$, where
%
\[ H^s_{\DQ,m}(E) = \inf \left\{ \sum_k l(Q_k)^s : E \subset \bigcup_k^\infty Q_k,\ Q_k \in \bigcup_{i \geq m} \DQ_i^d\ \text{for each $k$} \right\}. \]
%
A similar argument to the standard Hausdorff measures shows there is a unique $s_0$ such that $H^s_{\DQ}(E) = \infty$ for $s < s_0$, and $H^s_{\DQ}(E) = 0$ for $s > s_0$. It is obvious that $H^s_{\DQ}(E) \geq H^s(E)$ for any set $E$, so we certainly have $s_0 \geq \hausdim(E)$. The next lemma guarantees that $s_0 = \hausdim(E)$, under the same conditions on the sequence $\{ N_k \}$ as found in Lemma \ref{definingsequenceminkowski}.

\begin{lemma} \label{lemma51464}
	If \eqref{definingsequencegrowthrate} holds, then for any $\varepsilon > 0$, $H^s_{\DQ}(E) \lesssim_{s,\varepsilon} H^{s-\varepsilon}(E)$.
\end{lemma}
\begin{proof}
	Fix $\varepsilon > 0$ and $m$. Let $E \subset \bigcup Q_k$, where $l(Q_k) \leq l_m$ for each $k$. Then for each $k$, we can find $i_k$ such that $l_{i_k+1} \leq l(Q_k) \leq l_{i_k}$. Then $Q_k$ is covered by $O_d(1)$ elements of $\DQ_{i_k}^d$, and
	%
	\begin{equation} \label{equation824} H^s_{\DQ,m}(E) \lesssim_d \sum l_{i_k}^s \leq \sum (l_{i_k}/l_{i_k+1})^s l(Q_k)^s \leq \sum \left( l_{i_k}/l_{i_{k+1}} \right)^s l_{i_k}^\varepsilon l(Q_k)^{s - \varepsilon} \end{equation}
	%
	By assumption,
	%
	\begin{equation} \label{equation992352}
		l_{i_k+1} = \frac{1}{N_1 \dots N_{i_k} N_{i_k+1}} \gtrsim_{s,\varepsilon} (N_1 \dots N_{i_k})^{1+ \varepsilon/s} = l_{i_k}^{1 + \varepsilon/s}.
	\end{equation}
	%
	Putting \eqref{equation824} and \eqref{equation992352} together, we conclude that $H^s_{\DQ,m}(E) \lesssim_{d,s,\varepsilon} \sum l(Q_k)^{s-\varepsilon}$. Since $\{ Q_k \}$ was an arbitrary cover of $E$, we conclude $H^s_{\DQ,m}(E) \lesssim H^{s-\varepsilon}(E)$, and since $m$ was arbitrary, that $H^s_{\DQ}(E) \lesssim H^{s-\varepsilon}(E)$.
\end{proof}

Finally, we consider computing whether we can establish that a measure is a Frostman measure dyadically. First, we recognize the utility of this approach from the perspective of a dyadic construction. Suppose we have a sequence of nested sets $\{ E_k \}$, where $E_k$ is a $\DQ_k$ discretized subset of $[0,1]^d$, and for each $Q_0 \in \DQ_k(E_k)$, there is at least one cube $Q \in \DQ_{k+1}(E_{k+1})$ with $Q^* = Q_0$. Then we can set $E = \bigcap E_k$ as a `limit' of the discretizations $E_k$. We can associate with this construction a finite measure $\mu$. It is defined by setting $\mu([0,1]^d) = 1$, and setting, for each $Q \in \DQ_{k+1}(E_{k+1})$,
%
\[ \mu(Q) = \frac{\mu(Q^*)}{\# \{ Q' \in \DQ_{k+1}(E_{k+1}) : (Q')^* = Q^* \}}. \]
%
The mass distribution principle extends $\mu$ to a Borel measure, and we refer to it as the \emph{canonical} measure associated with this construction. For this measure, it is often easy to show from a combinatorial argument that $\mu(Q) \lesssim l(Q)^s$ if $Q \in \DQ^d$. Condition \eqref{definingsequencegrowthrate} is again sufficient to infer that $\mu$ is a Frostman measure of dimension $s - \varepsilon$ for all $\varepsilon > 0$.

\begin{theorem} \label{easyCoverTheorem}
	If \eqref{definingsequencegrowthrate} holds, and if $\mu$ is a Borel measure such that $\mu(Q) \lesssim l(Q)^s$ for each $Q \in \DQ_k^d$, then $\mu$ is a Frostman measure of dimension $s - \varepsilon$ for each $\varepsilon > 0$.
\end{theorem}
\begin{proof}
	Given a cube $Q$, find $k$ such that $l_{k+1} \leq l(Q) \leq l_k$. Then $Q$ is covered by $O_d(1)$ cubes in $\DQ^d_k$, which shows
	%
	\[ \mu(Q) \lesssim_d l_k^s = [(l_k/l)^s l^\varepsilon ] l^{s - \varepsilon} \leq [l_k^{s + \varepsilon} / l_{k+1}^s] l^{s - \varepsilon} = \left[ \frac{N_{k+1}^s}{(N_1 \dots N_k)^\varepsilon} \right] l^{s-\varepsilon} \lesssim_\varepsilon l^{s-\varepsilon}. \qedhere \]
\end{proof}	

\begin{remark}
	The dyadic construction showing that Minkowski dimension cannot be measured only at hyperdyadic scales also shows that a bound on a measure $\mu$ on hyperdyadic cubes does not imply the correct bound at all scales. It is easy to show from \eqref{equation12623} that the canonical measure $\mu$ for this example satisfies $\mu(Q) \lesssim l(Q)^{1-c}$ for all $Q \in \DQ_k(E_k)$, yet we know that for the set constructed in that example,
	%
	\[ \hausdim(E) \leq \lowminkdim(E) < 1 - c. \]
	%
	Frostman's lemma implies we cannot possibly have $\mu(Q) \lesssim_\varepsilon l(Q)^{1-c-\varepsilon}$ for all $\varepsilon > 0$ and \emph{all} cubes $Q$.
\end{remark}






%Our final method for interpolating requires extra knowledge of the dissection process, but enables us to choose the $l_k$ arbitrarily rapidly. The idea behind this is that there is an additional sequence of lengths $r_k$ with $l_k \leq r_k \leq l_{k-1}$. The difference between $r_k$ and $l_{k-1}$ is allowed to be arbitrary, but the decay rate between $l_k$ and $r_k$ is of polynomial-type, which enables us to use the covering methods of the previous section. In addition, we rely on a `uniform mass bound' between $r_k$ and $l_k$ to cover the remaining classes of intervals. Because we can take $r_k$ arbitrarily large relative to $l_k$, this renders any constants that occur in the construction to become immediately negligible. For two quantities $A$ and $B$, we will let $A \precsim_k B$ stand for an inequality with a hidden constant depending only on parameters with index smaller than $k$, i.e. $A \leq C(l_1, \dots, l_k, r_1,\dots,r_k) B$ for some constant $C(l_1, \dots, l_k, r_1, \dots, r_k)$ depending only on parameters with indices up to $k$.

\section{Beyond Hyperdyadics}

If we are to use a faster increasing sequence of branching factors than the last section guarantees, we therefore must exploit some extra property of our construction, which is not always present in general sets. Here, we rely on a \emph{uniform mass distribution} between scales. Given the uniformity assumption, the lengths can decrease as fast as desired. We utilize a multi-scale set of dyadic cubes.

\begin{lemma} \label{uniformMassFrostman}
	Let $\mu$ be a measure supported on a set $E$. Suppose that
    %
    \begin{enumerate}
    	\item \label{discreteBound} For any $Q \in \DQ_k^d$, $\mu(Q) \lesssim l_k^s$.
    	\item \label{controlledScale} For each $Q \in \DR_k^d$, $\# \{ Q \in \DQ_k^d : E \cap Q \neq \emptyset \} = O(1)$.
    	\item \label{uniformDist} For any $Q \in \DR_{k+1}^d$ with parent cube $Q^* \in \DQ_k^d$, $\mu(Q) \lesssim (r_{k+1}/l_k)^d \mu(Q^*)$.
    \end{enumerate}
	%
	Then $\mu$ is a Frostman measure of dimension $s$.
\end{lemma}
\begin{proof}
	We establish the general bound $\mu(Q) \lesssim l(Q)^s$ for all cubes $Q$ in two different cases:
	%
	\begin{itemize}
		\item Suppose there is $k$ with $r_{k+1} \leq l \leq l_k$. Then we can cover $Q$ by at most $O_d((1/r_{k+1})^d)$ cubes in $\DR_k^d$. By Properties \ref{discreteBound} and \ref{uniformDist}, each of these cubes has measure at most $O( (r_{k+1}/l_k)^d l_k^s)$, so we obtain that
    %
    \[ \mu(Q) \lesssim (l/r_{k+1})^d (r_{k+1}/l_k)^d l_k^s = l^d / l_k^{d-s} \lesssim l^s. \]

    \item Suppose there exists $k$ with $l_k \leq l \leq r_k$. Then we can cover $Q$ by $O_d(1)$ cubes in $\DR_k^d$, and for each such cube, Property \ref{uniformDist} shows there are $O(1)$ cubes in $\DQ_k^d$ which have mass. Thus
    %
    \[ \mu(Q) \lesssim l_k^s \leq l^s. \]
	\end{itemize}
	%
	This addresses all cases, so $\mu$ is a Frostman measure of dimension $s$.
\end{proof}

TODO: ADDRESS OTHER FRACTIONAL DIMENSION CASES?

%\begin{remark}
%    The condition $\mu_\beta(J) \lesssim_{N-1} (r_N/l_N) \mu_\beta(I)$ essentially means that the probability mass on a length $l_N$ interval $I$ is uniformly distributed over the length $r_N$ intervals it contains. This is what enables us to remove the discussion of the growth of the sequence $\beta$ over time from discussion.
%\end{remark}

%Since the construction is obtained as a limit of intervals, it is often possible to construct such a $\mu$ by the {\it mass distribution principle}. That is, we let $\mu$ denote the weak limit of the probability masses $\mu_n$, where $\mu_0$ is a uniform distribution over $\mu_0$, and $\mu_{n+1}$ is obtained from $\mu_n$ by distributing the mass $\mu_n(I)$ of each length $l_n$ interval $I$ contained in $X_n$ over the portion of $I$ that remains in $X_{n+1}$. The cumulative distribution functions of the $\mu_n$ uniformly converge, hence the $\mu_n$ converge weakly to some $\mu$, which satisfy $\mu(I) = \mu_n(I)$ for each interval $I$ as above. Because of this discreteness, it is most easy to establish a bound $\mu(I) \lesssim l_n^\alpha$ when $I \subset X_n$ is a length $l_n$ interval. Since any interval $I$ of length $l_n$ is contained within at least two such intervals (or is contained in other length $l_n$ intervals that $\mu$ assigns no mass to), we have the general bound $\mu(I) \lesssim l_n^\alpha$ for all intervals $I$ of length $l_n$. Hausdorff dimension is a local property of a set\footnote{If we define $\dim_{\mathbf{H}}(x) = \lim_{r \downarrow 0} \dim_{\mathbf{H}}(B_r(x) \cap X)$ then $\dim_{\mathbf{H}}(X) = \sup_{x \in X} \dim_{\mathbf{H}}(x)$.}, so it is natural to expect that we can obtain a general bound $\mu(I) \lesssim_\alpha|I|^\alpha$ given that one has established precisely the same estimate, but restricted to intervals $I$ with $|I| = l_N$. This section concerns itself with ways that we can establish this general bound, and thus prove that $\dim_{\mathbf{H}}(X) \geq \alpha$.

%\section{BLAH}

%The collection $\DQ^d$ forms a \emph{tree} under the partial ordering induced by inclusion, with a branching factor of $H$. We let $\DB^d$ denote the set of all branches of the tree $\DQ^d$. For each branch $\mathfrak{b} = \{ Q_k : k \geq 0 \}$, the set $\bigcap_{k \geq 0} Q_k$ contains a unique point, which induces a function $\pi: \DB^d \to \RR^d$. This function is obviously surjective, but unfortunately not injective. Nonetheless, for each $x \in \RR^d$, $\pi^{-1}(x)$ contains $O_d(1)$ points. This means that from the point of view of geometric measure theory, the spaces $\DB^d$ and $\RR^d$ are isomorphic\footnote{Formally, we can define a topology on $\DB^d$ as a subset of $\prod_{k \geq 0} \DQ_k^d$, and $\pi$ is continuous with respect to this topology. We can also define the Hausdorff measures $H^s$ on $\DB^d$ as limits of $H^s_m$, where
%
%\[ H^s_m(E) = \inf \left\{ \sum_{i = 1}^\infty l(Q_i)^s : Q_i \in \DQ_{k_i}^d, k_i \geq m, E \subset \bigcup \{ \mathfrak{b} \in \DB^d : \mathfrak{b}_k = Q \} \right\} \]
%
%Then for each value $s > 0$ the map $\pi$ is an isomorphism of $(\DB^d, H^s)$ and $(\RR^d, H^s)$.}. In particular, given any configuration $\C$ on $\RR^d$, we can define a configuration $\pi^{-1}(\C)$ on $\DB^d$ as
%
%\[ \pi^{-1}(\C) = \{ (\mathfrak{b_1}, \dots, \mathfrak{b}_n) : (\pi(\mathfrak{b_1}), \dots, \pi(\mathfrak{b_n})) \in \C \}. \]
%
%If we can find an $s$ dimensional set $E \subset \DB^d$ avoiding $\pi^{-1}(\C)$, then $\pi(E)$ avoids $\C$ and is $s$ dimensinoal. Conversely, if $E \subset \RR^d$ avoids $\C$ and is $s$ dimensional, then $\pi^{-1}(E)$ avoids $\pi^{-1}(\C)$ and is $s$ dimensional.

%The Dyadic model is useful, but if the lengths decrease too fast, the model fails to reflect the geometry of $\RR^n$ at all scales.

\section{Extras: Hyperdyadic Covers}

Nonetheless, it will be useful for us to know that we can `decompose' a set with a prescribed Hausdorff dimension hyperdyadically. We say a sequence of sets $\{ E_k \}$ is a \emph{strong cover} of a set $E$ if $E \subset \limsup E_k$, or equivalently, if every $x \in E$ lies in infinitely many of the sets $E_k$. In this section, we inclusively treat hyperdyadic cubes, i.e. we assume $l_k = 2^{-\lfloor (1 + \varepsilon)^k \rfloor}$ for some fixed $0 < \varepsilon \leq 1$.

%Fix two parameters $\delta > 0$ and $\varepsilon > 0$. Given two numbers $A = A_{\delta \varepsilon}$ and $B = B_{\delta \varepsilon}$, we say $A \lessapprox B$ if there exists constants $C_\varepsilon$, and $C$ such that $A \leq C_\varepsilon \delta^{-C\varepsilon} B$. We say $A \approx B$ if $A \lessapprox B$ and $B \lessapprox A$. We say a set $E$ is \emph{$\delta$ discretized} if it is a union of dyadic cubes with sidelength $\approx \delta$. We say a set $E$ is a \emph{$(\delta,\alpha)$ set} if it is $\delta$ discretized, and for any dyadic cube $I$ with $\delta \leq l(I) \leq 1$, $|E \cap I| \lessapprox \delta^{d-\alpha} l(I)^\alpha$. Thus $E$ is \emph{roughly} a $\delta$ thickening of an $\alpha$ dimensional set. A set $E$ is \emph{strongly covered} by a family of sets $\{ U_i \}$ if $E \subset \limsup_{i \to \infty} U_i$. We consider a fixed hyperdyadic sequence $l_k = 2^{- \lfloor (1 + \varepsilon)^k \rfloor}$.

%\begin{lemma}
%	If $C$ is sufficiently large, and for each $\varepsilon$, there is a $(\delta, \alpha - C \varepsilon)$ set $X_\delta$ for each hyperdyadic $\delta$ such that the $X_\delta$ strongly cover $X$, then $\dim(X) \leq \alpha$.
%\end{lemma}
%\begin{proof}
%	Let $X_\delta = \bigcup I_i$, where $\{ I_i \}$ are disjoint dyadic cubes such that $l(I_i) \approx \delta$, and with $|X_\delta| \lessapprox \delta^{d-\alpha + C\varepsilon}$. Then
	%
%	\[ |X_\delta(\delta/2)| \leq \sum (l(I_i) + \delta/2)^d \lessapprox \sum l(I_i)^d = |X_\delta| \lessapprox \delta^{d - \alpha + C\varepsilon}. \]
	%
%	A volumetric argument then guarantees that $N(X_\delta,\delta) \lessapprox \delta^{-\alpha + C\varepsilon}$, and so
	%
%	\[ H^\alpha_\infty(X_\delta) \leq N(X_\delta,\delta) \delta^\alpha \lessapprox \delta^{C\varepsilon}. \]
	%
%	Thus there is $C_\varepsilon$ and $C_0$ such that $H^\alpha_\delta(X_\delta) \leq C_\varepsilon \delta^{(C - C_0) \varepsilon}$. Since $C_0$ does not depend on $C$, if we set $C > C_0$, then
	%
%	\[ \sum_{i = 1}^\infty H^\alpha_\infty(X_\delta) < \infty, \]
	%
%	and so $H^\alpha_\infty(X) = 0$.
%\end{proof}

\begin{theorem}
	Suppose $E \subset [0,1]^d$ is a set with $\dim(E) \leq s$. Fix $\varepsilon > 0$, and write $l_k = 2^{-\lfloor (1 + \varepsilon)^k \rfloor}$. Then there exists a strong cover of $E$ by sets $\{ E_k \}$, where $E_k$ is a union of $O((1 + \varepsilon)^{2k} l_k^{-s})$ cubes in $\DQ_k^d$.
\end{theorem}
\begin{proof}
	For each hyperdyadic number $l_k$, we can find a collection of cubes $\{ Q_{k,i} \}$ covering $E$ with $l(Q_{k,i}) \leq l_k$ for all $i$, and
	%
	\begin{equation} \label{HausdorffBound5}
		\sum_{i = 1}^\infty l(Q_{k,i})^{s + C\varepsilon} \lesssim 1.
	\end{equation}
	%
	For each $k$ and $i$, find $j_{k,i}$ such that $l_{j_{k,i} + 1} \leq l(Q_{k,i}) \leq l_{j_{k,i}}$. Note $l_{j_{k,i} + 1} \lesssim l_{j_{k,i}}^{1 + \varepsilon}$, so
	%
	\begin{align*}
		\sum_{i = 1}^\infty l_{j_{k,i}}^{s + (C + s)\varepsilon} &= \sum_{i = 1}^\infty l(Q_{k,i})^{s + (C + s) \varepsilon} (l_{j_{k,i}} / l(Q_{k,i}))^{s + (C + s) \varepsilon}\\
		&\lesssim \sum_{i = 1}^\infty l(Q_{k,i})^{s + (C + s)\varepsilon} l_{j_{k,i}}^{-s \varepsilon} \lesssim \sum_{i = 1}^\infty l(Q_{k,i})^{s + C \varepsilon} \lesssim 1.
	\end{align*}
	%
	Thus, replacing $C$ with $C + s$, and replacing $Q_{k,i}$ with the $O_d(1)$ cubes in $\DQ_{j_{k,i}}(Q_{k,i})$, we may assume without loss of generality that all cubes in the decomposition corresponding to \eqref{HausdorffBound5} are hyperdyadic.

	For $k_2 \geq k_1$, we let
	%
	\[ Y_{k_1,k_2} = \bigcup \{ Q_{k_1,i} : l(Q_{k_1,i}) = l_{k_2}. \} \]
	%
	Note that $Y_{k_1,k_2}$ is the union of $O((1/l_{k_2})^{s + C\varepsilon})$ cubes in $\DQ_{k_2}$. We let $Z_{k_1,k_2}$ be the collection of hyperdyadic cubes covering $Y_{k_1,k_2}$ which minimize
	%
	\[ \sum \left\{ l(Q)^s : Q \in Z_{k_1,k_2} \right\} \]
	%
	and such that $l(Q) \geq l_{k_2}$ for each $Q$. Then clearly
	%
	\[ \sum_{Q \in Z_{k_1,k_2}} l(Q)^s \lesssim l_{k_2}^{- C\varepsilon}. \]
	%
	In particular, this means $l(Q) \lesssim l_{k_2}^{-C\varepsilon/s}$ for each $Q \in Z_{k_1,k_2}$. Moreover, for each hyperdyadic $Q_0$ with $l(Q_0) \geq l_{k_2}$,
	%
	\[ \sum_{Q \subset Q_0} l(Q)^s \leq l(Q_0)^s. \]
	%
	Now we define $E_k = \bigcup \left\{ \bigcup_{k_1,k_2} Z_{k_1,k_2} \cap \DQ_k \right\}$. Since $E_k$ only contains cubes from $Z_{k_1,k_2}$ where $k_1 \leq k_2$, and $l_k \lesssim l_{k_2}^{-\varepsilon/\alpha}$ TODO: THERE IS SOMETHING WRONG HERE THIS DOESN'T IMPLY $\log(1/l_k)^2$?. But this means that there are only $O(\log(1/l_k)^2) = O((1 + \varepsilon)^{2k})$ such choices of $(k_1,k_2)$. But this means that
	%
	\[ |E_k| = \sum l(Q)^d = l_k^{d - s} \sum l(Q)^s \lesssim (1 + \varepsilon)^{2k} l_k^{d-s}, \]
	%
	which implies that $E_k$ is the union of at most $O((1 + \varepsilon)^{2k} l_k^{-s})$ cubes in $\DQ_k$.
\end{proof}