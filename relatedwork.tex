%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Related Work}
\label{ch:RelatedWork}

\section{Keleti: A Translate Avoiding Set}

Keleti's two page paper constructs a full dimensional subset $X$ of $[0,1]$ such that $X$ intersects $t + X$ in at most one place for each nonzero real number $t$. If this is true, we say that $X$ \emph{avoids translates}. Malabika has adapted this technique to construct high dimensional subsets avoiding nontrivial solutions to differentiable functions. In this section, and in the sequel, we shall find it is most convenient to avoid certain configurations by expressing them in terms of an equation, whose properties we can then exploit. One feature of translation avoidance is that the problem is specified in terms of a linear equation.

\begin{lemma}
    Let $X$ be a set. Then $X$ avoids translates if and only if there do not exists values $x_1 < x_2 \leq x_3 < x_4$ in $X$ with $x_2 - x_1 = x_4 - x_3$.
\end{lemma}
\begin{proof}

    Suppose $(t + X) \cap X$ contains two points $a < b$. Without loss of generality, we may assume that $t > 0$. If $a \leq b - t$, then the equation
    %
    \[ a - (a - t) = t = b - (b - t) \]
    %
    satisfies the constraints, since $a - t < a \leq b - t < b$ are all elements of $X$. We also have
    %
    \[ (b - t) - (a - t) = b - a, \]
    %
    which satisfies the constraints if $a - t < b - t \leq a < b$. This covers all possible cases. Conversely, if there are $x_1 < x_2 \leq x_3 < x_4$ in $X$ with
    %
    \[ x_2 - x_1 = t = x_4 - x_3, \]
    %
    then $X + t$ contains $x_2 = x_1 + (x_2 - x_1)$ and $x_4 = x_3 + (x_4 - x_3)$.
\end{proof}

%\footnote{We always assume $L_n/L_{n+1}$ is an integer so that intervals in $\mathcal{B}(L_n)$ are either almost disjoint from intervals in $\mathcal{B}(L_{n+1})$ or contained completely within such an interval}

The basic, but fundamental idea to Keleti's technique is to introduce memory into Cantor set constructions. Keleti constructs a nested family of discrete sets $X_0 \supset X_1 \supset \dots$ converging to $X$, with each $X_k$ a union of disjoint intervals in $\mathcal{B}(l_k, \RR^d)$, for a decreasing sequence of lengths $\{ l_k \}$ converging to zero, to be chosen later, but with $10 l_{k+1} \mid l_k$. We initialize $X_0 = [0,1]$, and $l_0 = 1$. Furthermore, we consider a queue of intervals, initially just containining $[0,1]$. To construct the sequence $\{ X_k \}$, Keleti iteratively performs the following procedure:
%
\begin{algorithm}
    \begin{algorithmic}%[1]
        \caption{Construction of the Sets $X_N$}
        \State{Set $k = 0$}
        \MRepeat
            \State{Take off an interval $I$ from the front of the queue}

            \MForAll{\ $J \in \B(l_k, \RR^d)$ contained in $X_k$:}
                \State{Order the intervals in $\B(l_{k+1}, \RR^d)$ contained in $J$ as $J_0, J_1, \dots, J_N$}

                \State{{\bf If} $J \subset I$, add all intervals $J_i$ to $X_{k+1}$ with $i \equiv 0$ modulo 10}
                \State{{\bf Else} add all $J_i$ with $i \equiv 5$ modulo 10}
            \EndForAll
            \State{Add all intervals in $\mathcal{B}(l_{k+1})$ to the end of the queue}
            \State{Increase $k$ by 1}
        \EndRepeat   
    \end{algorithmic}
\end{algorithm}

Each iteration of the algorithm produces a new set $X_k$, and so leaving the algorithm to repeat infinitely produces a sequence $\{ X_k \}$ converging to a set $X$, which is translate avoiding.

\begin{lemma}
    The set $X$ is translate avoiding.
\end{lemma}
\begin{proof}
    If $X$ is not translate avoiding, there is $x_1 < x_2 \leq x_3 < x_4$ with $x_2 - x_1 = x_4 - x_3$. Since $l_k \to 0$, there is a suitably large integer $N$ such that $x_1$ is contained in an interval $I \in \mathcal{B}(l_N,\RR^d)$ not containing $x_2,x_3$, or $x_4$. At stage $N$ of the algorithm, the interval $I$ is added to the end of the queue, and at a much later stage $M$, the interval $I$ is retrieved. Find the startpoints $x_1^\circ, x_2^\circ$, $x_3^\circ, x_4^\circ \in l_M \mathbf{Z}$ to the intervals in $\mathcal{B}(l_M,\RR^d)$ containing $x_1$, $x_2$, $x_3$, and $x_4$. Then we can find $n$ and $m$ such that $x_4^\circ - x_3^\circ = (10n)l_M$, and $x_2^\circ - x_1^\circ = (10m + 5)l_M$. In particular, this means that $|(x_4^\circ - x_3^\circ) - (x_2^\circ - x_1^\circ)| \geq 5L_M$. But
    %
    \begin{align*}
        |(x_4^\circ - x_3^\circ) - (x_2^\circ - x_1^\circ)| &= |[(x_4^\circ - x_3^\circ) - (x_2^\circ - x_1^\circ)] - [(x_4 - x_3) - (x_2 - x_1)]|\\
        &\leq |x_1^\circ - x_1| + \dots + |x_4^\circ - x_4| \leq 4 L_M
    \end{align*}
    %
    which gives a contradiction.
\end{proof}

The algorithm shows that
%
\[ \B(l_k,X_k) = (l_{k-1}/10l_k) \B(l_{k-1},X_{k-1}). \]
%
Thus closing the recursive definition shows
%
\[ \B(l_k,X_k) = \frac{1}{10^k l_k}. \]
%
In particular, this means $|X_k| = 1/10^k$, so $X$ has measure zero irrespective of our parameters. Nonetheless, the canonical measure $\mu$ on $X$ defined with respect to the decomposition $\{ X_k \}$ satisfies $\mu(I) = 10^k l_k$ for all $I \in \B(l_k,X)$. If $10^k l_k^\varepsilon \lesssim_\varepsilon 1$ for all $\varepsilon$, then we can establish the bounds $\mu(I) \lesssim_\varepsilon l_k^{1-\varepsilon}$ for all $\varepsilon$. In particular this is true if we set $l_k = 1/10^{\lfloor k \log k \rfloor}$. And because this sequence is not too fast increasing, we can apply Theorem \ref{easyCoverTheorem} to show $\mu$ is a Frostman measure of dimension $1-\varepsilon$ for each $\varepsilon > 0$, so $X$ has full Hausdorff dimension.







\section{Fraser/Pramanik: Extending Keleti Translation to Smooth Configurations}

Inspired by Keleti's result, Pramanik and Fraser obtained a generalization of the queue method which allows one to find sets avoiding solutions to {\it any} smooth function satisfying suitably mild regularity conditions. To do this, rather than making a linear shift in one of the intervals we avoid as in Keleti's approach, one must use the smoothness properties of the function to find large segments of an interval avoiding solutions to another interval.

\begin{theorem}
    Let $f: \mathbf{R}^{d+1} \to \mathbf{R}$ be a $C^1$ function, and consider sets $T_0, \dots, T_d \subset [0,1]$, with each $T_n$ a union of intervals in $\B(1/M,[0,1])$, and such that $\partial_0 f$ is non-vanishing on $T_0 \times \dots \times T_d$. Then there exists a rational number $C$, and arbitrarily large integers $N \in M \mathbf{Z}$ for which there are $S_k \subset T_k$, each a union of cubes in $\B(C/N^d,T_k)$ with
    %
    \begin{enumerate}
        \item $f(x) \neq 0$ for $x \in S_0 \times \dots \times S_d$.

        \item If $k \neq 0$, $S_k$ contains an interval in $\B(C/N^d,I)$ for each $I \in \B(1/N,T_k)$.

        \item For at least a fraction $1 - 1/M$ of the cubes $I \in \B(1/N,T_0)$, $|S_0 \cap I| \geq C/N$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    We begin by dividing the sets $T_1, \dots, T_d$ into length $1/N$ intervals, and let $S_n$ be defined by including a length $C_0/N^d$ segment, for some constant $C_0$ to be chosen later. Then once we fix $C_0$, the $S_n$ will satisfy property (ii) of the theorem. We define
    %
    \[ \mathbf{A} = \{ a \in \mathbf{R}^{d-1} : a_n\ \text{is a startpoint of a length $1/N$ interval in}\ T_n \} \]
    %
    Then $|\mathbf{A}| \leq N^d$, since each interval $T_n$ is contained in $[0,1]$, and therefore can only contain at most $N$ almost disjoint intervals of length $1/N$. Hence if we define the set of `bad points' in $T_0$ as
    %
    \[ \mathbf{B} = \{ x \in T_0: \text{there is}\ a \in \mathbf{A}\ \text{such that}\ f(x,a) = 0 \} \]
    %
    Then $|\mathbf{B}| \leq MN^d$. This is because for each fixed $a$, the function $x \mapsto f(x,a)$ is either strictly increasing or decreasing over each interval in the decomposition of $T_0$, or which there are at most $M$ because $T_0 \subset [0,1]$. If we split $T_0$ into length $1/N$ intervals, and choose a subcollection of such intervals $I$ such that $|I \cap \mathbf{B}| \leq M^3N^{d-1}$, then we throw away at most $MN^d/M^3N^{d-1} = N/M^2$ intervals, and so we keep $(N/M)(1 - 1/M)$ intervals, which is $1 - 1/M$ of the total number of intervals in the decomposition of $T_0$. The lemma we prove after this theorem implies that there exists a constant $C_1$ such that if $x \in S_n$, and $f(y,x) = 0$, then $d(y,\mathbf{B}) \leq C_0C_1/N^d$. If we split each interval $I$ with $|I \cap \mathbf{B}| \leq M^3N^{d-1}$ into $4M^3N^{d-1}$ length $1/4M^3N^d$ intervals, and we choose $C_0$ such that $C_0C_1 < 1/4M^3$, then the set $S_0$ obtained by discarding each interval that contains or is adjacent to an interval containing an element of $\mathbf{B}$ satisfies $d(S_0,\mathbf{B}) > C_0C_1/N^d$, and therefore there does not exist any $x_n \in S_n$ and $y \in S_0$ such that $f(y,x) = 0$. $S_0$ satisfies property (iii) of the theorem since for the interval $I$ we are considering, we keep at least $M^3N^{d-1}$ length $1/4M^3N^d$ intervals, which in total has length at least $1/4N$.
\end{proof}

\begin{remark}
    The length $1/N$ portion of each interval guaranteed by (iii) is unneccesary to the Hausdorff dimension bound, since the slightly better bounds obtained on scales where an interval is dissected as a $1/N$ are decimated when we eventually divide the further subintervals into $1/N^{d-1}$ intervals. The importance of (iii) is that it implies that the set we will construct has full {\it Minkowski dimension}. The reason for this is that Minkowski dimension lacks the ability to look at varying dissection depths at once, and since, at any particular depth, there exists a length $1/N$ dissection, the process appears to Minkowski to be full dimensional, even though at later scales this $1/N$ dissection is dissected into $1/N^{d-1}$ intervals.
\end{remark}

\begin{lemma}
    Given the $f$, $T_0, \dots, T_d$, there exists a constant $C_1$ depending on these quantities, such that for any $C_0$, and $x \in S_1 \times \dots \times S_{d-1}$, if $f(y,x) = 0$, then $d(y, \mathbf{B}) \leq C_0C_1/N^{d-1}$.
\end{lemma}
\begin{proof}
    Since $T_0 \times \dots \times T_d$ breaks into finitely many cubes with sidelengths $1/M$, it suffices to prove the theorem for a particular cube $J$ in this decomposition, where we assume the zeroset of $f$ intersects $J$. If $J = I \times J'$, where $I$ is an interval, we let $U$ be the set of all $x \in J'$ for which there is $y$ in the interior of $I$ such that $f(y,x) = 0$. Then $U$ is open. The implicit function theorem implies that there exists a $C^1$ function $g: U \to I$ such that $f(x,y) = 0$ if and only if $y = g(x)$. Then the function $h(x) = f(x,g(x))$ vanishes uniformly, so
    %
    \[ 0 = \partial_n h(x) = (\partial_n f) (g(x),x) + (\partial_0 f) (g(x),x) \partial_n g(x) \]
    %
    Hence for $x \in U$,
    %
    \[ |(\nabla g)(x)| = \frac{|(\nabla f)(x)|}{|(\partial_d f)(x,g(x))|} \leq \frac{B}{A} \]
    %
    If $N$ is chosen large enough, then for every $x \in U \cap (S_1 \times \dots \times S_d)$ there is $a \in \mathbf{A} \cap U$ in the same connected component of $U$ as $x$ with $|x - a| \lesssim C_0/N^{d-1}$, and this means that
    %
    \[ |g(x) - g(a)| \leq \| \nabla g \|_\infty |x - a| \lesssim \frac{BC_0}{A N^{d-1}} \]
    %
    and $g(a) \in \mathbf{B}$, completing the proof.
\end{proof}

How do we use this lemma to construct a set avoiding solutions to $f$? We form an infinite queue which will eventually filter out all the possible zeroes of the equation. Divide the interval $[0,1]$ into $d$ intervals, and consider all orderings of $d - 1$ subsets of these intervals, and add them to the queue. Now on each iteration $N$ of the algorithm, we have a set $X_N \subset [0,1]$. We take a particular sequence of intervals $T_1, \dots, T_d$ from the queue, and then use the lemma above to dissect the $X_N \cap T_n$, which are unions of intervals, into sets avoiding solutions to the equation, and describe the remaining points as $X_{N+1}$. We then add all possible orderings of $d$ intervals created into the end of the queue, and rinse and repeat. The set $X = \lim X_n$ then avoids all solutions to the equation with distinct inputs.

What remains is to bound the Hausdorff dimension of $X$ by constructing a probability measure supported on $X$ with suitable decay. To construct our probability measure, we begin with a uniform measure on the interval, and then, whenever our interval is refined, we uniformly distribute the volume on that particular interval uniformly over the new refinement. Let $\mu$ denote the weak limit of this sequence of probability distributions. At each step $n$ of the process, we let $1/M_n$ denote the size of the intervals at the beginning of the $n$'th subdivision, $1/N_n$ denote the size of the split intervals in the lemma, and $C_n$ the $n$'th constant. We have the relation $1/M_{n+1} = C_n/N_n^{d-1}$. If $K$ is a length $1/M_{N+1}$ interval, $J$ a length $1/N_N$ interval, and $I$ a length $1/M_N$ interval with $K \subset J \subset I$ and all recieving some mass in $\mu$. To calculate a bound on their mass, we consider the decompositions considered in the algorithm:
%
\begin{itemize}
        \item If $J$ is subdivided in the non-specialized manner, then every length $1/N_N$ interval recieves the same mass, which is allocated to a single length $1/M_{N+1}$ interval it contains. Thus $\mu(K) = \mu(J) \leq (M_N/N_N) \mu(I)$.
        \item In the second case, at least a fraction $1 - 1/M_N$ of the length $1/N_N$ intervals are assigned mass, so $\mu(J) = (M_N/N_N)(1 - 1/M_N)^{-1} \leq (2M_N/N_N) \mu(I)$, and more than $C_N/N_N$ of each length $1/N_N$ interval is maintained, so
        %
        \[ \mu(K) = \frac{N_N}{C_NM_{N+1}} \mu(J) \leq \frac{2M_N}{C_NM_{N+1}} \mu(I) \]
\end{itemize}
%
Thus in both cases, we have $\mu(J) \lesssim (N_N/M_N) \mu(I)$, $\mu(K) \lesssim_N |K|$, and $N_N = M_{N+1}^{1/(d-1)}/C_N \lesssim_N M_{N+1}^{1/(d-1)}$. From this, we conclude using the results of the appendix that there exists a family of rapidly decaying parameters which gives a $1/(d-1)$ dimensional set.

\begin{remark}
    The set $X$ constructed is precisely a $1/(d-1)$ dimensional set. Recall that $X = \lim X_n$, where $X_n$ is a union of a certain number of length $1/M_n$ intervals $I_1, \dots, I_N$. For each $n$, the interval $I_i$ is inevitably subdivided at a stage $J_i$ into length $C_{J_i} N_{J_i}^{1-d}$ intervals for each length $1/N_{J_i}$ interval that $I_i$ contains. Thus
    %
    \[ H_{1/M_n}^\alpha(X) \leq \sum_{i = 1}^N \frac{N_{m_i}}{M_n} (C_{m_i} N_{m_i}^{1-d})^\alpha = \frac{1}{M_n} \sum_{i = 1}^N C_{m_i}^\alpha N_{m_i}^{1 - \alpha(d-1)} \]
    %
    We may assume that $C_{m_i} \leq 1$, so if $\alpha > 1/(d - 1)$, using the fact that $N \leq M_n$, since $X_n$ is contained in $[0,1]$, we obtain
    %
    \[ H_{1/M_n}^\alpha(X) \leq \frac{1}{M_n} \sum_{i = 1}^N N_{m_i}^{1 - \alpha(d-1)} \leq N_{\max(m_i)}^{1 - \alpha(d-1)} \leq 1 \]
    %
    Thus, taking $n \to \infty$, we conclude $H^\alpha(X) \leq 1 < \infty$, so as $\alpha \downarrow 1/(d - 1)$, we conclude that $X$ has Hausdorff dimension bounded above by $1/(d-1)$.
\end{remark}

%Thus, in both cases, we have $\mu(J) \lesssim (N_N/M_N) \mu(I)$, which means we can apply the second method of appendix to calculate Hausdorff dimension with rapidly growing constants, where $l_N = 1/M_N$ and $r_N = 1/N_N$. We have $\mu(K) \lesssim_N $ and $N_N = M_{N+1}^{1/(d-1)}/C_N$ and


%
%Thus, in both cases, we have $\mu(J) \lesssim_N 1/M_{N+1}$. If $J \subset I$ is any length $1/N_N$ interval considered in the algorithm, then either $\mu(J) = (M_N/N_N) \mu(I)$, as in the first case of the subdivision, or we can apply the second case of the subdivision, giving $\mu(J) = (M_N/N_N)(1 - 1/M_N)^{-1} \mu(I) \leq (2M_N/N_N) \mu(I)$. This means we can apply the second method in the appendix. The fact that 

%by induction, if $I$ is a length $1/M_N$ interval considered in the process, then
%
%\begin{align*}
%    \mu(I) \leq \prod_{n < N} \frac{M_n}{(C_n M_{n+1})^{\frac{1}{d-1}}} = \left( \prod_{n < N} \frac{M_{n+1}^{1-\frac{1}{d-1} }}{C_n^{\frac{1}{d-1}}} \right) \frac{1}{M_N} = \frac{A_N}{M_N}
%\end{align*}
%
%If $J \subset I$ is any length $1/N_N$ interval considered in the algorithm, then either $\mu(J) = (M_N/N_N) \mu(I)$, as in the first case, or in the second case, $\mu(J) = (M_N/N_N(1 - 1/M_N)) \leq 2M_N/N_N \mu(I)$, so in general $\mu(J) \leq 2A_N/N_N$. This means we can apply the second method in the appendix for bounding Hausdorff dimension, with $l_N = 1/M_N$ and $r_N = 1/N_N$. To obtain 

%Now if $1/N_N \leq |I| \leq 1/M_N$, then $I$ can be covered by $|I|N_N$ intervals of length $1/N_N$, and so
%
%\begin{align*}
%    \mu(I) &\leq 2|I|N_N \frac{A_N}{N_N} = 2A_N|I| = \frac{2A_{N-1} M_N^{1 - \frac{1}{d-1}}}{C_{N-1}^{\frac{1}{d-1}}} |I| \lesssim_\varepsilon |I|M_N^{1 - \frac{1}{d-1} - \varepsilon} \leq |I|^{\frac{1}{d-1} - \varepsilon}
%\end{align*}
%
%Provided that we can choose $M_N$ such that $A_N/C_N \lesssim_\varepsilon M_{N+1}^\varepsilon$ for all $\varepsilon$ (this is why it is incredibly important that the values in the lemma are independent of $N$ in the proof above). On the other hand, if $1/M_{N+1} \leq |I| \leq 1/N_N$, then $I$ can be covered by a single length $1/N_N$ interval, hence
%
%\[ \mu(I) \leq \frac{2A_N}{N_N} = \frac{2A_N}{N_N} = \frac{2A_N}{(C_NM_{N+1})^{\frac{1}{d-1}}} \lesssim_\varepsilon \frac{1}{M_{N+1}^{\frac{1}{d-1} - \varepsilon}} \leq |I|^{\frac{1}{d-1} - \varepsilon} \]
%
%Thus we obtain the theorem if $M_{N+1} = \exp(A_N/C_N)$, for instance.

\section{A Set Avoiding All Functions With A Common Derivative}

In the latter part's of their paper, Pramanik and Fraser apply an iterative technique to construct, for each $\alpha$ with $\sum \alpha_n = 0$ and $K > 0$, a set $E$ of positive Hausdorff dimension avoiding solutions to any function $f: \mathbf{R}^d \to \mathbf{R}$ satisfying wth $(\partial_n f)(0) = \alpha_n$,
%
\[ \left| f(x) - \sum \alpha_n x_n \right| \leq K \sum_{n \neq 1} (x_n - x_1)^2 \]
%
The set of such $f$ is an uncountable family, which makes this situation interesting. The technique to create such a set relies on another iterative procedure.

\begin{lemma}
    Let $I \subsetneq [1,d]$ be a strict subset of indices, and $\delta_0 > 0$. Then there exists $\varepsilon > 0$ such that for any $\lambda > 0$ and two disjoint intervals $J_1$ and $J_2$, with $J_1$ occuring before $J_2$, and if we set
    %
    \[ [a_n,b_n] = \begin{cases} J_1 & n \in I \\ J_2 & n \not \in I \end{cases} \]
    %
    then for $\delta < \delta_0$, either for all $x_n \in [a_n,a_n+\varepsilon \lambda]$ or for all $x_n \in [b_n - \varepsilon \lambda, b_n]$,
    %
    \[ \left| \sum \alpha_n x_n \right| \geq \delta \lambda \]
\end{lemma}
\begin{proof}
    If $C^* = \sum |\alpha_n|$, then for $|x_n - a_n| \leq \varepsilon \lambda$,
    %
    \[ |\sum \alpha_n (x_n - a_n)| \leq C^* \varepsilon \lambda \]
    %
    Thus if $|\sum \alpha_n a_n| > (\delta + \varepsilon C^*)\lambda$, then $|\sum \alpha_n x_n| \geq \delta \lambda$. If this does not occur
\end{proof}

\endinput